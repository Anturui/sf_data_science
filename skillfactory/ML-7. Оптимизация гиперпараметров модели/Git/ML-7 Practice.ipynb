{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np #for matrix calculations\n",
    "import pandas as pd #for data analysis and preprocessing\n",
    "import matplotlib.pyplot as plt #for visualization\n",
    "import seaborn as sns #for visualization\n",
    "\n",
    "from sklearn import linear_model #linear models\n",
    "from sklearn import tree #decision trees\n",
    "from sklearn import ensemble #ensembles\n",
    "from sklearn import metrics #metrics\n",
    "from sklearn import preprocessing #preprocessing\n",
    "from sklearn.model_selection import train_test_split #sample splitting\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from sklearn.model_selection import GridSearchCV # optimization method\n",
    "from sklearn.model_selection import RandomizedSearchCV # optimization method\n",
    "from sklearn.model_selection import cross_val_score # k-fold валидация\n",
    "from sklearn.model_selection import StratifiedKFold # k-fold валидация\n",
    "import hyperopt # optimization method\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import optuna # optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = pd.read_csv('data/_train_sem09__1_.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3751, 1777)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_activity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at the balance of classes:\n",
    "sns.countplot(data=data_activity, x='Activity');\n",
    "# # classes are not strong, but not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a matrix of observations X and a vector of responses y\n",
    "X = data_activity.drop(['Activity'], axis=1)\n",
    "y = data_activity['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the sample into training and test in the ratio of 80/20. \n",
    "# To preserve the ratios of the target attribute, we use the stratify parameter (stratified partitioning).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.542333\n",
       "0    0.457667\n",
       "Name: Activity, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.541944\n",
       "0    0.458056\n",
       "Name: Activity, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from locale import normalize\n",
    "\n",
    "\n",
    "display(y_train.value_counts(normalize = True))\n",
    "y_test.value_counts(normalize = True)\n",
    "# The training and test samples are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на train: 0.89\n",
      "f1_score on the test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Creating an object of the logistic regression class\n",
    "log_reg = linear_model.LogisticRegression(max_iter = 1000)\n",
    "#Training the model by minimizing logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "print(\"f1_score на train: {:.2f}\".format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.00\n",
      "Test: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Creating an object of the random forest class\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Training the model\n",
    "rf.fit(X_train, y_train)\n",
    "#Output metric values\n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "# It can be seen that the model has signs of retraining, however, a good score was obtained on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "f1_score on the train set: 0.80\n",
      "f1_score on the test set: 0.78\n",
      "Best hyperparameter values: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# setting the range of parameters for logistic regression\n",
    "param_grid = {'penalty': ['l2', 'none'] , # type of regularization\n",
    "              'solver': ['lbfgs', 'sag'], # optimization algorithm\n",
    "               'C': [0.01, 0.5, 1]}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42,#random number generator\n",
    "        max_iter=1000 #number of iterations for convergence\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time \n",
    "grid_search.fit(X_train, y_train) \n",
    "y_train_pred = grid_search.predict(X_train)\n",
    "print('f1_score on the train set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Best hyperparameter values: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.82\n",
      "f1_score on the test set: 0.78\n",
      "Best hyperparameter values: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid_search.predict(X_train)\n",
    "print(' {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Best hyperparameter values: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "f1_score on the train set: 0.94\n",
      "f1_score on the test set: 0.80\n",
      "Best hyperparameter values: {'max_depth': 15, 'min_samples_leaf': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Оптимизируем параметры RandomForestClassifier с кросс-валидацией на пяти фолдах\n",
    "\n",
    "param_grid = {'n_estimators': [100, 300] , # количество деревьев\n",
    "              'min_samples_leaf': [5,7], # минимальное количество объектов в листе\n",
    "               'max_depth': [15,35]}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        # max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time \n",
    "grid_search.fit(X_train, y_train) \n",
    "y_train_pred = grid_search.predict(X_train)\n",
    "print('f1_score on the train set: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Best hyperparameter values: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on the train set: 0.82\n",
      "f1_score on the test set: 0.78\n",
      " Best hyperparameter values:{'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# задаем распределение параметров для поиска по методу RandomizedSearchCV\n",
    "param_distributions = {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 1]}\n",
    "            \n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1,\n",
    "    return_train_score=True\n",
    ")  \n",
    "%time \n",
    "random_search_logreg.fit(X_train, y_train) \n",
    "y_train_pred = random_search_logreg.predict(X_train)\n",
    "print('f1_score on the train set: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = random_search_logreg.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\" Best hyperparameter values:{}\".format(random_search_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем распределение параметров для поиска по методу RandomizedSearchCV\n",
    "param_distributions = {'min_samples_leaf': [3,5,7],\n",
    "              'max_depth': [15,40],\n",
    "              'criterion':['entropy','gini'],\n",
    "              'n_estimators':[100,300]\n",
    "              }\n",
    "            \n",
    "random_search_randomforest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1,\n",
    "    return_train_score=True\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "f1_score on the train set: 0.98\n",
      "f1_score on the test set: 0.81\n",
      "Best hyperparameter values: {'n_estimators': 300, 'min_samples_leaf': 3, 'max_depth': 40, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "random_search_randomforest.fit(X_train, y_train) \n",
    "y_train_pred = random_search_randomforest.predict(X_train)\n",
    "print('f1_score on the train set: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = random_search_randomforest.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Best hyperparameter values: {}\".format(random_search_randomforest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "#do the import and output the library version\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# fmin is the main function, it will minimize our functionality\n",
    "# tpe - optimization algorithm\n",
    "# hp - includes a set of methods for declaring the hyperparameter search space\n",
    "# trails - used for logging results\n",
    "\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting possible values of logistic regression parameters\n",
    "list_solver = ['liblinear', 'saga']\n",
    "list_penalty = ['l2','l1']\n",
    "\n",
    "search_space = {\n",
    "                'solver':  hp.choice(label='solver', options=list_solver),\n",
    "                'penalty' : hp.choice(label='penalty', \n",
    "                          options=list_penalty),\n",
    "                'C' : hp.uniform(label='C', \n",
    "                        low=0.01, \n",
    "                        high=1)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random_state\n",
    "random_state = 42\n",
    "def hyperopt_logreg(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # the function gets a combination of hyperparameters in \"params\"\n",
    "    params = {'penalty': params['penalty'], \n",
    "              'solver': params['solver'], \n",
    "              'C': params['C']\n",
    "              }\n",
    "   \n",
    "  \n",
    "    # use this combination to build a model\n",
    "    model = linear_model.LogisticRegression(**params, random_state=random_state, max_iter=1000)\n",
    "\n",
    "    # training the model\n",
    "    model.fit(X, y)\n",
    "    # score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # you can also train the model using cross validation\n",
    "# apply cross validation with the same number of folds\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # the metric needs to be minimized, so we put a minus sign\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      " 30%|███       | 6/20 [01:53<05:31, 23.65s/trial, best loss: -0.7920651360713664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [04:10<02:47, 18.60s/trial, best loss: -0.7920651360713664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [07:26<01:51, 27.81s/trial, best loss: -0.7920651360713664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:32<00:00, 31.64s/trial, best loss: -0.7920651360713664]\n",
      "Best hyperparameter values {'C': 0.16941386753130935, 'penalty': 1, 'solver': 1}\n"
     ]
    }
   ],
   "source": [
    "# starting the selection of hyperparameters\n",
    "%time\n",
    "\n",
    "trials = Trials() # used for logging results\n",
    "\n",
    "best=fmin(hyperopt_logreg,  # our function\n",
    "          space=search_space, # hyperparameter space\n",
    "          algo=tpe.suggest, # optimization algorithm, set by default, optional\n",
    "          max_evals=20, # maximum number of iterations\n",
    "          trials=trials, # logging of results\n",
    "          rstate=np.random.default_rng(random_state)  # fix for repeatability of the result\n",
    "         )\n",
    "print(\"Best hyperparameter values {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.82\n",
      "f1_score on the test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Log. reg. with the best parameters\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state, \n",
    "    solver=list_solver[best['solver']],\n",
    "    penalty=list_penalty[best['penalty']],\n",
    "    C=best['C'], \n",
    "    max_iter=1000\n",
    "    )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score on the test set: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the hyperparameter search space\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 50),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 21, 2),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 8, 3)\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # the function gets a combination of hyperparameters in \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # use this combination to build a model\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # training the model\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # you can also train the model using cross validation\n",
    "# apply cross validation with the same number of folds\n",
    "   \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # the metric needs to be minimized, so we put a minus sign\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "100%|██████████| 20/20 [01:21<00:00,  4.07s/trial, best loss: -0.8160314454584471]\n",
      "Best hyperparameter values {'max_depth': 16.0, 'min_samples_leaf': 3.0, 'n_estimators': 150.0}\n"
     ]
    }
   ],
   "source": [
    "# starting the selection of hyperparameters\n",
    "%time\n",
    "\n",
    "trials = Trials() # used for logging results\n",
    "\n",
    "best=fmin(hyperopt_rf, # our function\n",
    "          space=space, # hyperparameter space\n",
    "          algo=tpe.suggest, # optimization algorithm, set by default, optional\n",
    "          max_evals=20, # maximum number of iterations\n",
    "          trials=trials, # logging of results\n",
    "          rstate=np.random.default_rng(random_state) # fix for repeatability of the result\n",
    "         )\n",
    "print(\"Best hyperparameter values {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on the training set: 0.97\n",
      "f1_score in the test set:0.80\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score on the training set: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score in the test set:{:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_log_reg(trial):\n",
    "  # defining hyperparameter search spaces\n",
    "  solver = trial.suggest_categorical('solver', list_solver)\n",
    "  penalty = trial.suggest_categorical('penalty', list_penalty)\n",
    "  C = trial.suggest_float('C', 0.01, 1)\n",
    "\n",
    "  # creating a model\n",
    "  model = linear_model.LogisticRegression(solver=solver, penalty=penalty, C=C, random_state=random_state, max_iter=1000)\n",
    "  \n",
    "  \n",
    "  # training the model\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-06 15:33:57,193]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:35:40,189]\u001b[0m Trial 0 finished with value: 0.783661995718675 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.7529313707906248}. Best is trial 0 with value: 0.783661995718675.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:36:07,893]\u001b[0m Trial 1 finished with value: 0.7885666487200088 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.12567899612594033}. Best is trial 1 with value: 0.7885666487200088.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:36:08,790]\u001b[0m Trial 2 finished with value: 0.7892173046268852 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.2217932943640443}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:36:10,169]\u001b[0m Trial 3 finished with value: 0.7866293480171617 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.535336550090106}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:36:35,279]\u001b[0m Trial 4 finished with value: 0.7828351545352598 and parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.16878753752152637}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:38:14,287]\u001b[0m Trial 5 finished with value: 0.7861045129117954 and parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 0.592594309863399}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:15,771]\u001b[0m Trial 6 finished with value: 0.7810893505547788 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.5309353926885354}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:16,691]\u001b[0m Trial 7 finished with value: 0.7886654231566205 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.32185627620402885}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:56,363]\u001b[0m Trial 8 finished with value: 0.7780173758251074 and parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 0.6839139017768052}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:57,055]\u001b[0m Trial 9 finished with value: 0.7882758549465647 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.12277002358875712}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:58,284]\u001b[0m Trial 10 finished with value: 0.7773860802149837 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.3331274895523608}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:38:59,261]\u001b[0m Trial 11 finished with value: 0.7890515236584387 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.31406535356746673}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:00,652]\u001b[0m Trial 12 finished with value: 0.7891091716528221 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.2873106592242807}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:01,939]\u001b[0m Trial 13 finished with value: 0.7821752455887678 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.8988970382348869}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:02,570]\u001b[0m Trial 14 finished with value: 0.7577274583182511 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.01958226238774094}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:03,645]\u001b[0m Trial 15 finished with value: 0.7884252973567989 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.40404934362190403}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:04,489]\u001b[0m Trial 16 finished with value: 0.7890735802208536 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.22946156013020108}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:05,676]\u001b[0m Trial 17 finished with value: 0.7881780654424799 and parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.4109306956136835}. Best is trial 2 with value: 0.7892173046268852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:06,534]\u001b[0m Trial 18 finished with value: 0.7916424515447698 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.018420352408761276}. Best is trial 18 with value: 0.7916424515447698.\u001b[0m\n",
      "\u001b[32m[I 2022-10-06 15:39:07,322]\u001b[0m Trial 19 finished with value: 0.7916377519714574 and parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.018046854330138806}. Best is trial 18 with value: 0.7916424515447698.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# creating a research object\n",
    "# we can directly indicate that we need to maximize the metric direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# looking for the best combination of hyperparameters n_trials times\n",
    "study.optimize(optuna_log_reg, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.018420352408761276}\n",
      "f1_score on the training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Best hyperparameter values: {}\".format(study.best_params))\n",
    "print(\"f1_score on the training set: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on the training set: 0.8309352517985611\n",
      "f1_score on the training set during cross validation:0.7916424515447698\n",
      "f1_score on the test set: 0.7829181494661923\n"
     ]
    }
   ],
   "source": [
    "# we set the best Optuna parameters for log regression and evaluate score for train and test\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state, \n",
    "    solver=study.best_params['solver'],\n",
    "    penalty=study.best_params['penalty'],\n",
    "    C=study.best_params['C']\n",
    "    )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(f'f1_score on the training set: {metrics.f1_score(y_train, y_train_pred)}')\n",
    "print(f'f1_score on the training set during cross validation:{cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()}')\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f'f1_score on the test set: {metrics.f1_score(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # defining hyperparameter search spaces\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 310, 50)\n",
    "  max_depth = trial.suggest_int('max_depth', 15, 46, 15)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 3, 8, 2)\n",
    "\n",
    "  # creating a model\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # training the model\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-06 15:39:08,423]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:12,108]\u001b[0m Trial 0 finished with value: 0.8088376706401439 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8088376706401439.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:18,714]\u001b[0m Trial 1 finished with value: 0.8107732272434319 and parameters: {'n_estimators': 250, 'max_depth': 45, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8107732272434319.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:22,646]\u001b[0m Trial 2 finished with value: 0.8154509271841853 and parameters: {'n_estimators': 150, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:26,519]\u001b[0m Trial 3 finished with value: 0.8108465347570523 and parameters: {'n_estimators': 150, 'max_depth': 45, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:32,484]\u001b[0m Trial 4 finished with value: 0.8145652135159441 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:35,719]\u001b[0m Trial 5 finished with value: 0.8064342186534139 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:43,390]\u001b[0m Trial 6 finished with value: 0.8107732272434319 and parameters: {'n_estimators': 250, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:49,791]\u001b[0m Trial 7 finished with value: 0.8143074842362192 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8154509271841853.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:39:58,100]\u001b[0m Trial 8 finished with value: 0.8159834669911783 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:03,412]\u001b[0m Trial 9 finished with value: 0.8145652135159441 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:11,780]\u001b[0m Trial 10 finished with value: 0.806371044078426 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:21,507]\u001b[0m Trial 11 finished with value: 0.8159834669911783 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:31,005]\u001b[0m Trial 12 finished with value: 0.8159834669911783 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:37,411]\u001b[0m Trial 13 finished with value: 0.8129109852451494 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:43,524]\u001b[0m Trial 14 finished with value: 0.8144850993766557 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:50,145]\u001b[0m Trial 15 finished with value: 0.8115211581394572 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:40:56,302]\u001b[0m Trial 16 finished with value: 0.8144850993766557 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:41:02,925]\u001b[0m Trial 17 finished with value: 0.8042204544602107 and parameters: {'n_estimators': 300, 'max_depth': 45, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:41:08,856]\u001b[0m Trial 18 finished with value: 0.8144850993766557 and parameters: {'n_estimators': 250, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [100, 310] and step=50, but the range is not divisible by `step`. It will be replaced by [100, 300].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [15, 46] and step=15, but the range is not divisible by `step`. It will be replaced by [15, 45].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [3, 8] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 7].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-06 15:41:17,343]\u001b[0m Trial 19 finished with value: 0.8115211581394572 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.8159834669911783.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# creating a research object\n",
    "# we can directly indicate that we need to maximize the metric direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# looking for the best combination of hyperparameters n_trials times\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values {'n_estimators': 300, 'max_depth': 15, 'min_samples_leaf': 3}\n",
      "f1_score on the training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# output the results on the training sample\n",
    "print(\"Best hyperparameter values {}\".format(study.best_params))\n",
    "print(\"f1_score on the training set: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on the training set:0.9653073645769933\n",
      "f1_score on the training set during cross validation:0.8159834669911783\n",
      "f1_score on the test set: 0.8009708737864076\n"
     ]
    }
   ],
   "source": [
    "# Creating a model with the best parameters defined by the Optuna method\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    min_samples_leaf=study.best_params['min_samples_leaf']\n",
    "    )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(f'f1_score on the training set:{metrics.f1_score(y_train, y_train_pred)}')\n",
    "print(f'f1_score on the training set during cross validation:{cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()}')\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f'f1_score on the test set: {metrics.f1_score(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Сonclusions\n",
    "1. Four optimization methods were used to find optimal values of model parameters: GRIDSEARCHCV, RANDOMIZEDSEARCHCV, HYPEROPT (Tree-Structured Parzen Estimators algorithm) and Optuna.\n",
    "2. To reduce the optimization time, the ranges and the number of values of categorical parameters were reduced (for example, the method of finding the maximum of the likelihood function in logistic regression)\n",
    "3. On all types of optimization, higher scores (f1-world) are observed for Random Forest than for logistic regression\n",
    "4. The classical GridSearchCV method showed the longest operating time even with relatively small ranges of model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
