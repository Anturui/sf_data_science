{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import varname\n",
    "\n",
    "import advertools as adv\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns #for visualization\n",
    "\n",
    "import datetime\n",
    "\n",
    "import ast \n",
    "\n",
    "import dostoevsky\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "\n",
    "from sklearn import metrics #метрики\n",
    "\n",
    "from sklearn import preprocessing #предобработка\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "from numpy import absolute\n",
    "\n",
    "from numpy import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import swifter\n",
    "\n",
    "# Визуализация\n",
    "\n",
    "import plotly.express as px # для визуализации данных\n",
    "\n",
    "import matplotlib.pyplot as plt # для отображения рукописных цифр\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import math\n",
    "\n",
    "from swifter import set_defaults\n",
    "\n",
    "set_defaults(\n",
    "\n",
    "    npartitions=None,\n",
    "\n",
    "    dask_threshold=1,\n",
    "\n",
    "    scheduler=\"processes\",\n",
    "\n",
    "    progress_bar=True,\n",
    "\n",
    "    progress_bar_desc=False,\n",
    "\n",
    "    allow_dask_on_strings=False,\n",
    "\n",
    "    force_parallel=False,\n",
    "\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, rand_score, adjusted_rand_score\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score, homogeneity_score, completeness_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "\n",
    "# import numba\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from plotly.graph_objects import Scatterpolar\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import optuna\n",
    "\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand_df_11_55_16_13_1.csv grand_df_14_49_51 grand_df_12_6_10_13_1 grand_df_12_52_54_13_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_df_complex = pd.read_csv('grand_data_zero_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_df = grand_df_complex.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38621, 1345)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>weight_to_height</th>\n",
       "      <th>forwards_to_views</th>\n",
       "      <th>second</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>skip</th>\n",
       "      <th>speech</th>\n",
       "      <th>💵in_msg</th>\n",
       "      <th>🤩in_msg</th>\n",
       "      <th>🎇in_msg</th>\n",
       "      <th>🐰in_msg</th>\n",
       "      <th>👆🏻in_msg</th>\n",
       "      <th>🌐in_msg</th>\n",
       "      <th>🌵in_msg</th>\n",
       "      <th>🦐in_msg</th>\n",
       "      <th>🦞in_msg</th>\n",
       "      <th>👨‍💼in_msg</th>\n",
       "      <th>⏳in_msg</th>\n",
       "      <th>👨‍🦱in_msg</th>\n",
       "      <th>🧤in_msg</th>\n",
       "      <th>🥃in_msg</th>\n",
       "      <th>🙌🏻in_msg</th>\n",
       "      <th>😄in_msg</th>\n",
       "      <th>🇨🇭in_msg</th>\n",
       "      <th>🎨in_msg</th>\n",
       "      <th>👖in_msg</th>\n",
       "      <th>🇬🇹in_msg</th>\n",
       "      <th>👉in_msg</th>\n",
       "      <th>🌴in_msg</th>\n",
       "      <th>🐌in_msg</th>\n",
       "      <th>🔸in_msg</th>\n",
       "      <th>🇶🇦in_msg</th>\n",
       "      <th>👁in_msg</th>\n",
       "      <th>🐊in_msg</th>\n",
       "      <th>🥳in_msg</th>\n",
       "      <th>🤷in_msg</th>\n",
       "      <th>🇦🇪in_msg</th>\n",
       "      <th>🍽in_msg</th>\n",
       "      <th>🧙in_msg</th>\n",
       "      <th>📸in_msg</th>\n",
       "      <th>🪴in_msg</th>\n",
       "      <th>🇸🇮in_msg</th>\n",
       "      <th>🧼in_msg</th>\n",
       "      <th>🔉in_msg</th>\n",
       "      <th>☄in_msg</th>\n",
       "      <th>👇🏻in_msg</th>\n",
       "      <th>🧐in_msg</th>\n",
       "      <th>🙈in_msg</th>\n",
       "      <th>⛷in_msg</th>\n",
       "      <th>🍄in_msg</th>\n",
       "      <th>👈in_msg</th>\n",
       "      <th>🏒in_msg</th>\n",
       "      <th>😮in_msg</th>\n",
       "      <th>🗺in_msg</th>\n",
       "      <th>🗿in_msg</th>\n",
       "      <th>🧔in_msg</th>\n",
       "      <th>⛸in_msg</th>\n",
       "      <th>🥤in_msg</th>\n",
       "      <th>🔬in_msg</th>\n",
       "      <th>▶️in_msg</th>\n",
       "      <th>🦑in_msg</th>\n",
       "      <th>🚿in_msg</th>\n",
       "      <th>🥕in_msg</th>\n",
       "      <th>🇳🇦in_msg</th>\n",
       "      <th>❗in_msg</th>\n",
       "      <th>🏺in_msg</th>\n",
       "      <th>🐍in_msg</th>\n",
       "      <th>✔️in_msg</th>\n",
       "      <th>🦝in_msg</th>\n",
       "      <th>💐in_msg</th>\n",
       "      <th>🦒in_msg</th>\n",
       "      <th>🚉in_msg</th>\n",
       "      <th>🦍in_msg</th>\n",
       "      <th>🇭🇰in_msg</th>\n",
       "      <th>🇵🇪in_msg</th>\n",
       "      <th>🇦🇱in_msg</th>\n",
       "      <th>👱‍♂in_msg</th>\n",
       "      <th>👇in_msg</th>\n",
       "      <th>🥺in_msg</th>\n",
       "      <th>🇸🇰in_msg</th>\n",
       "      <th>⛵in_msg</th>\n",
       "      <th>💁‍♂in_msg</th>\n",
       "      <th>🗨in_msg</th>\n",
       "      <th>🇳🇴in_msg</th>\n",
       "      <th>🇸🇪in_msg</th>\n",
       "      <th>🍂in_msg</th>\n",
       "      <th>💔in_msg</th>\n",
       "      <th>🤟in_msg</th>\n",
       "      <th>🇧🇷in_msg</th>\n",
       "      <th>💣in_msg</th>\n",
       "      <th>🏝️in_msg</th>\n",
       "      <th>📱in_msg</th>\n",
       "      <th>🐞in_msg</th>\n",
       "      <th>🦘in_msg</th>\n",
       "      <th>🍯in_msg</th>\n",
       "      <th>👑in_msg</th>\n",
       "      <th>👥in_msg</th>\n",
       "      <th>🐈in_msg</th>\n",
       "      <th>🌘in_msg</th>\n",
       "      <th>👕in_msg</th>\n",
       "      <th>🧘🏻‍♂️in_msg</th>\n",
       "      <th>🟡in_msg</th>\n",
       "      <th>🎗in_msg</th>\n",
       "      <th>🛩in_msg</th>\n",
       "      <th>🏠in_msg</th>\n",
       "      <th>🐒in_msg</th>\n",
       "      <th>✅in_msg</th>\n",
       "      <th>🇲🇦in_msg</th>\n",
       "      <th>🍑in_msg</th>\n",
       "      <th>💧in_msg</th>\n",
       "      <th>👠in_msg</th>\n",
       "      <th>☮️in_msg</th>\n",
       "      <th>🗼in_msg</th>\n",
       "      <th>🇮🇶in_msg</th>\n",
       "      <th>🔥in_msg</th>\n",
       "      <th>🦛in_msg</th>\n",
       "      <th>☄️in_msg</th>\n",
       "      <th>😻in_msg</th>\n",
       "      <th>🎟in_msg</th>\n",
       "      <th>🇪🇨in_msg</th>\n",
       "      <th>🇾🇪in_msg</th>\n",
       "      <th>💁‍♂️in_msg</th>\n",
       "      <th>💚in_msg</th>\n",
       "      <th>🙄in_msg</th>\n",
       "      <th>🐭in_msg</th>\n",
       "      <th>🌒in_msg</th>\n",
       "      <th>👨🏻‍🏫in_msg</th>\n",
       "      <th>🇲🇹in_msg</th>\n",
       "      <th>😤in_msg</th>\n",
       "      <th>🇨🇿in_msg</th>\n",
       "      <th>🎭in_msg</th>\n",
       "      <th>🐇in_msg</th>\n",
       "      <th>🎓in_msg</th>\n",
       "      <th>🤷‍♀️in_msg</th>\n",
       "      <th>✌🏽in_msg</th>\n",
       "      <th>🤪in_msg</th>\n",
       "      <th>👁️in_msg</th>\n",
       "      <th>📈in_msg</th>\n",
       "      <th>🅾in_msg</th>\n",
       "      <th>🎠in_msg</th>\n",
       "      <th>🦆in_msg</th>\n",
       "      <th>...</th>\n",
       "      <th>word_number_192</th>\n",
       "      <th>word_number_193</th>\n",
       "      <th>word_number_194</th>\n",
       "      <th>word_number_195</th>\n",
       "      <th>word_number_196</th>\n",
       "      <th>word_number_197</th>\n",
       "      <th>word_number_198</th>\n",
       "      <th>word_number_199</th>\n",
       "      <th>word_number_200</th>\n",
       "      <th>word_number_201</th>\n",
       "      <th>word_number_202</th>\n",
       "      <th>word_number_203</th>\n",
       "      <th>word_number_204</th>\n",
       "      <th>word_number_205</th>\n",
       "      <th>word_number_206</th>\n",
       "      <th>word_number_207</th>\n",
       "      <th>word_number_208</th>\n",
       "      <th>word_number_209</th>\n",
       "      <th>word_number_210</th>\n",
       "      <th>word_number_211</th>\n",
       "      <th>word_number_212</th>\n",
       "      <th>word_number_213</th>\n",
       "      <th>word_number_214</th>\n",
       "      <th>word_number_215</th>\n",
       "      <th>word_number_216</th>\n",
       "      <th>word_number_217</th>\n",
       "      <th>word_number_218</th>\n",
       "      <th>word_number_219</th>\n",
       "      <th>word_number_220</th>\n",
       "      <th>word_number_221</th>\n",
       "      <th>word_number_222</th>\n",
       "      <th>word_number_223</th>\n",
       "      <th>MessageEntityUnderline</th>\n",
       "      <th>MessageEntityStrike</th>\n",
       "      <th>MessageEntityUrl</th>\n",
       "      <th>MessageEntityBold</th>\n",
       "      <th>MessageEntityCode</th>\n",
       "      <th>MessageEntityHashtag</th>\n",
       "      <th>MessageEntityCustomEmoji</th>\n",
       "      <th>MessageEntityMention</th>\n",
       "      <th>MessageEntityEmail</th>\n",
       "      <th>MessageEntityTextUrl</th>\n",
       "      <th>MessageEntityItalic</th>\n",
       "      <th>MessageEntitySpoiler</th>\n",
       "      <th>word_number_224</th>\n",
       "      <th>word_number_225</th>\n",
       "      <th>word_number_226</th>\n",
       "      <th>word_number_227</th>\n",
       "      <th>word_number_228</th>\n",
       "      <th>word_number_229</th>\n",
       "      <th>word_number_230</th>\n",
       "      <th>word_number_231</th>\n",
       "      <th>word_number_232</th>\n",
       "      <th>word_number_233</th>\n",
       "      <th>word_number_234</th>\n",
       "      <th>word_number_235</th>\n",
       "      <th>word_number_236</th>\n",
       "      <th>word_number_237</th>\n",
       "      <th>word_number_238</th>\n",
       "      <th>word_number_239</th>\n",
       "      <th>word_number_240</th>\n",
       "      <th>word_number_241</th>\n",
       "      <th>word_number_242</th>\n",
       "      <th>word_number_243</th>\n",
       "      <th>word_number_244</th>\n",
       "      <th>word_number_245</th>\n",
       "      <th>word_number_246</th>\n",
       "      <th>word_number_247</th>\n",
       "      <th>word_number_248</th>\n",
       "      <th>word_number_249</th>\n",
       "      <th>word_number_250</th>\n",
       "      <th>word_number_251</th>\n",
       "      <th>word_number_252</th>\n",
       "      <th>word_number_253</th>\n",
       "      <th>word_number_254</th>\n",
       "      <th>word_number_255</th>\n",
       "      <th>word_number_256</th>\n",
       "      <th>word_number_257</th>\n",
       "      <th>word_number_258</th>\n",
       "      <th>word_number_259</th>\n",
       "      <th>word_number_260</th>\n",
       "      <th>word_number_261</th>\n",
       "      <th>word_number_262</th>\n",
       "      <th>word_number_263</th>\n",
       "      <th>word_number_264</th>\n",
       "      <th>word_number_265</th>\n",
       "      <th>word_number_266</th>\n",
       "      <th>word_number_267</th>\n",
       "      <th>word_number_268</th>\n",
       "      <th>word_number_269</th>\n",
       "      <th>word_number_270</th>\n",
       "      <th>word_number_271</th>\n",
       "      <th>word_number_272</th>\n",
       "      <th>word_number_273</th>\n",
       "      <th>word_number_274</th>\n",
       "      <th>word_number_275</th>\n",
       "      <th>word_number_276</th>\n",
       "      <th>word_number_277</th>\n",
       "      <th>word_number_278</th>\n",
       "      <th>word_number_279</th>\n",
       "      <th>word_number_280</th>\n",
       "      <th>word_number_281</th>\n",
       "      <th>word_number_282</th>\n",
       "      <th>word_number_283</th>\n",
       "      <th>word_number_284</th>\n",
       "      <th>word_number_285</th>\n",
       "      <th>word_number_286</th>\n",
       "      <th>word_number_287</th>\n",
       "      <th>word_number_288</th>\n",
       "      <th>word_number_289</th>\n",
       "      <th>word_number_290</th>\n",
       "      <th>word_number_291</th>\n",
       "      <th>word_number_292</th>\n",
       "      <th>word_number_293</th>\n",
       "      <th>word_number_294</th>\n",
       "      <th>word_number_295</th>\n",
       "      <th>word_number_296</th>\n",
       "      <th>word_number_297</th>\n",
       "      <th>word_number_298</th>\n",
       "      <th>word_number_299</th>\n",
       "      <th>word_number_300</th>\n",
       "      <th>word_number_301</th>\n",
       "      <th>dtdays</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>h_std</th>\n",
       "      <th>s_std</th>\n",
       "      <th>v_std</th>\n",
       "      <th>h_median</th>\n",
       "      <th>s_median</th>\n",
       "      <th>v_median</th>\n",
       "      <th>h_min</th>\n",
       "      <th>s_min</th>\n",
       "      <th>v_min</th>\n",
       "      <th>h_max</th>\n",
       "      <th>s_max</th>\n",
       "      <th>s_max.1</th>\n",
       "      <th>morinig</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>summer</th>\n",
       "      <th>autumn</th>\n",
       "      <th>winter</th>\n",
       "      <th>spring</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>g_std</th>\n",
       "      <th>b_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182</td>\n",
       "      <td>12</td>\n",
       "      <td>49.368139</td>\n",
       "      <td>52.525261</td>\n",
       "      <td>74.227846</td>\n",
       "      <td>116.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.820694</td>\n",
       "      <td>99.457378</td>\n",
       "      <td>107.34849</td>\n",
       "      <td>72.297118</td>\n",
       "      <td>68.99498</td>\n",
       "      <td>71.298567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration    w     h  weight_to_height  forwards_to_views  second  minute  \\\n",
       "0        15  720  1280            0.5625           0.003226      43      23   \n",
       "\n",
       "   hour  day_of_week  day_of_year  month  positive  negative  neutral  skip  \\\n",
       "0    11            0          255      9       0.0       0.0      0.0   0.0   \n",
       "\n",
       "   speech  💵in_msg  🤩in_msg  🎇in_msg  🐰in_msg  👆🏻in_msg  🌐in_msg  🌵in_msg  \\\n",
       "0     0.0        0        0        0        0         0        0        0   \n",
       "\n",
       "   🦐in_msg  🦞in_msg  👨‍💼in_msg  ⏳in_msg  👨‍🦱in_msg  🧤in_msg  🥃in_msg  \\\n",
       "0        0        0          0        0          0        0        0   \n",
       "\n",
       "   🙌🏻in_msg  😄in_msg  🇨🇭in_msg  🎨in_msg  👖in_msg  🇬🇹in_msg  👉in_msg  🌴in_msg  \\\n",
       "0         0        0         0        0        0         0        0        0   \n",
       "\n",
       "   🐌in_msg  🔸in_msg  🇶🇦in_msg  👁in_msg  🐊in_msg  🥳in_msg  🤷in_msg  🇦🇪in_msg  \\\n",
       "0        0        0         0        0        0        0        0         0   \n",
       "\n",
       "   🍽in_msg  🧙in_msg  📸in_msg  🪴in_msg  🇸🇮in_msg  🧼in_msg  🔉in_msg  ☄in_msg  \\\n",
       "0        0        0        0        0         0        0        0        0   \n",
       "\n",
       "   👇🏻in_msg  🧐in_msg  🙈in_msg  ⛷in_msg  🍄in_msg  👈in_msg  🏒in_msg  😮in_msg  \\\n",
       "0         0        0        0        0        0        0        0        0   \n",
       "\n",
       "   🗺in_msg  🗿in_msg  🧔in_msg  ⛸in_msg  🥤in_msg  🔬in_msg  ▶️in_msg  🦑in_msg  \\\n",
       "0        0        0        0        0        0        0         0        0   \n",
       "\n",
       "   🚿in_msg  🥕in_msg  🇳🇦in_msg  ❗in_msg  🏺in_msg  🐍in_msg  ✔️in_msg  🦝in_msg  \\\n",
       "0        0        0         0        0        0        0         0        0   \n",
       "\n",
       "   💐in_msg  🦒in_msg  🚉in_msg  🦍in_msg  🇭🇰in_msg  🇵🇪in_msg  🇦🇱in_msg  \\\n",
       "0        0        0        0        0         0         0         0   \n",
       "\n",
       "   👱‍♂in_msg  👇in_msg  🥺in_msg  🇸🇰in_msg  ⛵in_msg  💁‍♂in_msg  🗨in_msg  \\\n",
       "0          0        0        0         0        0          0        0   \n",
       "\n",
       "   🇳🇴in_msg  🇸🇪in_msg  🍂in_msg  💔in_msg  🤟in_msg  🇧🇷in_msg  💣in_msg  🏝️in_msg  \\\n",
       "0         0         0        0        0        0         0        0         0   \n",
       "\n",
       "   📱in_msg  🐞in_msg  🦘in_msg  🍯in_msg  👑in_msg  👥in_msg  🐈in_msg  🌘in_msg  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   👕in_msg  🧘🏻‍♂️in_msg  🟡in_msg  🎗in_msg  🛩in_msg  🏠in_msg  🐒in_msg  ✅in_msg  \\\n",
       "0        0            0        0        0        0        0        0        0   \n",
       "\n",
       "   🇲🇦in_msg  🍑in_msg  💧in_msg  👠in_msg  ☮️in_msg  🗼in_msg  🇮🇶in_msg  🔥in_msg  \\\n",
       "0         0        0        0        0         0        0         0        0   \n",
       "\n",
       "   🦛in_msg  ☄️in_msg  😻in_msg  🎟in_msg  🇪🇨in_msg  🇾🇪in_msg  💁‍♂️in_msg  \\\n",
       "0        0         0        0        0         0         0           0   \n",
       "\n",
       "   💚in_msg  🙄in_msg  🐭in_msg  🌒in_msg  👨🏻‍🏫in_msg  🇲🇹in_msg  😤in_msg  \\\n",
       "0        0        0        0        0           0         0        0   \n",
       "\n",
       "   🇨🇿in_msg  🎭in_msg  🐇in_msg  🎓in_msg  🤷‍♀️in_msg  ✌🏽in_msg  🤪in_msg  \\\n",
       "0         0        0        0        0           0         0        0   \n",
       "\n",
       "   👁️in_msg  📈in_msg  🅾in_msg  🎠in_msg  🦆in_msg  ...  word_number_192  \\\n",
       "0         0        0        0        0        0  ...              0.0   \n",
       "\n",
       "   word_number_193  word_number_194  word_number_195  word_number_196  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_197  word_number_198  word_number_199  word_number_200  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_201  word_number_202  word_number_203  word_number_204  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_205  word_number_206  word_number_207  word_number_208  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_209  word_number_210  word_number_211  word_number_212  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_213  word_number_214  word_number_215  word_number_216  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_217  word_number_218  word_number_219  word_number_220  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_221  word_number_222  word_number_223  MessageEntityUnderline  \\\n",
       "0              0.0              0.0              0.0                       0   \n",
       "\n",
       "   MessageEntityStrike  MessageEntityUrl  MessageEntityBold  \\\n",
       "0                    0                 0                  0   \n",
       "\n",
       "   MessageEntityCode  MessageEntityHashtag  MessageEntityCustomEmoji  \\\n",
       "0                  0                     0                         0   \n",
       "\n",
       "   MessageEntityMention  MessageEntityEmail  MessageEntityTextUrl  \\\n",
       "0                     0                   0                     0   \n",
       "\n",
       "   MessageEntityItalic  MessageEntitySpoiler  word_number_224  \\\n",
       "0                    0                     0              0.0   \n",
       "\n",
       "   word_number_225  word_number_226  word_number_227  word_number_228  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_229  word_number_230  word_number_231  word_number_232  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_233  word_number_234  word_number_235  word_number_236  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_237  word_number_238  word_number_239  word_number_240  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_241  word_number_242  word_number_243  word_number_244  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_245  word_number_246  word_number_247  word_number_248  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_249  word_number_250  word_number_251  word_number_252  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_253  word_number_254  word_number_255  word_number_256  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_257  word_number_258  word_number_259  word_number_260  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_261  word_number_262  word_number_263  word_number_264  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_265  word_number_266  word_number_267  word_number_268  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_269  word_number_270  word_number_271  word_number_272  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_273  word_number_274  word_number_275  word_number_276  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_277  word_number_278  word_number_279  word_number_280  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_281  word_number_282  word_number_283  word_number_284  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_285  word_number_286  word_number_287  word_number_288  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_289  word_number_290  word_number_291  word_number_292  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_293  word_number_294  word_number_295  word_number_296  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_297  word_number_298  word_number_299  word_number_300  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   word_number_301  dtdays  day_of_month      h_std      s_std      v_std  \\\n",
       "0              0.0     182            12  49.368139  52.525261  74.227846   \n",
       "\n",
       "   h_median  s_median  v_median  h_min  s_min  v_min  h_max  s_max  s_max.1  \\\n",
       "0     116.0      73.0     131.0      0      0      0    179    255      255   \n",
       "\n",
       "   morinig  day  evening  night  summer  autumn  winter  spring      r_mean  \\\n",
       "0        1    0        0      0       0       1       0       0  109.820694   \n",
       "\n",
       "      g_mean     b_mean      r_std     g_std      b_std  \n",
       "0  99.457378  107.34849  72.297118  68.99498  71.298567  \n",
       "\n",
       "[1 rows x 1345 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting rid of emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = grand_df['list_of_count_colors'] <= 392824  \n",
    "\n",
    "mask_2 = grand_df['re_lemmas_count'] <= 301\n",
    "\n",
    "mask_3 = grand_df['duration'] <= 70\n",
    "\n",
    "mask_4 = grand_df['forwards_to_views'] <= grand_df['forwards_to_views'].max() * 0.075\n",
    "\n",
    "mask_5 = grand_df['forwards_to_views'] >= grand_df['forwards_to_views'].min() * 50\n",
    "\n",
    "mask_6 = grand_df['list_of_count_colors'] >= 3 \n",
    "\n",
    "grand_df = grand_df[mask_1 & mask_2 & mask_3 & mask_4 & mask_5 & mask_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30503, 1345)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\190676265.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grand_df['forwards_to_views'] = np.log10(grand_df['forwards_to_views']) / np.log10(base)\n"
     ]
    }
   ],
   "source": [
    "base = 1000\n",
    "\n",
    "grand_df['forwards_to_views'] = np.log10(grand_df['forwards_to_views']) / np.log10(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\1461426068.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grand_df['list_of_count_colors'] = np.log10(grand_df['list_of_count_colors'] + 1) / np.log10(base)\n",
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\1461426068.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grand_df['re_lemmas_count'] = np.log10(grand_df['re_lemmas_count'] + 1) / np.log10(base)\n",
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\1461426068.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grand_df['duration'] = np.log10(grand_df['duration'] + 1) / np.log10(base)\n"
     ]
    }
   ],
   "source": [
    "grand_df['list_of_count_colors'] = np.log10(grand_df['list_of_count_colors'] + 1) / np.log10(base)\n",
    "\n",
    "grand_df['re_lemmas_count'] = np.log10(grand_df['re_lemmas_count'] + 1) / np.log10(base)\n",
    "\n",
    "grand_df['duration'] = np.log10(grand_df['duration'] + 1) / np.log10(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\50662512.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grand_df.drop_duplicates(inplace=True, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "grand_df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'forwards_to_views'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_scal = grand_df.drop([target], axis=1).columns\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# grand_df[cols_scal] = pd.DataFrame(scaler.fit_transform(grand_df[cols_scal]), columns=cols_scal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_number_285', 'word_number_286', 'word_number_287',\n",
       "       'word_number_288', 'word_number_289', 'word_number_290',\n",
       "       'word_number_291', 'word_number_292', 'word_number_293',\n",
       "       'word_number_294', 'word_number_295', 'word_number_296',\n",
       "       'word_number_297', 'word_number_298', 'word_number_299',\n",
       "       'word_number_300', 'word_number_301', 'dtdays', 'day_of_month', 'h_std',\n",
       "       's_std', 'v_std', 'h_median', 's_median', 'v_median', 'h_min', 's_min',\n",
       "       'v_min', 'h_max', 's_max', 'v_max', 'morinig', 'day', 'evening',\n",
       "       'night', 'summer', 'autumn', 'winter', 'spring', 'r_mean', 'g_mean',\n",
       "       'b_mean', 'r_std', 'g_std', 'b_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_df.columns[1300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_df.rename(columns={\"s_max.1\": \"v_max\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8304539 , -0.87612964, -0.67510196, ..., -0.66158888,\n",
       "       -0.75870708, -0.78183209])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(grand_df[target])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = grand_df.drop([target,'dtdays'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_train, y_train_predict, y_test, y_test_predict):\n",
    "    \n",
    "    print('Train R^2: {:.3f}'.format(metrics.r2_score(y_train, y_train_predict)))\n",
    "    \n",
    "    print('Train MAE: {:.3f}'.format(metrics.mean_absolute_error(y_train, y_train_predict)))\n",
    "    \n",
    "    print('Train MAPE: {:.3f}'.format(metrics.mean_absolute_percentage_error(y_train, y_train_predict)*100))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('Test R^2: {:.3f}'.format(metrics.r2_score(y_test, y_test_predict)))\n",
    "    \n",
    "    print('Test MAE: {:.3f}'.format(metrics.mean_absolute_error(y_test, y_test_predict)))\n",
    "    \n",
    "    print('Test MAPE: {:.3f}'.format(metrics.mean_absolute_percentage_error(y_test, y_test_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "X_test.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Local\\Temp\\ipykernel_22620\\1280981934.py:9: RuntimeWarning: overflow encountered in power\n",
      "  print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.184\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 36.956\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon3.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_train_pred \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_test_pred \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m print_metrics(base \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m (y_train), base \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m y_train_pred, base \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m (y_test), base \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m y_test_pred)\n",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon3.ipynb Cell 23\u001b[0m in \u001b[0;36mprint_metrics\u001b[1;34m(y_train, y_train_predict, y_test, y_test_predict)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain MAPE: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(metrics\u001b[39m.\u001b[39mmean_absolute_percentage_error(y_train, y_train_predict)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest R^2: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(metrics\u001b[39m.\u001b[39;49mr2_score(y_test, y_test_predict)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest MAE: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(metrics\u001b[39m.\u001b[39mmean_absolute_error(y_test, y_test_predict)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest MAPE: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(metrics\u001b[39m.\u001b[39mmean_absolute_percentage_error(y_test, y_test_predict)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[0;32m    785\u001b[0m     y_true,\n\u001b[0;32m    786\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m ):\n\u001b[0;32m    792\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model.Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.007\n",
      "Train MAE: 0.003\n",
      "Train MAPE: 42.681\n",
      "\n",
      "\n",
      "Test R^2: 0.005\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 42.457\n"
     ]
    }
   ],
   "source": [
    "model_with_reg =  linear_model.Lasso(max_iter = 4000)\n",
    "\n",
    "model_with_reg.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = (model_with_reg.predict(X_train))\n",
    "\n",
    "y_test_pred = (model_with_reg.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model.Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.178\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 37.276\n",
      "\n",
      "\n",
      "Test R^2: 0.109\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 38.543\n"
     ]
    }
   ],
   "source": [
    "model_with_reg =  linear_model.Ridge(alpha = 1, max_iter = 10000)\n",
    "\n",
    "model_with_reg.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = (model_with_reg.predict(X_train))\n",
    "\n",
    "y_test_pred = (model_with_reg.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5963,), (5964, 1), (5964, 1))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred).shape , y_test_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model_with_reg_ridge.pkl', 'wb') as output:\n",
    "    \n",
    "    pickle.dump(model_with_reg, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.168\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 37.632\n",
      "\n",
      "\n",
      "Test R^2: 0.104\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 39.270\n"
     ]
    }
   ],
   "source": [
    "regr1 = DecisionTreeRegressor(max_depth=10, min_samples_leaf = 105, random_state=42)\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr1.predict(X_train))\n",
    "\n",
    "y_test_pred = (regr1.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), (base ** y_train_pred), base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120,), (5964,), (5964, 1))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred).shape , y_test_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.093\n",
      "Train MAE: 0.003\n",
      "Train MAPE: 39.817\n",
      "\n",
      "\n",
      "Test R^2: 0.076\n",
      "Test MAE: 129.594\n",
      "Test MAPE: 40.136\n"
     ]
    }
   ],
   "source": [
    "regr1 = DecisionTreeRegressor(max_depth=5, min_samples_leaf = 5, min_samples_split = 2, random_state=42)\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr1.predict(X_train))\n",
    "\n",
    "y_test_pred = (regr1.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), (base ** y_train_pred), np.round(base ** (y_test) * 50000), np.round(base ** y_test_pred * 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 11:26:38,917]\u001b[0m A new study created in memory with name: DecisionTreeRegressor\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon3.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# ищем лучшую комбинацию гиперпараметров n_trials раз\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mFATAL)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(optuna_rf, n_trials\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon3.ipynb Cell 27\u001b[0m in \u001b[0;36moptuna_rf\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m DecisionTreeRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                               \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                               max_depth\u001b[39m=\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                               random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                               )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# обучаем модель\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_absolute_percentage_error(base \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m y_test, base \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon3.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:172\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    170\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 172\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    173\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    176\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:591\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    590\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 591\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    592\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    593\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 100, 1)\n",
    "  \n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 1000, 1)\n",
    "  \n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 100, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = DecisionTreeRegressor(\n",
    "                                \n",
    "                                max_depth=max_depth,\n",
    "                                \n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                \n",
    "                                min_samples_split=min_samples_split,\n",
    "                                \n",
    "                                random_state=42\n",
    "                                \n",
    "                                )\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = metrics.mean_absolute_percentage_error(base ** y_test, base ** model.predict(X_test)) * 100\n",
    "\n",
    "  return score\n",
    "\n",
    "%time\n",
    "\n",
    "# cоздаем объект исследования\n",
    "\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "\n",
    "study = optuna.create_study(study_name=\"DecisionTreeRegressor\", direction=\"minimize\")\n",
    "\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "\n",
    "study.optimize(optuna_rf, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.150\n",
      "Train MAE: 0.003\n",
      "Train MAPE: 38.745\n",
      "\n",
      "\n",
      "Test R^2: 0.125\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 40.217\n"
     ]
    }
   ],
   "source": [
    "regr1 = DecisionTreeRegressor(max_depth=study.best_params['max_depth'], min_samples_leaf = study.best_params['min_samples_leaf'],  min_samples_split = study.best_params['min_samples_split'], random_state=42)\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr1.predict(X_train))\n",
    "\n",
    "y_test_pred = (regr1.predict(X_test))\n",
    "\n",
    "# print_metrics(1 * (y_train), (1 * y_train_pred), 1 * (y_test), 1 * y_test_pred)\n",
    "\n",
    "print_metrics(base ** y_train, base ** y_train_pred, base ** y_test, base ** y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.204\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 36.432\n",
      "\n",
      "\n",
      "Test R^2: 0.150\n",
      "Test MAE: 0.002\n",
      "Test MAPE: 37.884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(\n",
    "\n",
    "    max_depth = 3,\n",
    "\n",
    "    min_samples_leaf = 10,\n",
    "\n",
    "    n_estimators = 200,\n",
    "\n",
    "    random_state = 42 \n",
    "\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# gb_pred  = gb.predict(X_test)\n",
    "\n",
    "\n",
    "y_train_pred = (gb.predict(X_train))\n",
    "\n",
    "y_test_pred = (gb.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5953,), (5964,), (5964, 1))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_pred).shape , y_test_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gb.pkl', 'wb') as output:\n",
    "    \n",
    "    pickle.dump(gb, output)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.473\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 27.764\n",
      "\n",
      "\n",
      "Test R^2: 0.159\n",
      "Test MAE: 0.002\n",
      "Test MAPE: 37.536\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgbt = XGBRegressor(random_state = 26)\n",
    "\n",
    "xgbt.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = xgbt.predict(X_train)\n",
    "\n",
    "y_test_pred = xgbt.predict(X_test)\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.393\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 30.649\n",
      "\n",
      "\n",
      "Test R^2: 0.190\n",
      "Test MAE: 0.002\n",
      "Test MAPE: 36.789\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cbr = CatBoostRegressor(verbose=False, random_state=42, loss_function='RMSE')\n",
    "\n",
    "cbr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = cbr.predict(X_train)\n",
    "\n",
    "y_test_pred = cbr.predict(X_test)\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best regressor is ... CatBoostRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model for predict in bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cbr.pkl', 'wb') as output:\n",
    "    \n",
    "    pickle.dump(cbr, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.80081066, 4.26186608, 5.04402081, ..., 1.22038802, 0.7422953 ,\n",
       "       0.66445054])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbr.feature_importances_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'features': list(grand_df.drop([target,'dtdays'], axis=1).columns), 'importance': cbr.feature_importances_}).sort_values(by='importance', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h</td>\n",
       "      <td>5.044021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>4.261866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>MessageEntityTextUrl</td>\n",
       "      <td>3.790689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>MessageEntityBold</td>\n",
       "      <td>3.518880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_of_year</td>\n",
       "      <td>3.357995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>minute</td>\n",
       "      <td>2.959939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>list_of_count_colors</td>\n",
       "      <td>2.414779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>positive</td>\n",
       "      <td>2.340904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>second</td>\n",
       "      <td>2.239669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>word_number_4</td>\n",
       "      <td>2.189590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>negative</td>\n",
       "      <td>2.154013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>word_number_2</td>\n",
       "      <td>1.932985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>skip</td>\n",
       "      <td>1.850047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hour</td>\n",
       "      <td>1.805748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>1.800811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight_to_height</td>\n",
       "      <td>1.783129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.742538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>speech</td>\n",
       "      <td>1.712102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>blue-green</td>\n",
       "      <td>1.657100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>🐻in_msg</td>\n",
       "      <td>1.462174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>word_number_1</td>\n",
       "      <td>1.421729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>🌍in_msg</td>\n",
       "      <td>1.293081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>green</td>\n",
       "      <td>1.232643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>r_std</td>\n",
       "      <td>1.220388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>pink_3</td>\n",
       "      <td>1.123327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.010065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>word_number_3</td>\n",
       "      <td>1.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>s_median</td>\n",
       "      <td>0.956739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>word_number_5</td>\n",
       "      <td>0.938662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.935205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  importance\n",
       "2                        h    5.044021\n",
       "1                        w    4.261866\n",
       "1235  MessageEntityTextUrl    3.790689\n",
       "1229     MessageEntityBold    3.518880\n",
       "8              day_of_year    3.357995\n",
       "5                   minute    2.959939\n",
       "998   list_of_count_colors    2.414779\n",
       "10                positive    2.340904\n",
       "4                   second    2.239669\n",
       "1006         word_number_4    2.189590\n",
       "11                negative    2.154013\n",
       "1004         word_number_2    1.932985\n",
       "13                    skip    1.850047\n",
       "6                     hour    1.805748\n",
       "0                 duration    1.800811\n",
       "3         weight_to_height    1.783129\n",
       "12                 neutral    1.742538\n",
       "14                  speech    1.712102\n",
       "985             blue-green    1.657100\n",
       "832                🐻in_msg    1.462174\n",
       "1003         word_number_1    1.421729\n",
       "903                🌍in_msg    1.293081\n",
       "994                  green    1.232643\n",
       "1340                 r_std    1.220388\n",
       "992                 pink_3    1.123327\n",
       "989                 orange    1.010065\n",
       "1005         word_number_3    1.001038\n",
       "1321              s_median    0.956739\n",
       "1007         word_number_5    0.938662\n",
       "984                   blue    0.935205"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 128059 (\\N{BEAR FACE}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\Arwielao\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 127757 (\\N{EARTH GLOBE EUROPE-AFRICA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAAKCCAYAAAAnY357AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAADGBUlEQVR4nOzdd3htVbWw8XcgoihWwC5i91o/FXsBsaCIDRWxAhb0WlGvvYH92rteLGDDggVFBRUQuwKCXUGl2EDABlhAOOP7Y6xN9snZyclJ5lo7Ce/vefKcZO991lgrWXXMOceMzESSJEmSJEmSpNY2mvYKSJIkSZIkSZJWJxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvdh42iswly222CK33nrraa+GJEmSJEmSJGkeP/jBD87MzC0nvbdsE9Bbb701xxxzzLRXQ5IkSZIkSZI0j4g4Za73LMEhSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL3pNQEfEdhGRE77+1mdcSZIkSZIkSdL0bTxQnKcDR4/9fP6G/Ocz3v2RtmszZsv/flRvy5YkSZIkSZKki7KhEtC/yMzvDRRLkiRJkiRJkrQMWANakiRJkiRJktSLoRLQH42ICyLizxFxQERsNVBcSZIkSZIkSdKU9F2C4+/AG4GvA2cBtwReCHw3Im6ZmaePfzgi9gT2BNhqK3PUkiRJkiRJkrSS9ZqAzszjgOPGXvp6RHwDOIqamPDFsz6/L7AvwDbbbJN9rpskSZIkSZIkqV+D14DOzGOBE4DbDB1bkiRJkiRJkjScaU5CaA9nSZIkSZIkSVrFBk9AR8Q2wA2pMhySJEmSJEmSpFWq1xrQEfFR4CTgWOBv1CSELwD+ALytz9iSJEmSJEmSpOnqNQEN/BR4OPA04FLAacBngJdl5pk9x5YkSZIkSZIkTVGvCejMfA3wmj5jSJIkSZIkSZKWp2lOQihJkiRJkiRJWsVMQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRebDztFViOznjPvr0sd8sn7dnLciVJkiRJkiRpObIHtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1YtAEdEQcGhEZEa8cMq4kSZIkSZIkaXiDJaAj4uHALYaKJ0mSJEmSJEmarkES0BFxBeDNwLOGiCdJkiRJkiRJmr6hekD/L/DTzPzYQPEkSZIkSZIkSVO2cd8BIuLOwGOw/IYkSZIkSZIkXaT02gM6IjYB/g94Q2Yev4DP7xkRx0TEMWeccUafqyZJkiRJkiRJ6lnfJTieC2wKvGohH87MfTNzm8zcZsstt+x3zSRJkiRJkiRJveqtBEdEbAW8CHg8cImIuMTY25eIiMsDZ2fmBX2tgyRJkiRJkiRpevrsAX0d4JLAR4C/jn0B/E/3/c16jC9JkiRJkiRJmqI+JyH8IXC3Ca9/jUpKvx/4dY/xJUmSJEmSJElT1FsCOjP/Bhw5+/WIADglM9d5T5IkSZIkSZK0evQ9CaEkSZIkSZIk6SKqzxIcE2VmDB1TkiRJkiRJkjQ8e0BLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6sfG0V0Dwp3e/sZflXvm/n93LciVJkiRJkiRpIewBLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRebDztFdDwTn3XC3tZ7lWf/OpelitJkiRJkiRpZbIHtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknqx8bRXQKvf797+yF6We82nfbSX5UqSJEmSJElqwx7QkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSetFrAjoidoiIIyLitIg4NyJ+HxGfjIgb9xlXkiRJkiRJkjR9G/e8/CsCPwDeBZwBbAU8H/heRNwsM0/pOb4kSZIkSZIkaUp6TUBn5seAj42/FhFHAb8EHgK8sc/4kiRJkiRJkqTpmUYN6D93/54/hdiSJEmSJEmSpIEMkoCOiItFxCYRcX3g/4DTmNUzWpIkSZIkSZK0ugzVA/r7wLnACcDNge0z8/TZH4qIPSPimIg45owzzhho1SRJkiRJkiRJfRgqAf1o4PbAI4CzgK9GxNazP5SZ+2bmNpm5zZZbbjnQqkmSJEmSJEmS+jBIAjozf5GZ3+8mJbw7sBnw/CFiS5IkSZIkSZKmY+OFfjAirgVcPzMPi4hNgY0z8+wNDZiZf4uIXwPX29D/Ky3EL9/5gF6We6OnfK6X5UqSJEmSJEmr1YJ6QEfEE4BPURMIAlwDOGgxASPiysCNgN8s5v9LkiRJkiRJklaGhfaAfgpwW2oyQTLzVxFxpfX9p4j4LHAs8GOq9vMNgGcC5wNvXMwKS5IkSZIkSZJWhoUmoM/NzPMiAoCI2BjIBfy/7wG7AM8GNgF+BxwJvCYzT97QlZUkSZIkSZIkrRwLTUB/PSJeCGwaEfcEngwcvL7/lJn/C/zvEtZPkiRJkiRJkrRCLagGNPB84AzgJ8ATgS8BL+5rpSRJkiRJkiRJK99Ce0BvCnwgM98LEBEX6177Z18rJkmSJEmSJEla2RbaA/pwKuE8silwWPvVkSRJkiRJkiStFgtNQF8yM88Z/dB9f6l+VkmSJEmSJEmStBosNAH9j4i41eiHiLg18K9+VkmSJEmSJEmStBostAb0XsCBEfFHIICrAA/ra6UkSZIkSZIkSSvfghLQmXl0RNwIuGH30vGZ+Z/+VkuSJEmSJEmStNIttAc0wG2Arbv/c6uIIDM/1MtaSZIkSZIkSZJWvAUloCPiw8B1gR8CF3QvJ2ACWpIkSZIkSZI00UJ7QG8D3Dgzs8+VkSRJkiRJkiStHhst8HM/pSYelCRJkiRJkiRpQRbaA3oL4OcRcRRw7ujFzLx/L2slSZIkSZIkSVrxFpqA3rvPlZAkSZIkSZIkrT4LSkBn5tf7XhFJkiRJkiRJ0uqyoBrQEXH7iDg6Is6JiPMi4oKIOKvvlZMkSZIkSZIkrVwLnYTwHcDDgV8BmwKPB97Z10pJkiRJkiRJkla+hSagycxfAxfLzAsycz/g3v2tliRJkiRJkiRppVvoJIT/jIhNgB9GxOuAU9mA5LUkSZIkSZIk6aJnoUnkR3effSrwD+CawM59rZQkSZIkSZIkaeVbaAL6gZn578w8KzP3ycxnATv1uWKSJEmSJEmSpJVtoQno3Sa8tnvD9ZAkSZIkSZIkrTLz1oCOiIcDjwCuExGfH3vrMsBf+lwxSZIkSZIkSdLKtr5JCL9DTTi4BfDGsdfPBn7c10pJkiRJkiRJkla+eRPQmXlKRPwe+Hdmfn2gdZIkSZIkSZIkrQLrrQGdmRcAayLicgOsjyRJkiRJkiRplVhfCY6Rc4CfRMRXgX+MXszMp/eyVpIkSZIkSZKkFW+hCejPdF+SJEmSJEmSJC3IghLQmfnBiNgEuEH30vGZ+Z/+VkuSJEmSJEmStNItKAEdEdsBHwROBgK4ZkTslpnf6G3NJEmSJEmSJEkr2kJLcLwRuFdmHg8QETcAPgbcuq8VkyRJkiRJkiStbBst8HMXHyWfATLzBODi/aySJEmSJEmSJGk1WGgP6GMi4n3AR7qfHwkc088qSZIkSZIkSZJWg4UmoP8beArw9O7nbwLv6mWNJEmSJEmSJEmrwoIS0Jl5bkS8AzgcWAMcn5nn9bpmkiRJkiRJkqQVbUEJ6Ii4L/Ae4DdAANeOiCdm5iF9rpwkSZIkSZIkaeVaaAmONwJ3y8xfA0TEdYEvAiagJUmSJEmSJEkTbbTAz509Sj53TgTO7mF9JEmSJEmSJEmrxEJ7QB8TEV8CPgkk8FDg6IjYGSAzP9PT+kmSJEmSJEmSVqiFJqAvCfwJ2Lb7+QxgU+B+VELaBLQkSZIkSZIkaS0LSkBn5h59r4gkSZIkSZIkaXVZUAI6Iq4NPA3Yevz/ZOb9+1ktaeU49j3362W5t3rSwb0sV5IkSZIkSRrKQktwHAS8HzgYWNPb2kiSJEmSJEmSVo2FJqD/nZlv63VNJEmSJEmSJEmrykIT0G+NiJcBXwHOHb2Ymcf2slaSJEmSJEmSpBVvoQnomwGPBrZnpgRHdj9LkiRJkiRJkrSOhSagHwpcJzPP63NlJEmSJEmSJEmrx0IT0D8FLg+c3t+qSFqIb++7Uy/LvdOeX+hluZIkSZIkSbroWmgC+vLALyPiaNauAX3/PlZKkiRJkiRJkrTyLTQB/bJe10KSJEmSJEmStOosKAGdmV/ve0UkSZIkSZIkSavLvAnoiPhWZt45Is4GcvwtIDPzsr2unSRJkiRJkiRpxZo3AZ2Zd+7+vcwwqyNJkiRJkiRJWi02mvYKSJIkSZIkSZJWJxPQkiRJkiRJkqReLGgSQkkXTYe9b8feln2Px3+pt2VLkiRJkiRpebAHtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi+chFDSsvGFD9ynt2Xv9NhDelu2JEmSJEmSJrMHtCRJkiRJkiSpF/aAlnSR9an97t3bsh+yx6G9LVuSJEmSJGmlsAe0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF70loCOiIdExKcj4pSI+FdEHB8Rr4mIy/QVU5IkSZIkSZK0fPTZA/p/gAuAFwL3Bt4N/Dfw1Yiw57UkSZIkSZIkrXIb97js+2XmGWM/fz0i/gJ8ENgOOKLH2JIkSZIkSZKkKeutJ/Ks5PPI0d2/V+8rriRJkiRJkiRpeRi6FMa23b+/GDiuJEmSJEmSJGlggyWgI+LqwMuBwzLzmDk+s2dEHBMRx5xxxqQO1JIkSZIkSZKklWKQBHREbAZ8Djgf2GOuz2Xmvpm5TWZus+WWWw6xapIkSZIkSZKknvQ5CSEAEbEpcDBwHWDbzPx93zElSZIkSZIkSdPXawI6Ii4OfArYBrhnZv6kz3iSJEmSJEmSpOWjtwR0RGwEfBTYHtgpM7/XVyxJkiRJkiRJ0vLTZw/odwIPBV4F/CMibj/23u8txSFJkiRJkiRJq1ufCej7dP++qPsatw+wd4+xJWnZ+cj+O/Sy3Eft/uVelitJkiRJkrRUvSWgM3PrvpYtSZIkSZIkSVr+Npr2CkiSJEmSJEmSVicT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXvU1CKEmarvd/aIdelvu4x3y5l+VKkiRJkqTVxx7QkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRfWgJYkNfHOj/RTc/opj5pcc/oNH+sn3v883BrXkiRJkiS1Yg9oSZIkSZIkSVIv7AEtSdIC7P3Jfnpc772LPa4lSZIkSauXPaAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUlOCRJWob2+vS9e1nuWx58aC/LlSRJkiRpEntAS5IkSZIkSZJ6YQJakiRJkiRJktQLS3BIkiR2+Vw/JT8++QBLfkiSJEnSRZk9oCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvrAEtSZIGdZ/PPa63ZR/ygPf3tmxJkiRJ0oazB7QkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF5sPO0VkCRJ6tOOBz2vt2V/6YH/29uyJUmSJGk1sAe0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oU1oCVJkhra8bOv7G3ZX3rQi3tbtiRJkiT1wR7QkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXmw87RWQJEnS4t33M2/sZblf3PnZvSxXkiRJ0kWLPaAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ64SSEkiRJWrD7fuYdvSz3izs/tZflSpIkSZouE9CSJElatu776X17We4XH7xnL8uVJEmStDZLcEiSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqxcbTXgFJkiRpudjp0/v3stwvPHj3XpYrSZIkLXf2gJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSepFrwnoiLhGRLw9Ir4bEf+MiIyIrfuMKUmSJEmSJElaHvruAX09YBfgr8A3e44lSZIkSZIkSVpG+k5AfyMzr5yZOwIH9hxLkiRJkiRJkrSM9JqAzsw1fS5fkiRJkiRJkrR8bTztFZAkSZIuqnb61Ed7We4XHvLIXpYrSZIkbahllYCOiD2BPQG22mqrKa+NJEmStLrs9KlP9rLcLzxkl16WK0mSpJWv7xrQGyQz983MbTJzmy233HLaqyNJkiRJkiRJWoJllYCWJEmSJEmSJK0eJqAlSZIkSZIkSb1YVjWgJUmSJK0e9/vUQb0s9+CHPLCX5UqSJKm93hPQEfGQ7ttbd//eJyLOAM7IzK/3HV+SJEnS6veAT32pt2V/7iE79rZsSZKk1W6IHtAHzvr5Xd2/Xwe2GyC+JEmSJDX1wE8d1tuyD3rIPdZ57UGf/lZv8T774Duv89qDP31ML7E+/eBtelmuJElavnpPQGdm9B1DkiRJkiRJkrT8OAmhJEmSJEmSJKkXTkIoSZIkSZqqXT79816W+8kH33ji63t85re9xNtv5616Wa4kSSuZCWhJkiRJknq092f/2M9yH3S1XpYrSVJLluCQJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhZMQSpIkSZK0irzzs3/qZblPedCVe1muJGl1swe0JEmSJEmSJKkX9oCWJEmSJEmL9tFPn9HLch/54C0nvv75A8/sJd79H7pFL8uVpIs6e0BLkiRJkiRJknphD2hJkiRJkqQJDjugn97dAPd4xOQe3pK02piAliRJkiRJWga+86H+Et53fIwJb0nTYQJakiRJkiTpIui4953e27Jv+fgrrfPa8e/8Uy+xbviUK/eyXEltmICWJEmSJEnSqvO7N57Wy3Kv+eyrTHz9tNef3Eu8qzxn616WKw3FBLQkSZIkSZK0wpz2pp/3styrPOvGvSxXF10moCVJkiRJkiTN609v+UEvy73yXrfuZblaPjaa9gpIkiRJkiRJklYne0BLkiRJkiRJWlb+9NZv97LcKz/jThNfP/3tR/QS70pP237dWO/4Ui+xAK701B17W/ZimYCWJEmSJEmSpFXq9Hd+prdlX+kpO6/3M5bgkCRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1wgS0JEmSJEmSJKkXJqAlSZIkSZIkSb0wAS1JkiRJkiRJ6oUJaEmSJEmSJElSL0xAS5IkSZIkSZJ6YQJakiRJkiRJktQLE9CSJEmSJEmSpF6YgJYkSZIkSZIk9cIEtCRJkiRJkiSpFyagJUmSJEmSJEm9MAEtSZIkSZIkSeqFCWhJkiRJkiRJUi9MQEuSJEmSJEmSemECWpIkSZIkSZLUCxPQkiRJkiRJkqRemICWJEmSJEmSJPXCBLQkSZIkSZIkqRcmoCVJkiRJkiRJvTABLUmSJEmSJEnqhQloSZIkSZIkSVIvTEBLkiRJkiRJknphAlqSJEmSJEmS1AsT0JIkSZIkSZKkXpiAliRJkiRJkiT1otcEdERcMyI+FRF/j4izIuIzEbFVnzElSZIkSZIkSctDbwnoiLgUcARwI2A34NHA9YGvRcSl+4orSZIkSZIkSVoeNu5x2U8ArgPcMDN/DRARPwZ+BTwReFOPsSVJkiRJkiRJU9ZnCY77A98bJZ8BMvMk4NvAA3qMK0mSJEmSJElaBvpMQN8E+OmE138G3LjHuJIkSZIkSZKkZSAys58FR5wHvCkznz/r9VcCz8/Mdcp/RMSewJ7djzcEjl9E6C2AMxfx/xbLeMYz3kUj3mreNuMZz3jTi7eat814xjPe9OKt5m0znvGMN714q3nbjGc84y093rUyc8tJb/RZA3qDZea+wL5LWUZEHJOZ2zRaJeMZz3jGGzyW8YxnvItOvNW8bcYznvGmF281b5vxjGe86cVbzdtmPOMZr994fZbg+CtwhQmvX7F7T5IkSZIkSZK0ivWZgP4ZVQd6thsDP+8xriRJkiRJkiRpGegzAf154PYRcZ3RCxGxNXCn7r2+LKmEh/GMZzzjLYNYxjOe8S468VbzthnPeMabXrzVvG3GM57xphdvNW+b8YxnvB7j9TkJ4aWBHwH/Al4MJPAK4DLAzTPznF4CS5IkSZIkSZKWhd56QGfmP4DtgROADwMfBU4Ctjf5LEmSJEmSJEmrX289oCVJkiRJkiRJF2191oCWJEmSJEmSJF2EmYDeABFxn662tZYoIi4WEbeIiC2nvS6SJEmSJEmS+mECesN8EfhLRHwnIl4VEXePiEtOe6VWqASOAW457RXRyhQRl40Iz2FLFBHXi4hHRMRzun+vO+11Wmki4qURcbU53rtqRLx06HWSJEmLExH/HRE3mPZ69CUi7jXtdVAbEbFZRFwrIi4+7XWRpPVZFTWgI2I34OHAVsDshHBmZpOESkRcD7g7sB1wN+BKwLnAUcARwNcy8xstYl0URMSJwLMz87PTXpc+dMnRjTLz/LHXdgBuChyRmcdNbeUWKSI+sAEfz8x8XE/rcTngL8B2mfnNPmKMxbo5cFdgc+D/MvO07lzwp8w8u8HytwauDpyQmWdMeH8LYMfM/NBSY81a7iWBdwGPBi429tYFwAeBp2TmuY1ibQKcBuyemZ9vscwFxLwssCNzXxde0TDWBcAdMvOoCe/dGjgqMy+27v9cOYa6zg4tIraa5+01wN9bHOcLXJdbU8fdYxsuc2rbFxFXYfL+gvdKCxcRVweeTV2HrgjcPzN/GhF7Ad/NzO83iHFp4F7A+cCXM/O87hz6JOB6wK+B92XmX5Yaa0LsjYDbMve+0vratwnwKOA2VGeI7wMHZOZ/WsaZhoGve5sAL2DmunCJCfE2bhVvaBFxLrAxde9yJDPPeSdOc71aiYg1wInA/wH7ZeaZPcRYFs8Mq1VE7AS8HLgFdS67bWYeGxHvo54zD5jqCm6Aae8rEXEdYBfmPne6by5TQ173hhARNwEulZlHj712P+CFwP+jjvWjgL0z88ie16WXHMiKT0BHxEuAfYCfdl/rJEwyc4+eYt8Y2B54EJWUXpE3W+t5QF1HZv62UdznUSeMe2bmeS2WucC4vT/MdXE+AZybmY/pfn4SlfAD+A9w38w8rEWsWXFvCbyE2r7LM3ND8mrgG5l56BKWfTJ14hu5PHA56qH1z9QJamPg78BfM/M6S4g1XxJmU+DtwOuB4wEyc0NuXhYS/xLAR4CdgaC2+zbd7/IzVML4+UtY/sW75T+ke2kN8H6qUeYfY5+7HfCd1gnMiHgH8ATq/Plx4E/AlamHyZdSF5qnN4x3OvCozPxKq2XOE+tOwMHU/jlJtvx9dg9yt58jAX0P4POZeakGce66IZ9vleSb1nV2iKR397db343QicDrMvO9S423nnV5MPDJHvbNQbevu8Z+GNh20ts0OP6mdd8yx7pcFbg2cGJmntZ42TcBvkk1DH4XuC8z16E3A1fOzEcsMcY1gW8B1+xe+ilwT+Aw4MZUY+/mwG+BbVomqrr76IOA61L7xmxL2lci4ljg0Zn5s+7nK1DJxJsBo+vspYHjqAbtvhpjersvG4sx9HXvrcBTgEOAnzD5urBPq3gLWJ/NgZs0vO5tSv29tqOe9W5FjRz+HfA1KsH34RaxZsUdpEEmIrYDnkg9wwJ8hrrv+3qL5XcxTmagZ4Yu3kUm4R0RDwQ+DRwOfAV4HXV+PjYiXgTcNTN3aByzt31z6H1lVuwHAp+kju/TWfdcli3jjcXt/bowK96gSfaI2Jb57+Hv3iDGoNe9sbi9PZ9ExDeAw0fXz4h4CLV//ow63qHu0W4A3DszD5+4oCXoOwdCZq7oL+Bk4M0Dx7wUsAPwWuBo6uT4V+CgRstfQz1sLOTr/IHjXdDw9/hK4Pfd1/uAV1AtuaOvfXr4292Eepg6A/h8t0236t57M9ULplWsU4Bdx37+DbAvcBngY1RPitbbd2fg38DPgbd1f9vR9r2y1T46Fut31MXsYt1rFwMeRj2o3rHRfrlmjq/x95rtl2Px39Ad148Atpz1u3wCcNwSl/8/wL+om497d+eTfwI/Aq4y9rnb9bR9ZwIvnOO9FwFnNo63L7Bv6+2YI9bRwLHArYFNeoqx3di5atR48PJZX6/vjsWjG8Vc6Lm66THBdK6zL+m248fAAcB+s78axdmz274fdjH3pBpgftS9/lzgC93vdfeet/nBrY/1aWwfdW09g2rovReViF7rq0GMQe9bqAfTN1MPv38enTup6+p/ujjnA+9o/Pc7FPg2sBn18D1+HXoolfReaoz3UdfsewHbAF+negUfD1y7+8xNqOv9axtv35FUA8iDqYepa83+arCf3Hbs53cDZ1EdD0avPQg4G/jflts2tvxB7ssY4Lo3K94fgBf1HWcD1qf5+XPW8i8D3A/4Kv3dd94YOIG57337iLkF8Jwu7hrgF8AzgCs0jtPrM0O3vJOBk8a+/tpt03nAqd2/a7rXl3zu7GLu2J3HfgV8btJ20MN9PNVo9r7u+9nXhgcAf1ip++YQ+8qseD+hkvhbtlzuArZxkOf1bpkP7Pb/84E/zjpOTmp1PIzFe2K3TWcC36Ea7db6ahRn0OteF7PX55Pu/HSfWfvnJ+g6DnevBfBZ4Ns9bWO/OZAh/lA97wRnA9sPFOvlVC+Rc7u4h1AX7VtTpRZaxdkbeNlCvxrE2x3Yrfvaszu5/5R6SH1iF+dn3etPaLidcyUW+7zR6v1hbizWv4C7dN9fr4t18+7ne9E4wdct91vUDVBM2L6dgd82jHUU8OQ53nsKVXZgKcv/CfWAsyvrPpTevNu2XWjwkDpH/D9Qw+GhbnzGf5f3oFrgl7p9L5r12s2pG4HfMPPg31cC+mzgHnO8dw/grMbxHkTdUH6KGv58d6pX0YVfDWOdQ5Utafo7mxXjZePnqjnOYf+mbozu0CjmOom8+b4a7yuDXGfHYp7MAElv6ibrU3O892ngTd33H2aRN1xsQKK09bE+xPZNWO5fqV6nff7ddmfA+xbgqd3f5wDgHVQS85XU/eDLqJ7Jr6eS0bsuNd5Y3HOA+3Xfz74O3RX4Z4MYJwGPH/t5dH3dfdbnngn8tPHf8Sxg5x73k9kJ6D8yoeGVuu/+VU/rMMh9GQNc92bF+/vQ14X1rE8vCWjg+t055eNUOY4LqMTDW3qIdSQ9NsgsIP7dmRlx8Q9gf+BmjZbd6zPDhGUOkfC+S/e7+mW3f5xCJfheOutzfSSg/02NIJ7r2vDvlbpvTmFf+Qdwr5bLXEDMwZ7Xu2UOmmSnGis+Qs9J4aGve13Mk+nx+aTbH7cd+/k/wN0nfO7eNLgHnGMdes2BrLhyERN8nap9dMQAsV5M9VB8GzVcdZ16rS1k5t59LHeeePuPvo+It1AJkwdlt5d1r7+cGiZ544ZxpzGB3J2Bh2fmORExe0jGn4CrNIx1FjVkCKq35JmZ+ePu5wuYMHypgVtRD3MZETnrvTOpVqxWbkbVhZzkV1St66W4JdXA8z7qof95mflXuLAGNMBpmXnKEuPMZXOqJ8gkG7FuvcMNdW3qBuRCmfnjiLgj1cPmWxFxzyXGmM9hVEPIpDIw96L9OfXT3b87d18jyczwnlbDpH7L0v8+88oaGjUaHjVnCY7GMZsNjd1AQ15nRzanhtX17VFUMnOS91EP4M8CDqQevBbjfKqXxtfW87n/YmY4dCtDbN9s/6KGsfZmCvctj6eS9c/plv01qkfKa3OmzMAXI2Iz4MlUMqKFNfO8twX1u16qq9KVsur8svt39vXvR9Rw05bOpHplDeVKVCeE2b4FLH446fyGui/r/bo3y8FUoqvX68IGlFW4VuO4H6Lm+7kadU/7NeBpVM+95vWSO7eiGn4+09Py5xQRO1KJ9ttT5+/PUaN9HxkRT8/Mdy8xRN/PDLO9CXhNZn5y9EJmXgB8optb5S1UOYmleBnwJeCBmXlBV1pvH+BlEXG1zHzSEpc/n7Ooa8AkW1OjkFoact8cel/5JTPP60MZ8nkd4DpUicdeclcTXJ3qCdz39X3o6x70/3zyM+raOnrm+xOTj/UtqLxkH3rNgazIBHRXg2hkL+AzEfFn6iLwl9mfz8z5buA3xDOom5HHAs+MiB9RN15HAN/MzHMaxQGmM3EXVc9m9/GHOKhiNhHxHuph9ZkDrUsfhniYG/kO8PyIOJ/aT7809t71qNIjrf2bKhEzyVWpHiutnEb1LJhU03dX6oS5aFmTN76mq6X9buCEiHhuZu63lOVugJOAOzD54eq2rP3Avhh/Y8INT2ae2tX6/Qp18dl7iXHm8ibgw93kUwcyUwN6F2pI4aO6emGj9TpxifHutsT/vyH2oY69wzPzrL6DTakxrVdTvM6ODJX0vgxzP8RtSY2WgXrYu2CRMX5CTdjxkvk+1NWAbp2AHmL7ZnsvNbnplxstb32GuG+5LlU2aeQw6iZ8du29L1FDXVs5CtiDyQ87uzA5mbqhzmLt+omjmpuzH2wuyfz3UIvxZuApEXFIlxzqw9XHrmVnUHNIzLYpE2oYNzLUfVnv173xewJqHo4PdQ2wc10XlnrfANWA9neqp9t8Jv1dl+JR1DHwJuDDYx1I+jRog0w3UezjqAa2a1G9nx8FfDozz+866ryVGlmy1AR0r88MEwyRxLw5sNvo3JU1kekLI+KnwH7d5GiPbhBnkq8CL4iIQ6hRagDZ1W59KjVKu6Uh982h95XnAm+JiO83OmctxJDP6zB8kv0HVNK7eX3iWQZ93uv0/XzyDuBdEfHDzDyYOge/OiJ+mZk/AoiIW1Gla780z3KWotccyIpMQFM3x+MPGkHVXJkkabSdmfl24O0REVTvzO2ooeNPAC4VEUdn5p1axOrindclL//dapkLsBlzt7pdiZqsZSUb4mFu5HnAF6l6mCeydiLxYdSEQq19C9grIj439troWHkcbU+WbwHe3E3ANDuBuQOVtFqy7mZgh4h4JPDGbnLCF7ZY9np8iLqRPJmZ3rsZEXejkhl7L3H5P6ISvev0JsjMv3RxvkRdePowaln9b2C8l0bMen9kSb2TB+69uxO1L54UEd9l3QfjzMzdWgftHua2YvLkLE0mRpoV7ybUg+MNJ8TMXNoEH1O5zo7Zi2GS3l+nbux+kZk/GL0YEdsAr2Km1/L1qZ4Wi/EDaqjcQkyaiG0phti+2f4APDoiDqcegif97Rbaq3EhhrhvWcPaf5tRMmz2Q+LZzD0ZzmK8AjgsIr5CjQRK4B4R8QyqseKuDWKcQJWSOxguPK4m/T5vRA0xb2lL6vz184j4KpPP1S9bYoxPjX0f1HD42ZM73ZR+OgXAcPdlQ1z3fs2614W9qZ6gk7QY1fRb4CuZued8H+omavpEg3gj96ee8e5BdTr6K1WG4AiqF/Qv5/m/izVEgwwAEfFpap/5NzVU/l3ZTdY50vXqPYAa1bFUb2GAZ4YxQyQxL86EpGxmHhARZ1MTh30WeGODWLO9iHqmPZ66R0pqFMfNqcn7Htg43mD7JsPvK3vT9fiMiF8x+dy5beOYQz6vw/BJ9qcDH42I4/t4/hkzjee9vejx+SQzPxQRNwIOiogTqXzBFsCxETGKdUWqUeE5i42zHr3mQGJWh5EVISL2Zv2zul8oe5iFueudfEeqXtY9qdaAzMYzbUbEvtSC573xahjvi1SrzoMy8+ix129LJcp+mJk7NYy3J5UAuyETuvP38Pvcluq59DXqYe79wAuoCXZ2pWYN/n7jmJtn5p9nvXYzqnxE06EwEXELKol+MvXQ9RKql8otqAfM22TmUnvujsd7HPXgcY2xl39HTSDZMsEwind5qqbp7tSDz936urB1PT8+St3wnEvtn/+iEn0fz8xHLnH5T6D+PrecvX+MfWZT6rjboXUv224G3wXLzA+2jN+niDhpPR/JbDuD9tWpGrqTblCDfq4Nt6OSiydTycMfA1egEuC/B36dmdsvYfl7M8XrbNerjnnWITNzyUnviLg2dU3Ymkp0nE4lLbeiegDcMzNPiohnAudm5rsWEeMmwK1zPTPEd8f7lVqWFRpi+ybEXN+Nd9PjYYj7loj4OfC2zHzP2Gv3pWaqP3vstccAr8jMZuUAujhvoXphj5xM1edbci+3rnF388x823o+903ge6MyJC30va/McZ07NTO/MutzX6HqWz9rsbHmWYdB7suGuO5N474hIj4FXCczb7Wezz0Y+GTra2237Csy0+loO6pc0qmZeY15/tti4ryc6oH8H6qHax8NMqNYP6Z6NX94vhG8EXEZqvbnkjsRDPnM0DXSvZlqBJ2YxOw6li0lxtHAZzPz1XO8f3eqDNQZVI3k1veB16B6gO5AXdf/TDWuvTQzf9c41mD7ZhdvyH3lSNZzv5uZTUdxTuF5/ZvUPcTm1AiA5kn2iPgda/8eL0d1EPgnNTfI7HhLvk8a+nmviznU88kdqBzZnahSUBtRx/jPqIat92dmLyO3es+BrMQE9LRE1WbdnhpKfgfqj/FnqkX8a/TQIh4RD6JqTn+fuoidyqwdPjObtZLNelj9HTMX7GtSD6v3yMyTG8V6DDVU94NUL74PUK3J96cu1h/tqfGg14e5LsY0yqeMYt+KmgzprswUjv8m8KzMPK6HeEHdIFyV2j9/nz2fWLrk242AQzKz11qjEXEXZt3cDdybd1WIiPWdp5baY3dqIuLz1DXhtVS5hXVuCFrvM13v0j9Rwzv/A2yTmcdGxPZUMvzRLa8NQ1tIArzV9SGqbuMeVM/I0Xnse8D+WUNqV7Shty8i1vtQ0WOSvZf7lojYD7hEZj5iPZ87kLq3fshS4s2x7OvRXYdaPpiqf0Pfl60m3bPCozLzXuv53H8Bu/T03HAt6tlvNGny1YDzM3OTxnEGbbybhiGfGfpOYkbEa6gJ7G8wV4/HLon0ReByK/lvN419cxrPl0Ma8rowRJI9IvZfX4xZ8fZYSrxpGfL5ZNr6yoGYgN4A3cn3b8A3mBmC9ZMBYk5y4cRdPZzwL071ML09Myf97wIfbPmwGhHHUuUpXsHaCZQrUEn992bmO1rFmxC/14e5iDidummeNPyrdxFxSWqIxt8ys68i9ctO12p3HtV6fOy016e1lbp9c9z8bE6NfjgDOGEpPXanKWpo7tMz88MDxjwD2I3q7XI+cLtR78+I+G+q8et2jWJdnJrJ+h8T3rs0cN5qSNQuNyv1WJ+Goe5bFrAeOwK/uSgkiFfz/tnXtq2m+7KuUfnJkzreRMQNgPes1Gs6QEQ8gplOR1tT9y8/pHv+o4e5f4bWJfjuRyXANgf2zsxTutGiv8rMPzaM9VLgfZOWGVVq4QmZ+fJW8caW3VsSM6rs2q2pfWHO+rMRcUNqoupmIwlX8/E3rX1lWlbTdUHTs5LuyUxAb4Cupeq4IVvfupuAea3U3phR9bEeQN3I/Qe4c2Z+r3tvF+BVmXn9xjEHu6jFwOVTupgPAL6YNYHfEPEuS9UxnlT3NjPzFUOsx6x1uhhjDRpLWM5xVO/8j2Vm6wkvFm0p2xc1m/wrsobcr6/3R2bm4xa7nhuwTtelRnc8MzMPa7jcS1ETxm5L3dj9hTrX7JeZLScbJSL+COyRmUNNukZE/B24f2Z+PSLOBB47Gm3R9YI+ODOb1OyPiA8BG0/q/RkRH6ES0I9tEWuO+JtRD8d/bJ1MjIgtgEtl5m/HXnsiVRP2y5n5hZbxNnDdlnwum+b2RcTNmUls/F9mntY1/P4px8pWrGZd8uP9VGJng2tsd70/57KGqkF9XGb2Vb94Tq2utcvRSt+2iLgSk+ciaFXnfdRB5vaZedSE924NHDXNHp8Njr0LgJ9S9w1HUOV2/tZ0Jaeo6+zzJWpkzNnUUPnbdB2BPgL8JTOf3jDeBcAdhtpflnMSc6n7ZreMZX38LcXQ+8rYsq9AlbQbZB6X1Wwax98Q173lbCXdt6zUSQinYhp/zJWaXF6gfwEbZWZGxGnUbKnf6947hxri1trLqB6Dk1r1r9a93+qEeAjwtqj6dQfRc/mUzmeBP0fEx4GPZON61uMi4k7UpEWXn+MjSfVuX6lOpYZGvS6q3MEHgYMyc8hJQVu7GzOTGm7P/EOIBmloy8zfRMRrqd/1LVsss+uVciRwA2rSrNH55cHA0yJiu8aNCu+lSmEMloCmJoO6evf9j4HHRsQombgHtc2tbMfcE118nvrbNRcRO1Hn41t0L92GmoTjfcARmXlAgzAfoGpmP7mL+RKqpuJfgSdHxCMys+XEVkMbfPsi4hLUpFY7043Uoq4VpwGvoya9e37DeFN5WF2gjaiRCu9gcZM87s/MuXh8EsTx19ZExCeoRrB1JsRa7mLguUCG1j2Iz6dJY31EbAS8Engic9+Xtf5dznWfcF1mJuqclqUee1fKOebnWCVeT5UpuhNwNGtPpncY7Se3mm+C3SswoXTZEg35vLehlrpvjgx2/HXXmMOBIzPzhJbLnhRunvea7ytdD+QPUPVu54q95HPnAq4F43rpxDVgkn2Q429K1z2iSq3eh7kngV9x+Y+uUWuhz/6ZS6hzbQJaRBVw35Ad7rrr/9iC/AS4HnWj801qts2TqOHke1Oze7Y25EVtNGvozt3XyIXlU2h/Urw9lQh7GJVc+DU1k+lHs1Ht7jFvoWpnPwH4yUp88J1PZu7YtaY+gpp44wDg7KiZwz+cmV+b6gouQmZee+z7rae4KrOdQSWLW3kddTzfJTO/PXoxqo7/p4H/pYbrL1pEjPf4/T3w6K6h4hAmz4jcelLOL1CJ4QOAV1M1Bs8CLqB6MjXruUSVKpqr1voZVL3dpiLigdTf6nDgedTfdOQk6uGtRQJ6G6pxaeRJwKsz88UR8TbgWcBKTkBPY/teBdyDuhZ9larJPHIIlQxvloBm/uv6xRioMW0e863f+tyJmgjmYGqiovGJtHaifpc3oR7kTgFeuKQ1HVjXw/vt1D56CybMBTK9tWtm73neG+2bLR5W9wKeQl3fXkkdh2uAR3b/vnapASJiD6qBE2rd9+1GM47blBphcfhS4zWw6GNvlHzueqvemJmRVD/vcyTsgA0yDwD+JzO/2/WcG/dbKjm9JBGxHdXZYeSJXcPyuE2B+1ITa7U0dMJ7Q23wvjnl4+8a1Ll644g4lW7uK6oc6fomgluvKe8rL6Hup3ej5lB5CvBv6jnhqsAzGsXZewM+27QT11BJ9vGQ87zX8vjbi56ve7NFxNWAbzFTmmm0rePXhRWXgKbuIwe5XzYBvQzFurOIjjufegA5AnhrtpmA7evzxOvTvlSvRKiT/2HUAQ01HOyBLYJM8aLWdMbcheh6gB0VEc+kWuYeDbwI2Ccivg18KDPf3yjcaMKXHzRa3rLTHV9vAd4SNcHNo6mE9G4R8ftsMIPvtETE5TLz7/O8f+PM/PkA67E5lQT7TcPF3gd43njyGSAzvxMRL6bNDcn7Jry2NZOP+6Ru/JrJsdnGM/OwiLg91cP7UtQkES1rz58O3Ix62JjtZtTEFK29jCqX8viI2Ji1E9A/pevR28AV6RKkEXFT4CrMJGwPAuYrgbASTGP7Hg68ODMPmJDYOIk6Tpas6/kyuvHfqPt53KbUueDMFvGm5H+oGcfHE8snAN/sEg97ZuaDIuJy1APXikpAUw+Pr6Ee1h4PvCvXngtkxfdAzczZ+yURcUWqAeHZNLrXpRJTL6fuWV4JfLb7Xb4S+ApVKm2p1lCNnND1vh/7eeTPwLuphMCKFhGPp36XW469fHpEvLjhvfR4vCEbZDYD/jDHe5dkaQ1nI9sCL+6+T2aSp+POA35Og0bzKScxhzC14y8z7xQ158ddqN/xdsCu1LX3t9SotKWU7Rt0X5nlwdS58+NUAvr73aj3/aImFr431Xi+JJOuBQPqPck+peNviOvebK+nzsd3pRrrbtf9/FiqA+C8E+YuV5m595DB/FpmX9SQy/3m+PoQlaj9J9Xr7prTXt+G231pqtfU/YEtGi73ZdRFenShXjPh69/AsdQw3qn/Lhr/Xi9LnRR/R83a3Wq5PwceNO3tm7Beo5mEb9XDsi9JPeT/DrhgJW8fNergEnO891/AqY3X+yTgxFlfv6fqVf2HqmfcKta/gHvP8d4OwL8axLjWhnw1/l1enOq9dO2B9rl3UTdXN5/1+s2o5OZ7eoj5b+Ce3fdr7fPUTd+/G8X5A7Br9/3Tgd/N2lfOGuJ3PMe6LflYn8b2dX+77ef4290L+GeDGC/rrucL+Xr7Sv0bUo3xd5/jvXuM/n7APYFzV9K2jW3f9lQy5XyqpunovV2oidBW3N9tA+I8E/hSo2X9A9i2+/484E5j7z0A+G3jdf8acKNp/H2G+Bsy04Puq1TSZofu369055WH97DOx1K9JGefN68A/Ah4asNYPwReN+l3RSUvv9N429YAt+35b74invcanTunfvwBd+yOjzU0fCYaYl+ZFe+f1IhJqJ65dxl77z7AadP8PTfaxl9SI+DW2feAA6lOjUuNMfjxN/R1r1vub6n7k426bbr12HuvAj43pb9xn/mPLVsuzx7Qy1Bm7r6+z3Q1Tr9N1XLsbfKnIWXmP6jkeuvl7kP9nuadtKEvXU+XOzAzfO+7mbnOEP2eYl+LKh/xKKpebMu6sPsAz4+Iw3Oe2Z9Xg6hJ3R5NlVLZDDiK6rW1kl0F+HhE7Jzd1QUgIm5EjbBo3Ttk0kiLf1PDxg/MzJY9oI+n/l6HTnjvUTQo75OZpyx1GUuI/Z+I+CTVK2PJQx8X4KVUgusHEXE01XBwdeC2XfwXz/N/F+ssYIs53tuaSoi3cBiwd9Rkfc+megWP3IjaP1eyaWzfSdQ1b9IcB7eljs+lOrL7N6j98/3UfjnuXKqhdGoTSTZwLnBrJg+nvjUzdVs3oh7EVpppzAWynPyIdkN1/85MLco/UiUcRqOANqbuQZvJzMFH+Q3suVT5ukfPev2DEfFhqjTUxxrHvD7wDWaSNZsAZOZfI+JVVHLjHY1ivQt4R9SExqNyVpfvyjw8FWg6gXoO0Ptz2s97Q5rG8Rc1ifDdmOkBfSXqGvsOJl/vF2WIfWWWP1PPdlAdjG5BddKBug/dtK/AEXE36n7p6lSHge9mPyUetwJ+lpkXRMR/qE5/Ix+gOjkuqRf0lI6/Qa97ndGk6Gsi4h9UA+HIEdT5c8WLiG2p3uW3BTaJiPOA7wMvzSXWCzcBvUJlzSb/GroDvaWIuBnVirUtdVD9lWppfUVm/qRxrEsDj6N6tG1ODSf9VUTsCvwwM5vWgR76otYNAXk2dRM5Gs52bkS8ITNf0lPMy1Etc4+m6kf+i0o67EW1VLeyE1WL8qSI+C7r1r3NzNytYbxBdcPVH0WV3LgGVe/6rVT9519NcdVa2YG6SP8f3YNGRNyAungeD9yvZbCFNKw19AbgQxFxZerB6lQq4b4rM7VpV7oTqZv/3mXmmRFxG6pUyj2B/0eVNXgV8Oacp5TLEnwVeEFEHEL1kgTIboK7p9JgOGTnudSEea+hJmIav6Y+kpmyUCvVNLbvQ9ScDiczMxdCdg9az2TD6iBOlDVB89cBIiKp2dbnGk6+kh1IldC6gKoBfTp13D+U+j2OSvv8P9ok9oc2jblAlpOdaNeYdhxVq/jL3dc+EfEv6nf5KqrXWVMRcVlgRyq5sSomYhpzQ+r8OclHWLsxr5XBGmQyc9+IuA51TRhNBjbqzfq6zGxaf72bg+OKmfmF7ufNqcTlTan99XmZObucxKJNIYnZu65Eyxcz88/d9/PKzA81jP1bKkn6ayonsBdVdqPV+Ws81qD7CnWM3ZK6r/w08IqIuAx17nw2PdwndZ3TDqQS+UnlWq5Qb8XXqBKXLTurDZpkH/D4G/y6R3V2GHWQ+Q01sm/UgfK2VOeqFS0iHkqVpDmBKjnyJ+o5+iHAERGxa2Z+atEBptFF3K9m3eG3o/GQS+A21FCUP1OtYa/p/j2T6l1z64axrkkduOdSvUAuYGb41/9RD5Stf2dbre+rYay9qBu591LJ/Bt2/76329an97B9n+r+fudTJ8PdgM162v9OWs/XiY3ibAJ8FrjrBvyf3YArLDHuGuqGYF/gzn38Dqe5fd1ybkm1Hr+CSgL8gbohuXRf29vF3aw7/nvZN7sYe1I9/seHfp0KPKGHWCexbnmR0devgR90+9FNG8bcA/gxjYdFLZcvqpfz6dRNz37dOfMTwC+oXg5XG2AdLgts0nB5UzvWh9i+seVejLpxXUMlVNZQ9w8XUD0Kh9h/bkzVdex9P1nA72IpZQA2pZJdk0qLfBi4ZPe5+27IfjVHrMH3T6pe4gu6769HNfSOtu9vwHaN/g7TvM5+YMLXR6gSCBdQ9dJbbOM9gSd231+FanAaXftOYlYJpQbx7kR1PJg0zLrpkPxFrt9Sj70zgMfN8d7jgNN7WOfDgSd133+Mmu/gDtSz2VHAD3qIeS2q/voLgScC1+np7/FN4GVjP3+Auv/8dHd9eEnjeHcEdhr7efPud/oTqpPCxfreB+dZt0Xtm4yVppjnuOvl+KOeK/9BNbw8HbhZj7+fofeVbYCdu+8v08X5T/d7/A4NcwNjMT9CjfR7BHDx7rWLUx0D/k51dmoZ70Dghd33/0s9374AeA71rPTFnv6WV6GSsned/dVo+YNe97o476E630BNGLuGKs30xe44eWejONO8b/kF8HmqQXT89Y2oUYW/WNLy+9jZ/Brmi+rF96fGyzyMusm5zKzXL0N1u/9Kw1ifpIbuXIvqjT9ef+wRwPE9/M5GdYnm/GoY65ejE9SE994M/LKH7fspNSzwGn3ue0N/UT0gtxs45kOYo0byati+sdh3p1pr/0L1iO4t+Uz1uj6mu0Bf0P17FF2t3x7ibUTVs75T9+9GPcXZnypl8C/qAfKA7t9/UwmVz1DJ738Bd2wU88NUK/w53Xn7w1TP09HXB3vYzi2oHnu7Ub1ToHq99fV7vQYzpRXO636H+7GC5z6Y5rE+hW29C9UDZV+qMXvbnuK8g7E65FSppNHD49+A2wy83ZuNfb8R1Vvs+ktc5g2oe77ndv/esKd1n+r+SU9zgUxz27prwOwG+l9QJaJ2B6KnuEEl9W9Ol+BovPyjqd5lt6aHhqxFrlOzY6+7jv6JsXqw3et36K5FfVxjh2yQ+QsN595YQMwzgPt231+cSr49tvt5L5aY0JgQb9Ak5gLWZ8n7JvW8vMnY9/N+NV7/y3bn5Tcz02nsT1THgCcBN1ip+8oc63AJ4LI9Lv/vwFPmeO9pwN8bxxs0yU71lj+CybmW3hoo6fm618XYYnx/7/5e36Kuh6+m6xjQKNa07lv+Ddxnjvd2ZIlzKUW3IK0wEbEp8F3ghMzcpeFyzwEenZmfnfDeztQN12UaxforVXLjwIi4GHUi3CZr9tJtqda4zeZfygbH3J1169BuTiVVrk2VGfnA7P+3yFj/plrf16lrHRH3AL6QmbOHLGqCiDgUODIzXzvtdenDUNvX1bKeZBcqabMndaMHQGY2q+kWETtQrcO/pnqhnEbNvPww6mZhx8xsWSJmMBHxOKp22r0y87Sx169KDQl7OzNJ6bMz854NYp7MuueycZmZ11lqnC5WAK+jbrI26eLepjtXfxn4Vq7godYRcW+qpME1mTyMfNuGsQY/lw25fdMQEb8B9sluuHFE/IQ6z7wUeCNwXmbOnol9KfHelplPn+O9zYAvZ+adWsUb0mq+1q7mbZuG7nlhl8z80oAxBzv2url2vgFclxodNirldQ3q/HLXzPxTi1jzrMOlqYT3pahJAc9suOzTgUdl5ldaLXM98f5F3SN9MyLuRP1ur5qZp0fEXYFDMvPS8y9lg+KdAeyemV+MiItTI3v3yswPRMReVK/J/2oYb9VeFybpymLcjeo1vz11L9GktOvQ+8o0RMRfqAmi1zn+IuJewMczs4/6xeNxLkF1tGo+j1NEfJ46d72WGnVw7uzPZJVS0zymdd/S3Ue/PieU8YmI3YD/ycybLXb51oBehiLi5fO8fTGqBtgOVE+RhzcOv74WiZYtFpswU9tztstRvSObysz953jrTd2kIk0SNp0/U/WqJk2seJPu/RUtIi5FTYK5LTOTLH4N2C8z/9Uw1LOBg7oHnoOoB4G19sXMXLPUIBHxUqr0yx+77+eTDZNug2wftS8mM/XImfXzp8e+T+p808re1BClnca3pTvffYGqQ7joBPQ0a+NRow5eOJ587mKc2tWBf3Vmvjci3koN3VqyzNy6xXIW6AVU3eWXU3+j74+9dzDVI7OXBHREbESVU9gcOCZrstqWy38udYN8BpVUOG/+/7FkQx3rwFS2bxQ3qDryo/kd9s7MU7rG5V9l5h8bhrsq1VOQiLgGdX19XGb+JCLeRvWib2mPiDg1M9eaiLa7Hh5KJfqb6pJhk+rskkucDGaW3vfPiNgKODVrMtWt1vf5zPztUuKNGfTYm4aIuDq1naPj7n6Z+dMu4fbdzPz+fP9/A/2W6iU4pMGOvay5dv4fdY97F+oe92Sq9vz+mfnPVrHmWYdeJmfvHESN9BskAU0l8W9B9Uy+D/DTzDy9e+8KVPnAljZjpkPFbaln5tGEtMdS59OWBr8uTENEXJNKON+t+7om1av1Bw3D9L6vTPmZAeBzVAecScffrvRTY34tmXkuExLDjdyFKjX64Z6Wf6GBr3vjcXt9PulM677lRcBbI+IXmXn06MWIuB31PP+0JS19Kd2n/eqt2/t8NZ3+Q52YP0IPQzCpG52jWbcEx6VpX4Lju8B7u+/XqocFvBs4fODf+w7UrKatlvcOKsH+aGDj7rWNqUaDvwNvaxTnAtauCTZfiZHzG27fVagyI6M6S9/t/l1DDS+9csNYa9azbU22iynVVxtw+7bdkK9W29fF/ifdkLoJ7+0E/HMl/u26eP+ibngmvXd/uqFK1M3RkoYtjS33rsxRQ7s7Xzepr9Yt70RmhgXPPlffGziz5e9zLO5TqDrQo2NjFPMgGtXQp5Io72agepBDHevT2r4u5hW668Ea6lo3/rf7CI2ufWPxzqRGUEDVT/wbXVkYaq6MJZ1bJsS7N/XQtsfYa5eiemn9Abhuw1izh7Gumf39Sts/2bB7lhV3ne1irVPvcr6vRjFvQnUCOIOq3Th+3L0ZOKDxvvIw6rmgt2HqE2IOduwNuE1bMVMDdqv1fTWM+yBqMrJPURNu351KLF741Xg7X0ElhEdz1Txn7L19qB7eLeP9Gnhq9/0rgR+NvfcA4IyVvG9SnbheRj2H/bPP81kXb9/udzoqn/cDqpb2jszKGayEfYUpPjN0MXemSvd9kSrFdJ/u3y91rz+w9bFIzfvzGeqe6Xxmrg+vBu7dePv+COzQ+vc2Ic6g172xuKPnkwtmxTyIhnN8MfAzw1jcb1LJ7guohtfvM1MS6o/deW309fUNXb49oJehnO7MvS8EjgROiYgvMDPkbEfqQrpdw1ivBz5VHaU4oHvtxhHxAGqCj/s3jLUQV2JC76IleAHVgvtB4APdcJsrUgmcb1G/6xZeTtVIHX0/VF2d11GJhrtk5rdHL3azF3+amuRg90axBtmu8WNv4ONwqO27cLhT13K7UWaeP/baDlSv/SMy87jG4c+lashNchmW3gp/bep8Nfp+SL8Anh0RX8nqUQBARFwS+J/ufajRK62G7H6NGt521IT3btS936oH+9WpWcInOY9KeDcVEU8A3krVbfwKNWfAyDepCebe1iDUZYEDs+2M6vMZ8hwNw28f1LX9mlTt9aNZu9f1YdSkNy0dCzwlIn5LPRR8NWd6hIyfF5rIzEO7/fO93TDvw4FDqFJC22bmbxqGezdwM6r288RhrI0NsX8+lpqAevT9UMfDkMfekXPEmjT6qNVoozdS15odqPqN48fdd6h7spZ2Aq4MnBQR36WSAOMyM3drGXDgY28oJzFzLT+Z9e+jra7rn+7+3bn7Gmm9X47sTe2Xt6dG5bxp7L1bUJOktfQx4NURsR31DPuysfduBfyqZbAp7Juvp653h1BJxb6vDbenkqVfo0oC/K3HWHvT/74yzWcGqOQ61L3SfSa8Pzo+mxyLEXFn6v7rRCrn8tSxt9dQdbwPXUqMWd5LdcD7csNlTjL0dW/I5xMY/plh5AKqceuXY6+d1H0tmTWgl7mu1tGxmXnOhPc2o1pcWg6/JCJuTtVOHA05+ws15OwVmfmTxrGeRF1cLsPMjfnZVGvnvi1jdfHuOuHlTaik2wuA72XmAxrGC2p2+tm/y0NyhR983Q3W83JCzeyuJu5rM3PL4desjfFhwhPe2xi4WrYbGjy4iPgEcG5mPqb7+UnAu7q3/0P1Vm429DMiPkslUu6ZmSeNvb4VVdbhZ5m581z/fzmLrqY71dvzS1Sr+JWoh57LU70zD+/KAVwyM/dsEHMNcPvMXCcB3TUCHZmZmyw1Tre8E6kJVd8e69brfybwhMy8cYtYYzF/AXw+M583IeZ9gfdn5lUaxPkE1TPq1Utd1nI0je3rrg3/k5kfnPC32x44KDPnaoxaTLzbUA9Ol6d6P98tM3/cvfc5qgd063Jlo/Ime1OJ4WtRE8X8ct7/tOEx/spAw1jVTldqZsGyQS3MbojuwzPz4AnH3V2BQzPzUkuNMxZvfQ+imY3mIZgQu5djr9umhd6bZ2Zet0HM3ag5Yf4ck+epmR30g0uN2cXdbgGxplKjtXt2egmwb84qbbYBy7gY8HwqiXk08KpRQ2xEHET12ntzmzVeK27v14Uuzh+Ad2Xmq1oveyVpsa9Mw9DXiIj4FlX684FUMvs8Zq4POwNvycxmZWkiYk/q+DuJaiSZ3UDJpPzBIuIMet3rYg7yfLKa2QN6+Zuvl9sNadvLDYDuwe0hLZc5T6z3RNVevgOVsPkzNbRmrtrQS3Uk695wjRLfXwf+u2WwLsn8BWbqjvUqIj5ANRSs82AQEdeiZoR+bKNwm1HDMCb5ffd+c13Dy+ZUuZR1ksMNjfdKme0W3etNjz0YdPtuT9UuHnkO8D6q3tS+VP2nlrUHnwd8Gzg+Ir7HzOiK21NJo+fN/V83TERcANxhjuTsrYGjMrPZ3y4zD4uIWwEvpoZUX5XavsOAV2bmL7rPPX0pcSJia9auU79Nt7+M25TqVdiyceRA4KURcSwzPaEzIm7AzP7S2rWZu+fEP6hkYwtPBT4bEUn1ZPjr7A9k5omNYq1loGN9Gtu3GTXkeJJLsnYv0CXLzKO7hqwbUfWlxyfU2ZcGPd26ESOzvYGakGxXavj6CaPPZbuafP+iGrQGN+C1aHB9b9ukZEFEXJbq7HB16vj4SeN73fn2uS2ofamZzByk1+DAx97XGbi32XhCOeeep6aPuEcOFWsRNqJ6LH+BmrB6g3XJ5onJ2cx84PjPi01iTvG6AHWd/W7D5S1IRNyUtef9OTIzfzb0eoxZ8r4ytC5p+Tfq+nPGQGFvBeycmdndD447E2jdYWw0383WVK3w2ZLqQbxUg173OkM9n6xlqHuyiNgE+ATV8ahpJ9cRE9DL33wPapegusivSBFxucz8e/Y7ycZsk06C/wZOWUktp/PYnTrpT+qZsgWwG5WcauF4anjNpCE7j2LtYRtLFhE7UUNRbtG9dBvg2Ih4H1Uy4oA5//MiQ87z3sWZ/6K34cGG374r0SWJIuJ61AX1HZl5dkTsx0xZnCYy84RudMWzqREBt6JuXt9KXeRaDpOf7293MXp4wMzMnwOPaL3cWXajbrSz+3o7k4d0n08NzWxlb+COVK2vU7rXDqSGDn6HGsXS2pnUjeskN2TuBOeGSmrUzauoOpGTNG1oGvhYH3z7qGvDvZh8Xd+W6hnWVHcfsc4kSJn5xfGfuwe/84DbZOaxGxDifOY+bwTww/GwtLu/HmoY64X63j+7hvKFysx83FLizYo99HV2FPel1LVvM2aGVJ8TEa/PzLmOyw11FLAHNTHsbLtQDcAr0WDHXmbuvtj/u9JExBHzvD2q3/8Dqjdfq9JhG6JpQ+V6LDaJOa3rAtRxfldqjoDedSM/96fmMVrrvjMiDgB2z2FLfY3b4H1lA0c70Hg0RwLHUCOkh5oE9N9UKdVJrkod7y0NVdZkGte9oZ5PgOHvWzLzvG5k71tbLnecCehlaBq93LresfemEmsHZ81Wfxeqzu/NqeLub8vMN82zmA31x4j4OPCeHJths099DyfrhsVvyPC9Po7BueJfhbYtgW8APhQRV6aSlaMerbsC96AempuIiAdS9bAOp3rKvm7s7ZOoxNyST8ARcXmqVX/k6hEx+6Zj0y5eswaLobZvlrOollSo2u5njoatUw1bLeuhA9Almf+n9XJHul4moxvRjSb0TtmUqrV2Zl/r0LP9qVEcQT10PAX4+azPnAuckJnrDHdbrMz8Vzdc9xFUnbVfU6NVXgF8NMfqiDf0BarX9ZHMJL0zIrYAnkm7GcL3p5Lrb6Yazc6b99NLNIVjfX8G3L7Ou4B3RMTfmdmWy0fEHlSP7CWXoFmixSQ2plWH7w/AoyNiVE+0l2GsIwPtn9uz9u/y8sDlqGTOn6nr0sbUA/E6PfYXa0rXWSJiH6p35fuAj1PzAFyZSuTsExEbZ+beDUK9AjgsIr5CbUcC94iIZ1ATzk0qQbckEXEp6llkvEfk14D9MrPV/ea0jr1BTLFBZiPg+lTy6SRm9stRbdw/UWXEnhkR23aN7KvZsr8uzHoeeTv1DLaGKv026drQcnTTy6iE3kupyYRPo575HtW9dyJr19le7maPdrg7tf9/m5lj4U7Udh7eMnBmromI39HD/Cnz+BawV1eW7MJV6f59HI0bMjLzlPV/qonBr3sM93wytfsW6ji4PfXM2Zw1oJehiHgZM73cLnx57Pu1erll5nuXGO82VA3WUU3GfwAPpQrkn0gVd78pNbz14Zn5yUnLWUTcvakb16sDP6Ym2zkgJ9S7Xim6bdqQFtV9GsR8EHWShboROJR1E2ybUr1Oj8/MDao7tZ7Ye1I3YFcae/lPwEuXul/OinMc8IPMfHzXCj9eu+oBVB20qzeIM+nYm/hRqpzJK5Yas4s7yPbNivlZ6sHjlVQP1mNGvX8i4onAMzPzRo1j7kY9dG/FugnuJdVT7P52L13gx9+VmU9bbKwu3oXlbhbwANm0F18Xf1tqfoC+yhVNVXcj922ql/X3qZvI71DXodOBO2bmkntsRMQ/qOvo/ktd1gLjDXqsD719Y3FfSzU2BTM9PtcAr8vMFw25LrPWa616fdNaj4XqkgvzyZblhKawf96Zmizs2cCnM/OC7m/0EGqSrV0z8zuNYg1+ne3i/pFqqFtn8s2IeAPwiMy8WqNY9wXeAoxfS0+mzgGHtIgxFusq1MPpDaiH8FFC6lrUKIjtptRzdtEi4jEb8vnM/FCDmCezAQ0yrXpiRsT9qH3loePnwqgyZZ8EnkX1gP4K9ezwoEnL6cPQ5+mVcl2Y0MlplBuY+MzS+NpwEtWw9PIJ770U2GOosjyzYi/5b9c9y+4F3Cszfz/2+jWpZ+q3tHym7Zb9PKqB556Z2XvHgIi4BXVPfTKV33kJ1YhxC+DW1Kiw43uI23vJliGve128QZ5PuljTum+5CZVIf2v376nMOs8spaSQPaCXp/0Ztpfb3lSNxF2pobpvpVpTPp+Zj4AL62N9EngGa8/2uWiZuXdEvJyaSfuJVK+p13dDef4vM3/YIs64qLo2L2AmCXaJdVdr8b2SG/Vi2VBbUcllqJPD/2Pd2ZDPpU6OL2gZODP37YaA3JCZi8vxSzkpzeG/gOeOws5676/M9ORdqoOoi1ZQtaleCcyeufpc4OdjvYVbGGr7xj2X6jXxeaqhae+x9x5G49pyEfESYB/gp9SwxNYzdh85CkUlot9P1SIfdy51Lm1Rk/1uzAxPmt2jb7Y+Sn4MPjlQV0LlrtT++H+ZeVpU+ZY/tU6EZ+aZEbEN9VCwA3Ucbgy8gyrZctY8/31DnEE1mg1l6GN96O0DIDOfHxHvBu7JzPwOX23cI+uiYOgH+qH3zzcBrxnv2NAN4/5E95D3FuC2jWJN4zoLlUycq4TKoTSce6QrOfPF7rx8JeDPfSQVOq8DrgDcJTMvHOYcNQnup4H/pcrCrST7b8BnE1hyAjoztx59P9Yg80QmN8g8aqnxxrwS2Ht20i4zf9D12n9lZt4sIl5PjXjU9O0xxdhXo54jJ/kONW/MSvUc4IXjyWeAzPxddyy8miqH1dJlqITpiRFxKOsm+DIzm/Uoz8wfRU3K93rqbxXUiLRvAtu2vk7EgCVbBr7uDfl8AtO7bxmVynsrk0txLKmkkAnoZagbtnAKQETcjf57ud0KeGpm/qaL+UIqATU+MUZGxAfZsJuz9eoSlZ8HPh9VBuTxVK/oPSPiGKpX9Mcys1Wy6vVUQv8Q4DO0T4JNFFVC5QpU74WmPbwz88KTQ9dC/cDM/FHLGOuJv4bqJd+ns6ga1pNsTSVZlqz7vf0IIGqShi9k5p9bLHs9Btm+cZn5K+D6EbH5hG18Bu0n83gc8NbMfGbj5QIXJmS/Dhf+7d6bmXNNktki3rXHvt+6rzhzifXXr1tSj/JZsS5BDbncmZnerAdT+8jrgBOo2a6b6BoK/5caEfMKaohdX94GPDkivtxDw9kkQx/rg25f97c7jXq4+DxVdmDV6YZC78LcozmajHjI4Yaxjgy9f96MKukzya+o0XetDH6d7Xyfqtk4qSb6bbr3m8rMXzP377WV+wDPG08+d7G/ExEvpp+5Afo+9gbvwTnLkA0yN2Duff4M4Hrd979h2FIBK1bf14Ucm7AyIu4DfCNr/oMh/JEqSTHpPHZH5p6UfiW4BlUjeZJzqZHarb1w7PtJczMljUuadI1Nd4+IS1Kdxv6Wmf9sGWPM4CVbBrrujWKdTT2b9Pl8AtO7b+m1vJAJ6OXv0vMlnyPiOZn5+iXGuDJr9xT8Xffv7J36DCqJ2pezqB6051BJjstRvRhfEREPz8xvNYjxEKp0wsSZkVuLiB2oyZ/+H13iJiKOBV6UmV9tHW/I4U8R8WZgi8xcp9ZzRHwYOG3SkNNF+irwgog4hOqlD/W7vATVgtt8iM34jd4ABt++kUkJ9sxsPkkY1Uo7aZKI5rJBaZsVYHb9Oqjf8R2pc2jLem6vYqau+1dZu0ftIcCTaZiAzpoA44nAZ1stcx5XoJJcP4+Ir7JuzdmmvVAY/lgfdPu6v935zP0wt+J1Nfk+SdVQPZ11G7JXcm27offP06iH1EkTMe1K2977g21brD3/wNOBz3bHxYHM1BfdhUo8PKBh3CtSE1tdk8kJsJbnss2YO+n0++79pvo+9qbQ4DPbkA0yJwNPYPJE4nt270MlP4boiLGiTeG68EXgPxHxA6ru+uHAdzKzr2vvR4EXdWVAPsra8/68iOo0sFL9HHhORHx1/PcXEZtSvaOb1z/PzNlz1Aym28a+GwweRY2iGM+3nAK8qhvVsQeNEtADX/eGNpX8QN8j+q0Bvcx1J/q3As/NzP+MvX4V4MNUjbWLN4hx+8w8qvt5Yj2liLgddXFrVlOqW+6dqOFmD6Fqnn2Uqmnzk4i4IbAvlei8SYNYfwcelJm9zxrcJZ+/SN1Mfox60Loq1bv8esCOLZLQ3ZCaYzPznO77eWXmN5Yas4v7G2r43ocnvPcoKtF//UaxtqZmuk2qbMRjqBpWN6caKrbpo7drVwPp8VSJkUkXtbs3irM1U9i+IUXEF4DDM/PNA8W7EjX0a66/XeuazJemenmPSlTsmZm/iohdgR9m5i9bxptnPS5PPVC+LRvNjBwRfwBenZnvnH19iJop+cDMbNo4GRHfpnpAv7PlcifEGbrG7tYMeKwPvX1dzH27BU97ssF1NKoX+RPq4fuRmdlX75PxePeiyjRMOpeRjWrCdrG2Ztj98xnUBJmHsG5ydgdgr8x8e6NYWzPQtsXkWq2THrgCWJMNJqTu9pNPM3dv1dbnsh8CP8vMR05478PATTPzlq3idcsd9NjrYg5Weqob2XR4Zj5+wnsfAO7WqqNJRDyc6pn4M2q/OZ0avv5gKtH9iMz8eES8C7hKZu68xHgbARvl2KTF3XPSTYEjMvO4WZ/9DbBTNq4XO8e6rcTrwvWoifO2o0rCXYlKeh9FdUD4WqvnvS7exlTJmV1Z99z2MWC37GdC6vWt15L3lYi4O/W8fhZ1bRhdh3akrg33GSJv0LeI+C8q1zJXona3hrHOBe6bmev0mO+eG76YmbPLoC4mzqDXvS7mRlQj3UOZ+3d5rUaxtmYV5gfsAb38PZG6Od+26wV8fNTEEe+nehg1SYAB23RlIqBabxO4TZfMGLlxo1gARMTTqAP4xlQJh+cAHxq/oeu292W0m4H2YOpGcogLyd5Ur56dxoc+R9W9/gJVD7dFL+gjqZlKj+q+n6tVafQA1OpEfHXgt3O893saDlnKzJMj4lbU72wH4ALq73goNeFhH8nn21G9TE+mZgr/MdWbcCtq+5oN85nG9g1hVi+wvYDPRMSfmXvG7iYlArqGq+9S17hLU5NyXpHa9/9KTebTTNREJUdSw/h+ST1QXaZ7+25U7+F1Hij7kJl/i6rZ+CrazYy8OXOX2dmIdWvpt/Bs4GMRcQp1o9pLa/nQvVCGPtan1MvmEOBtEfEp5p68pMk1uCv58Qmq7l6zh+31uA7w7IGSDDtS9y2HURPcHApcihoKfQpVv7GZKeyfb42Ic6ieUPcZe+t3wBMyc30TvG5IrCG3rdfhq3N4E3AcVWbul+OdVnryBuBDEXFl6loz3iNyNGKmtSGPvUFLT3XeArw5Iq7KHA0yrQJl5sci4kzqeHghcHEqCXsMNRnbKHH0LOpYWaqPUQnSxwBExJOouX+gevJemKzq7gWHLIeS1Pl0KWUZB9s3Ya1yA/8HEBE3puYjeRBV9uAlNMzzdMnlR0TEq6jz5mjen2+0biSIiPnuD9ZQ9/A/AN6fNdHpkvaVzDw8Im4JvJiaU+mq1PnsK1Qv3kE6kPQpaoLVD1D7+unUZHbjWl+vhirZMvR1D+r8/6wu7tGs+7tsZlr5gaiJRdezarn48iOZ6dcy/6IKkP+IGlb9GWrn+xRwhUbLX9Mtc808X6P3L2i4XedSD47brudzV6d607aIeTtqdu6XAttQNwxrfTXcvn9SrX+T3tsJ+GejONsCm419P+9Xw+07FXjcHO89Hji9VaxpfFGNHgdQScs1wK2617cH/gBsP+11XO5fY+eO0dfsn8e/zm8Y9/PUpE+bjv521I34Y6nExi0ab+cnqSF61+rijO8vj6Am5hzy935f4JyGy/sFVTaICcfDi4HjetiG31G9US6gGlt/RzV4jb5OGfJ32q3TaHLSrYaOvZK2b8j7iC7e2dRosIV+fjeWcP9EPfg+fKC/yXepOt6zj7sbACcBu0x7v2m0nUH1JLpt929Me51W2hf1jHDPgWPuSSVkx4/zU6nGgz7iDXnsvYFqsH4EsOWs4+8JfVz3umU/rrvGjf9OTwEe2+O2bkT1oN2oxxinALuO/fwbaoTrZajk9Nd6iLkblaj5OVVzdvzrN41jDbZvzop7KSox9VoqGXZ+t98e1DDGJlSy+f4DbdPXqOesNd1+8p3u3zXd68cC/6JKg9546N95o22c73nogh7uk35F9RS+/EDb90oqMfsSKr+yKdVQ8AIq//PyRnGmcd07Ddhn2vtQz9u4vpzgkvZPe0CvAJn5i4jYnToBP5C6wOya7Ya63K3RcjbUVlktl/PKzD8A+3Stdwdn5uwalhviu92/ezN37aFWPYTPBS47x3uXodEEiFmTr63z/QAOA14cEV8Y/zt2vWFeSJve3euIiKtRjRJ/yH57Bt+cunkdtQpfDKrnXkS8EngN1aDR1IDbN4Rp9AKDmtjpScwcY6Nhnx+IiC2pXkYtz3v3pEpunNIN5Rz3B/qZwGQd3RDJm1Lnt5Y9Uj4EvDAiTqZuYKFqkN0NeGYXr7XDWX61dDeizgnvYO7RHwu2DI/1Vtu3PcP+7b5NjQI6ciEfzqXX938u8JaI+H5mnrjEZa3PjagG81FJh40BMvOEiNiberj75Jz/ewmG3D+znnh+x8wcJL1ahsdeC8cBVxsyYGbuGxHvo8rDjHpEHp/9TXg65LH3cODFmXnAhOv6SdQEUM1l5vu7chvXYKYn5u+7Y6QX3d/r9L6W37kSdT80Kh9xbeAdmXl2ROxHuxFbdDFeQvUa/CnwQ/qfdH7IfXM0mnZ76n73POBb1LXgSVTjSLNjMIef2+FN1H367FKgt6a2cR8q4f8VarTfg1oE7UZt3pga9XdM9jvB46Tno82Be1GjCvdvHO8qwJMy82+NlzuXvanE8z6s/YwwKtny8kZxBr/uUfdhQ424u9DA92TrjJ6MqrW9EzVC9YFLWb4J6BUgIvakTsa/pHoMvwT4bleSY8llAAZOWo7HXfDkMt3N337UhXYpCejHMtyD8ZHUBIrfy8yTRi9GxFbUyfhrrQNuSI21Bl5CNYb8qqvvOyq7sRN1k/LihrFGw4f2oUpgjF77LfCSzPxIy1idTYB/ZOaaiPgL9SAwcjxtJ4OZxvb1LnuexGAemwF/6f52f2ftGYSPpvbdljZhZnKI2S5H9UhpakKN0XFnUb2gW3kdcAtq3oH3da99i6p79vFsVKN1XGbu3nqZjcSSF7C8j/Ulb19mHtlgPTbEs4GDulIOBzG55EfLhNjedGVpIuJXrFtOKDNz20ax1lCjQzIizqD2maO69/4IXLdRnAsNvX92Q59fQg0rvTxw26z68q+mhndPmiRtsbGW87G3VM8C9o+IEzLzu+v9dCPdsTVXiabW9ma4Y28apaeA4RtkBnIW9TuFqlt8Zmb+uPv5AibUt1+ixwFvzcxnNl7uXPZmuH0T6hnrn9QImddl/6U/DqLqB0+aMLa1V1JzDK1VjzszfxAR+1BlMW7WlZt7Q4uAEfEUqmPaFnRlSIFjI+Ig6vn5bS3ijMz1fNTlOw6mcalAqqH+v2hX0nReOVzJlmlc9z5FjToY5He5XO5bMvMvVNmtzYF3UjXSF8UE9DIXEZ+mWvbeRk1EeF5EHEy1Hh0XEU/PzP0axtsT+GjPrX6L1eLBeP8G67FQz6NO+MdHxPeYqY93e+Bv3futLbjG2lJl1SW6DdWKeU/qxutM4LNUyZRms4lHxFOpY+Aw4BXM1MV7OPDBiLhctp+s7NfM9Fz9MfDYLtEONXvvaa0CTWn7VrOTqWMNqrHgoczM9L4Tdfy19GNq4p5JiZL7UD01WpvUe+Lf1DDXQzKz2c1rZl4A7BoR7wTuTQ1H/jNw6LQaMFeqi8Kxvoj6jUv1k+7ft3Zfs13Yc7iRC6jzyhCOZ6an5THAXlETdJ5PJd5Pbhls6P0zIu7cxTqR6gH51LG311C9+ZokoC8Cx94PqAfib0XEP1j3OpfZaGKkka5H1H2ZeyKmuUYaLtaQx95JwB2YPGfMbftajyEbZAb2HeD5XU/avai5QEauR3ViaWlzKpE3lCH3TYBnUCP5Hgs8MyJ+RO2rRwDfzMxzGscbbG4HqsTUXAn1M6j9Baosx1yTzy1YRDyBunf4AJVgHx9V9E3q/r5pAnoumXlB1MSf76B6gbfyVGbm4fkKEzrz9TRy5SyqjOzo+nDlbqR0q/1l8OselfT+aNSE219m8u+y1Twny/G+5Ufduixa9DiiRw1ExJ+APTLzS7NevwTV6vfkbDur9QVUPZ2PULM9/3g9/2UQ0WCG4mmImkjk2dSkBqPWv69TEyad2kO8U4DnZebHu59/Q52Yn03VWrtKZk6r5MqiRc0M/rXMfOyE9/anals3nbCkG958tczcM7oZe6l98AKqh+3TW530p7F9q1lEvImqi75nROwCfJyqf3Y+NaT9VZm5vgkWNiTezlSL+PupJMrhVCPQ9al6Z/dfwQ+NU9G1+M9llMQ8LjNbP7TOqcV1aDkf662usxFxJLXvX5VK4oxumK9NPbT+ieqJcw61vT9f4nrvzXpGNmXmPkuJMS1dr6xrZeZzu+HHhzFT2usC4BGZ+amG8QbdPyPiW1Rj1gOpMlfn0e1/3Xn1LZm51TyL2JBYy/bYayEi3kwlpY6jRkyuMzFSZu7RMN69qJJMcyWAsuXzydAi4gVUObknUdv5T+DWVFL4U1QPzaajf2Y1yBxGJY1Gx8MrgZtm5gNbxhxKRFyfSjpfl9q+e2Tmyd17R1DzOrTcP78AHJ6Zb261zOUoIgK4JdWrfHvgzlRd6KMz804N48yVnEy6STpbHe8R8Qvg55n54AnvfRa4UWb+V3eNeHtmLqnMXRfv85n5vNn3QRFxX6qx/CrzL6WdiHgwsF9mzlXGczHLvCQ1YeWj5vhIZmazhvqIuA7wUaqxbp23abS/DH3d62Jel5qT7WazQ9H+WFh29y3dM/aDlhLXBPQyFxFXnq+HUNej9YsN420NPBHYnarXdRTwHuATmTlU7adJ67XoB+OoWmqvyMyTuu/nk5n5uMWu57RFxL+o2au/GVVj7QTg/2Xmj7uHhQMyc4v5l7LBMXuvmdVt1wMyc52hX912HZSZl2odd1acW1Kt4Jeien42G4a2HLZvNeka6C6RmWd1P98PeBjd3w54bza++HWjDV5L1XcfjdY4G3hOZu7bMtasuIPVrIuq+XwHuhpkwHeyp3ILsXaJkfHRL+OvraHKUu2Rmb3NQj22Ti0S0Mv2WG+YgL4f1XPnoTm5fuOzmKnfeHxmNqnfeFEQEdegRiFcCjhsqcn7CcsfdP+MiH8CO2fmoRMe/O8KfDkzN20Ua9keey1ExF+Bt2X7Xsdzxfsp1aniKcAvM/M/Q8QdSrc/fhTYhRpZeAlq4rNR6alH9hBzsAaZaYmIzTPzz7NeuxlwWi6xjER3PzRyHSpJ9AYq8T27JEZfPT4HFxGbAHcE7k6NSL0tjRuAImK95UOy0Yi4iHg41RHuZ1Tjz+lUTuLBVPnDR2Tmx7uewlfJzJ2XGO/fwI5Zc/zMvg5tRz3zNS0RE1WOc7ZNqO17PfC7zNy+YbwPU89BBzN3orZZQ33XqHRD6rlornhL3l+Gvu51Mb9BNaT1um1drKnct8yRLxvtnzejRrq/crHLtwTHMjdKPs+VZGiZfO6WdzLwgqjJGx5Etfx/AHhTRHwI2Dczh6r11srdmBmWu77JkZolpSLiBsBVJ52EugerUzPzV63idQatsRbD1cz6CXPXurw+NclIr7LqZ7esoT1u6tu3WnQ3jzei6qMCkJkH0/NQzMx8T3eDdwfqRvnPVIJ2rtrQSzbU8Rc1zPpA6ly6hhpudoV6K74G7JJVG6ylO1EP/wdTvc1GvWh3ocqoPBm4CVWK5BSqp9pKcFE41gev39i37pp9bGae030/r8xc8gQ1XVLhv6lefD/tlvt7Zuqw92Ho/fPfVDJ9kqvStg7maj/21jDsxEhbA8/MzJ+s74NLMY1jr1vONEpP3YpqkMmImP08cma3Diva7ORz91qrfeh81n6OC2r+oImrwhLzINPaN7vYd6SeaUcdAy5B7Z9HAh+k8TxDo30+Ii5LJaFGHRF+0vo+NzM/FhFnUnVvXwhcnEoKH0N1shqVknwW9Wy7VGcy96SiN6SbPLOxk5mccwiqtMhTGsd7ANUhZlKZsj7cBtg9Mz+93k8uzdDXPYBtgMdkw9Fn85jWfcukfNmozONbqHPMopmAXgHGkgyjxOJ4kuHw7GcCqPOphMOBXU/a9wFPB57etdC/rnXyuy/jQwQyc+sBQ78F+DlVcmO2nagGhZ0axxysxloMWzPrGcDHuxuSz2TVyLpYF+M5wK6N4kzLat++ISV1k3pfhpksZSZwNQw2qbG+PgMff2+jrjuPAg7MzP9ExMWpZPC7uvV4dKNYI/9D9TIbTyyfAHwzIs4G9szMB0XE5YBHsnIS0BeFY33Q+o0DOZKav+Go7vu5eudH9++Se55lzfnxWmqym6EMvX9+i6pr/bmx10a/28cxuf7uYq32Y+9Aas6BQSZGohrkrzZAnCMZ+NgDiIjvAO8GPpmZ32yxzAUYskFmNZo0N0afjmQK+2bnW1S9228Az6eG6ffdGPRSqqTjZsxs0zkR8fql9IacJDO/Cny164C3BdWhas2sz7Qamf0F4KVR5cNG8xdlRGwBPJOqed3aY5k7wXd01wDW0j+onMRQfs+EnsE9GPq6B/Bbhtk2mNJ9S9/5MhPQy9wCkgwPAZonoLvYl6GSCk+kutsfRx3o9wM+HxFN66guQMveyddk7klTWrUab0OVL5nkG8BujeKMey6VdP48VWNt77H3Hga0nCH2WcAbc6Zm1rhfUifGRYuI37H23/xyVC3fC7ohN1egbubOoYbht55c5yTm3ufGJ9J626h32gYuf6rbt1pl5prudztoYqu7Sb4tNUvxOiMNMvNDjUP2evzNcj/gBZl5wOiFbrj1R7ve0U0fPDr3YmYC1dmOYGaysm9Q570hJNWguEG9fVbQsb6o7ZvgZOAJTJ48bk9mJs7bguqxtRLcjZmHtyHnUfgFNZS8tx4+U94/X0JN1vwjaqRDArtF1Ri8NdXwtWgr6Nhr4RDgzV2j3KH0ODFS51nA/hFxQma2vLecbVrH3nlUL6+3RMQHqXlx+p5kbsgGmVUnM/ceOOS09k2oZ8zjMoeppdqNXnoJ1SHt46w9Gdo+EbFxH7//Lul8euvlzvJi6u/3U+D71DH3Nmo05elUw0ZTmbk/TOxR/rMeks9QIwEeAXy1h2VP8mrgeRFxRPZYGpDhr3tQzzyjbWs92edF4r7FBPTyN2SSAYCI2IZKOu9K7SOfpHqbfb/7yGu7Eh17ARuUgI6Ip1O92k7v6h+dugF142L9H1lv/NlF8UfL7KOF+jJUa+Yk/6FOKE11JT2uP6nGGtWKdlrDcNemZn+d5B/URC1LcTjD9mSY7evUDcmVqJ7lo5utO1G/x1OoxNyjI+LumfmdDVz+tLdvNfs/6iHuizlMbeAbUz0krsvk81QCrRPQfR9/4y6gJnGc5HjaDIGc7VwqATWpV8Otmel9sBG1vb3rHoQW85C5Io71JWzfbC8HPhIRP2aO+o3d5+5BPewte+ND7occikzdY701In7QY++2qe2fmfmjbuj664EXUefPp1IdLLZtkPBbEcdeI5/t/n1c9zXSVw/MH1C/329FxD+o3pjjMjOX/GA8rWMvM7eLiBtRjWaPAZ4REd+kekV/ZgOeXTZErw0yamuK1wVml7gawBOofMR43uFnwBER8XfqONl74HVqIjPP7HIfe1Ejjn5D5T/eAbw5u/lkWhuyRzn1zPrwiPgqcydq1zdP1oJl5oe78+fJEfG9CfEyM1t0xBv6uge1j1yD2rbv0n7blsV9S0RcnhoBsNbcP9RcBH9byrJNQC9/QyYZiIhjgVtQM9e/nJr5dVJtz69StZk21JuB71EPpCdRO/VR6/tPXWvgRuv73AK8j+qhuBdzFI5v6ERqQohJZQC2Z6YXWHOZ+eeI2IxqJftrZp7Tw8NrrzWzMnP3pfz/Br5J1eO7XWZemLiPiKtSx+Qh1AiBw6lj4Z4bsvBlsH2r2WXoZlqPiEOBU1n7Yp7ZdsKKd1HX012oel3nNlz2XIasWfc5agTFpHPZrvQzPPFAqlfNBdSD+CiJ+VDqIWd0o/z/qCT4onR1dl9A9eLZiqqjOC5ziTODT/NYH2L7ZptC/cbBDfjg+LwuxnERcTKTz2XrnRxqPtO+FnWJlLtHxCWBKwJ/y8x/Nlr27i2Ws0IM3QPzjVRjwXH0fz99oYHLAPwSeFZEvIC6vu8JHACcGRH7UfPinNgwXt8NMurRwAnFoV2OufMRh1LzFaxYXSPBK7qv3k2hR/m7u3+vReUmZktm7quXLCJ2p+49L6CepWdfH1olWIe+7gHcmRoJfTbV2DTbkrZtOdy3RMQtqJKSl6Pydj+n9s8XAk/uOt4tOq8UA43c0CJFxO+Bl2bmB2LdmVmfCDw3M+cqTr6YeJ+nTlKHzjesp3uovWpmnjLXZ+b4f38G9sjMz0fEGiq5d/SSVnrD4p/NMEXxiYjnUReyZwLvy8xzI+ISwOOBN1GTNL2mh7g7AK+iEjOjG6BjgRd1NbVaxXkPNTHL9lTL6n+oHhq/o4YRfjEzn90q3tAi4gTghTlhkoGI2AV4dWZeL2q25vdkZvMe7Vqc7twyn8y2s4OfRZ1XPtNqmQuIOdjxFxE7U42HP6USw+MTAt6EGl1xYQ+RFsPdImJT4L3UzfhsBwBPyMx/R8R9gbNzkZP7RMRbqcleDmGOxoNsODP40Ka9ffPVb1yp1vPg+FjgFa0eHLualPPeqGfmNB7AtMJFxGOAgzNznZ5wC/z/f6VKkLVszF1fzMGOvTni34q6fx9NOLeG6oH3tPGOCo1iNW+QUX+mvW/2LSKOAL466bm1a6C5Z2ZuP/yarUwR8Ufgo7N6lI/eewPwiMxsVmM/ItY7GmVDczrriXcK1engcUvtLdvSUq97FxUR8XXq/LXD+H4REVtTDU6nZeZ2i16+CejlbegkX4zN6Dvhvc2AWy32Qb9bxueBu1DDy+5KJUbnGtqSmTmplW7RIuIXVNL+4JbLnSPWxajaPDtTN6l/oW4mN6KGJT+s9QN5l3z+IvBr4GNUqYirUr0Xrwfs2CoJHTU5w7epWtrfp/6e36FqZp0B3CEzm02Y0tWavS9z1+5u+hAUEf8Cdpm0r0TE/YFPZOam3THz5czcdInxBt0+tRMRJwJPz8wvDBhzvuPvdOCOrY6/hST0Rx+lfXL/BsDtqPPYqcBRLXuBRcQfgHdl5qtaLXMBMQc71qexfavd0A+OQ5vCtfa/qPlM5orXbL4Mr7Oluz89D7jNYofydx1KdsnMwSZ/msax1zWGPhx4EvX8dTzVUWc0J87ewC9bP69oZVmN14WuAXnkxlRjy76s2xHhCcADMnPISe6a6bZzT2qE3VzXhtbzDP2D+p2tM3F5RNwD+FxmTmWS5ogIqjFl38U2rEXEOdT2DTk54LxaXPcWEXMjqifxE7PKpC5mGYPft0TEP4HdMvPACe89DNgvM+eaMHf9yzcBvfx0Q47vkJlHDZlkmB17wnu3ph7+F51ciIgrAy+j1n9bqkfWnLWxMvMui401R/zRpIo7ZL9F8cdjbk+VZ9icGjb/lcw8sqdYo1pEO40nt7sT4BeAy2fmHRvGuwwzNbOuRE0odSiNa2ZFxL2opP1cF+OmSa8u5qhxZIfMPHfs9UtSpQg2y8xbRcSuwGtzCTPGTmP71E5EPA3YkTruBispMODxt0FD/HOsLuJyF1W78EEtem0vMN6gx/rQ23dRMPSDY1TZp2dT90xXpBqzv0bV4/xTqzhdrKH3z8dQw36TuqddZ5huZl6nUSyvs53ZIyoXuYz3AOdk5v80Xbn5Yw527EXEzajnhUdS+8znqMa8r8363P2AAzNzncmHFxl3sAYZtbOcE4qL1XU+GE8UBZNH5ASwJhuX8xpK10DwLOYpJ5SZezSOuWx7lDdqoDwU+EJmvqPpyi1Bi+ve0DGndd8SNRHiUzLz8xPeewDwjsy85mKXvyJPFBcBF05ilcMXxp9vor9LsMR6jd3D0pPhwgvbnpOS3X3J4Yrijy/wCNYzc3XX2vh+qizHb5cQ7hbAQ2f3rM7MNRHxLmpCySa6pPa/MvPCmlkRcW9qSP51gB+2ikUNeTyOGkr+y+xn8pfZnksl7X8bEV9ipgbtjlTt9R27z92RybVxN8Q0tk9LEBGzZ8W+EfDzqAk+ZtfN76WFOoerWfdNYKPMPH/0Qjfa4qbAEZl5XJ/Bu3PNr4H7ZebPGi/+YKphd6gE7dDH+tDbd1HwfWoysHUSDd3rzSZW7EYAfIu65nybOg6uQpW9eUxE3GWxvWrmMPT++RIqsTfEMF2vs20dArw5Ii7H3JNatT7vDHbsUSM1/wi8heoJeOocn/s18N0WARfSINMijnox5L45lJdz0djnHkWVSBlyBMzTgc9GxPms26P8scADxnugz36uH8B8+aCFeAbwya5U01zXh1VRlq1n07pveTfwnIj4Smb+e/RiNyLof4B3LmXh9oBehrrE7O2HSsx29VxGPUwOoya8+OWsj21KnRBvkZnXaxT3WsCpmTnIxCVdzN2pm7sL6Lm3zQauV5NhId2J/smZ+bEJ7z2c6r1xhcWv6VrL+wRwbmY+pvv5idRkbEG19t13Uk+ARcY6h+rF16yG9QLj3hh4MWuXAPge8MrM/EXDOFPZvtVqQq+NdSy1xXgBZSlmheulhXo3ZiaXm9RTqsn8ABOO9SdRxzo0PtbniN9br4WIuB3wIeCjwJdYt/GAbDjJ1NDH+tDbd1EQETdlPUORGbuHWspDVkR8lmrouWdmnjz2+rWohs+fZebOi13+hHhD759nAw/MAYbpep2d0agH9Fz7ddJDOaYu5pDH3s5Ur9UhRzX9Cvgxy6xuqtZvyH1TbUVNmvywIa5DYzFHf/+5epTPnmx4sE6jja8Pcz2LDbpNsGJ7QE8r//FK4DHUs+WXmDmf7Qj8i3quGP1tN7iTlQnoZSgGnpwvIl5GlcWYPcxmZHQzeT7VHf+9jePvxKyhpZn5pZYxxmIt16L4TU6K3cPqzaiH1ZPGXt8K+CoNH1a73+XzMvPj3c+/AQ6nhgrvC1wlG02OFBHfpCZy/GCL5S03q337hhYRe7PuTc/mwL2okRz75wqeWA4gIl4C7ENNDPhTJk8u12TI4JDH+hzx+0xAjz8ETrwhaplEGfpYH3r7LgqGfHCMiL8BTxode7Pea9qo3C1z6P1zsGG6XmdnNEowrLc0UzYux7SckzYtDNkgo7ZW+765mnXlhM7KzOcOGHNvNqB3+ZDPLI2uD3uz/o5Agz6HrdAE9FTuW/ruZOXJb/nat7sRWZ/MzA2qzznB/sCR1AXyCKqb/+yJBM4FTsjMdXpPLVZU/dIvUJMSnk/VL90ceFZ3wO2UEyZDXKLNqQe2vzVe7nLxPGqY7vFdiZFTqeG6twf+1r3fypWAPwBExPWAa1M1gc6OiP2AAxrGehawf0SckJlNhjouVDcE6sbUvnNM9lM7fGrbtxrlHDONdzcCBwPN6uZvqIbldh4HvDUzn9lmzeY15LE+tMcy7BDToY/1obfvomDIYcmbMPc8GWd377c09P75VOAzURPafYV+h+l6nW1oQ5PLXXmJgzNznb/xBljtJQG+DfwX1cCrlWW175ur2bOAj0bEvsCXGaCc0FzPKavFat++AU3lviUzN1r/pxbPBPTytYYl1lteqMw8BTgFICLuBhybVVu0b68GbgU8Gvh4Zl7QJYh2pWrPvJqqkdTSt1jFN3eZeUJE3JzqmXgX6vf7F+CtVM3wuWrYLcZZVFIWYDvgzMz8cffzBaxbEmApfkD9zb4VNdHH32a9n9l4hmKAiHgKNTpgC+rG8jbAsRFxEFX79m2NQk1l+y5qunPMu6ga+m+Z0mpsBOzWrcNSEtCbU8n0IQx5rK+j+7vtAZy03g9v+LL3b73M9Rj0WJ/C9q16Az9Y/RB4WkQckmtPLBzUfBo/bBxv6GvR76n6hh+Z4/2k3bOK19m1DZYs6+7t96PuoRadgL4IJDWGbJBRQxeBfXM1uypVivQBwOPHXr+wnBDgSLHVYaU1Eq3K+xYT0MvXf+eAk/ONtB4utx4PBl6cmR8di38B1Qq5BTUJXOsE9Kovip+Zp0ZNkHZT4OpUz8Wf9NCo8B3g+d0ECntRNYJGrkc9WLbyRurGfM4ZiluLiCdQifsPUA8C4xM4fpPaf1sloAffvouwS1DlfqZpqZN7AHydmnR0iMnlhjzWJ1pFw+Y91rUhXk6NFPtFV4t9NKrpocD1gfs2jjf0/vle4GHAQQPE89hbW4vr0HKOtxIN2SAjqexHdTR6Bl4bVruVdh2a+n1LNxL8MOCJ2WjSay9iIiJOpAqc/ygiTmL+1qHMRhNbUT3qZpf6GPk5Mz3uWhpNHPehOd5f8Td3EfFSqgf0ZmMvnxMRr8/MVzYM9VwqEfV54ERg77H3HkajWcE7uzP8DMXPAt6Ymc/reu+M+yXwnIaxdmf47Vu1uprns21CNcq8lqoDv9LtxUxPqbkml2vVmDbksX6hiLgl8BLgrsDlgdtm5rER8WrgG5l56CKX+wHqeDup+34+mZmPW0ycOexOz8f6lLdPDWXmod08Ga8EXsRMb6wfUGXKvtI45O4Mey16APCczHzrALF2ZxVfZyPiGcABmXnG+j7bdfbodYitFmXIBhlJZRvgMZn5qWmvSN8i4rKsv4NaUiPj15lbZrlZAde9NcAHgTMX+f93Z/r3LUGNfr1MqwWu6ESbmvk6NcR69P1QwxNOAnaiJsebbUd6GG7NKq/RFRH7UAmb9wEfZ2bW0ocD+0TExq2GiXWtYNePiM0z88+z3n4GcFqLOJ01wDcaLm8hrk3VApvkH1RCrJVpbN9qdjJzTwTzG6rO/Up3QvfvfnO836wxbeBjHYCIuDPV4n4iVWP6qWNvrwGeRI1iWYy7UaMbALZn2GvCEMf6NLdPjXUNLYdGxKWAKwB/zcx/9hRu6GvRP5i7I0Jrq/06+wbg9RHxFaqTxecyc9knELSWIRtkJJXfchFo7JnVQW3UmL1OB7Wu88q1p7OWG2zw615EHEcllT+WmX+a77OZmcBSJoRflfctJqCXp0FbnTJzj7Hvdx8qLvB/wBsjYjPgo8wMLd2VqsH0rNYBl3GNrqSS/0stk/EEqtfueO/cnwFHRMTfgT1Zu/fikk1ISJGZP2kZAzgQuA/D1u4+8/+3d9/xklR1+sc/z4AEYZcliChLRlEXVhclqmREERQMKEg0wa4Jl12VHxlEEcy6GFAQWBAVI6DEcQAFhQUkKIsKDC6SQUmShnl+f5y6TM+dvndm7q3u6q77vF+vec3trr59vmemqqv6W+d8D7D6GNvWoVqUrSZN9K/Nui289jjls/XK6i74sOv7zbQ+HesjjqHcANqJUnuvMwF9NbDnRN/Y9hodP68+0feZoJ4f6w33L3qkSjr3KvE8ot/nopOA3eg+EKFubT/PrgK8A9idMgDhIUnfA0613bovsC3VzxsyEVF8HPiopOm2H2k6mF7o5wC1PmvivHcncBxwrKSLKMnoH9l+vAdttfK6RSUxH4NK0nuB02w/2qf2DgW+YfuOLtueB7zH9pE1tvcJSqL5WSNPUe5Cfsb2QXW10wRJTwObdKvlLenlwBW2a13UoCpQ/0bbF3bZtg3lzuBSdbbZD5LeCHyO8gE8Vu3uWmvhSvoq8FrKCMLbgKeAlwP/R1nM8hzbB9TUVt/7F82oyrk8BbzC9tVNxzOoJP0NeFNVgmCufzNJmwHn2V5yEu8/kePpHttvn2ibVbt9Odab6l8Mt36fiyTtC3wM+OM47c2vjMyCtjVlzrOS1qMs8L0rZar1bcB/2z6koXhy3lsA1Xei53UODIqI3pJ0KqXU21KUknKjzw22vVffA6uRpDso+aR5ykdK+jSwm+3n9z+y+vTzvCdpRcrN892B9SkDCL9PSXz/vMZ2Gr9uqRa9PhT4mu1aZrwmAT3gqiTmI5QFKb5m+7o+tNfvpOmywMaUhcEeAH5le8KrZA8KSbOBjcf4t9wQuMx2rbMQqqTDBbY/2WXbgcC2treqs81+qP4tu3lmheIe7JcrAL+k3F39NeXi5DLgRcA9wKa2H6yprb73r20WMuFm21v3LJhx5Iv4gpH0APBu2z/okoB+G/AF2ytN4v3vAF69ML8CTLfdrb74wrTbl2O9qf7FcOv3uWic9p5pt672puJ5tvriuD3wVeD5TfWv+gx/Etgg572x9fOGTEQU1fpX47HtNfsSTI+0dYBaN/0+70l6MSXxvRslZ3C77dVqeu9Grlsk7UkZaDfPzFdJy1HWIBlrPbX5SgmOwbcWsC+lCPl+kq6gHFDf6dFQ//FWB12WHpQGqZLNPxvvNdUKnH8EdrT927pjqFMV68i/47TqcaclKdMpJlqQfjwfBH4oaRZl2sbIFJtdKGUJ3tgZj+tbpKzXtux3g7bvk/QKymJv21FqBy8KfBn4nO2Hxvn1hdX3/rXQNOYuSbEOpaTPTOYcB6tTpk7d1OfYOtVVbqftfgHsL+nHHc+N/P++C5jsHf9Ztm9emF8o17ST1q9jvan+xXDr97mon3Ump9R5VtLmlNFZbwGWoYbFdyV9EDjD9j3VYr932n5qQX99su1PAV+p/l4N6HaT3EAS0BE16ixb1mK/BjagrK0y2gbV9qHXi/Pe/Ni+UdKRlJKnxwD/WOPbN3XdchKwCTBPAppy3XYSpeb2hGQE9JCQtCiwM2XhpS2Av1L+479u+8ZJvvcWlDIDAAdTdqrR9W2XBF4PPGp7g8m0NxHDMmpQ0mGUaQoL4njbH6i5/ZGE8lgLsHU+77pHYEcMAkk7URZh28X2rzue3wj4DvAh2z8e49cn0+66wObMmc0xY9BvmA0qSS+lzECYCZxJqV33JeCllFI4G9ie8I0ESX9a2NG+E/mdprS9fzH1VKOaDqFc99a+8GkbSHoRZSTWO4BVKYtr/TdlWvCkb7x2zpIcb8ZkTIyk+Y6as31bP2KJiHlVg7guBPZ1WaB7YI0aAPcS4IfA15l3gNp7KKOjh7L+fK/Pe/Npe6uq7TdRFne8omr3+F6222vzmcW/GWW2/eITfv8koIePpLUpReRHptf+AjjW9jkTfL/DgMOqhyND+kd7krIwxvtsXz6RdiZjiBLQm1NuEIzUy/kmcPuolz1B+bc8u+4RyJIOZyEWJrN9RJ3tt42kvSi1pFYFlhi12bbX6n9UMT+SrgeO6zY9SNLewAG216uxvUWBb1H2lc7PTwOnA3u7HQsf9pWk9SkLfWxGWYhwNnAp8O+2r5nke7c6Qdv2/sXUkzIO45N0FfAyyuyaMylfgi+uuY37gX1s/6T6grqR7SvrbCMWTG7IRPTfsOQj4JkkYmdOYPRAtM7nZw/joLR+nPe6tLkuZZT1bpTRzjOZk/Ae6JsS45H0Mko9ayh5xqOB0eVplgTeDixre92JtjV0O9pUJunvKHdZ9gXWA66h3MXaEfiJpKNtL+jo22dUScgjqjbGvOMR81d96F0MIMnACe6yoGMP2z+8X2310wLU9629pq+kQyjHxQ3Ab+hB+ZmOtvrev5Z7AXDvGNvuAdauub3DKKMIDqVchNxFKf+xe7XtFubc5IsFVF3cby1pCcqo8r/a/lvDYU1KjvUYZEOwf064jMMQ9G2y7gSOpdTy7EWJPiizUk6WdG31+CuSxipHNuz/noNuGuW64mzKNUdERKcjWYhBaUOqH+e90a4DHqTk4E6x/YteNdTn65Y3MveA1IPGeN39lFKIE5YE9BCo6tDuS7njsCjwXeC9HVPLj6mSZfuz4OUfurI9ul5xTFBGF9dqdH1fgOUpdX7vBX7fgzbfRVno7MM9eO/Rmuhfm91K+czsVlt+X8rd6jrtDnzc9tEdz90GHF2NltiHJKAnrLqo7NuNvB7LsR6DrM37Z5v7hu0d+tDMeyjnshdR/i0XBZ7Vh3aju9TVjoiu2joorVOfznuj7QKcZbtnA9M69PO65fOU2byiDJx6E2Wwa6cngLs9yRIaSUAPOElXU2pe3kq5k/VN2w90eekFVKOYa2p3JbqXHcD2JXW103ZVSY7xSjhkdMgCsL1Ft+clrQX8CPhED5pdHjirB+87j4b612ZHAKdJuoEyJWuk1tlbKF+c31Fze88HLhtj22WMfRc5xiBpfjdTbfuoSTSxvKTTFyakSbT1jD4e6430L4Zbm89Fbe4bgKRNgeVsn109Xp6yaPK6wHnARydbCsr23cC/Ve8/mzIYJjMmIyKi7/px3hvN9pld4liOsjjfDXUmpvt53WL7QcrIbiStQVlk+Mm63r9TEtCD73ZK8uLc+dxtuJoaVhOXtDJwKmUhrXk2U+7CLDLZdqYCSftSVrR+gHKHavQHUr7wT5LtmyUdQ6kT+y81v/3FlJs/85v+0jM97l9r2T5D0n2URPSBlBFaTwFXAtvZvqjmJu8AXkn31aU3pT2jd/vp8HG2jZwLJ5OA3n4Cv/OFSbQ3rh4c6wPVvxhubT4Xtahvn6Kcg86uHh9H+Ry4EPhXyhfLyXxmjrYGZfpzREREE/p93kPSwcBStg+sHm9Wtb8U8GdJW/e6FnSvr1s6F7uVtCLdB6T+aaLvnwT04Ps0cHW35LOkpYH1bV9S3aGoY2Xkr1DqS38EuJ4e1r2dAg6gLED2zl7dQQqgTEF5YQ/ed3/gB9WiOz+l3EiYS92LSI6hV/1rNdsXAhdWq0CvANzXw/+v04CDqhFhp1G+lK9EKZt0EOUCKRZCt3JQ1QiDHSifrTtN8v17ukjJBNV2rA9o/2K4tflc1Ia+vQg4BkDSsygzfva3faKk/Snlp2r7Ij7yBVXSDpRBK8tRrpN+bvundbUTERExhr6e9yq7A5/pePwp4FpKLepDq/beXnOb3fTsukXS31MGpbwNWHyMl014QGoS0IPv58AmQLcpbutU2+sckfxq4IO2T63xPbuSpIWoITObMppxmEYSrgyclORz71RTbf4duLkHbz9SV+mkMbaP1D/smR73b0qoks739LiZw4E1KZ9Rh3c8L+DblPJJMUlV+alTquPiv5jYKN+BlGM9Blmb988W9W1pYGRBwA0po7FGRoVdTSkFV5tqYfSzKd8bZlEWJloe+HdJlwI72H6kzjYjIiI69PW8V1kZ+AOApOdU7W5te4akxYAv9qDNufThuuW/gDcD36QHA1KTgB5845VpWByota4N8Bi9T9aMuE3SCZS61uMmlqtE9bAt6ncVJSlV93T/KUfSrcxbhH8xSl1fKB+Sdevb6sEN9S9qYnsWsJuko4HNmDMS7BLbv200uHa6lvpHNPRFjvUYZP3eP6sZKtOqz9CR57aj1G+cbrtzARxTZvpN6IvQFDj2/kwpG3Yp8DpKLcqR6/llgb/V3N4ngPWBPYAzbD9dLbr7dspsyk8AH6y5zYiIWkm6BjgZ+HZV5348s6vX3tfzwGJB9Pu8ByX3tlj182bA48Avq8f3Ur4D1qLB65bXAv9p+7968eZJQA8gSatTEpcjXlGV2+i0JPBOYML1V8ZwAuVi8rya37eb6cDHgEMknQ181fb5fWi3Xz5IWQjtpizcOGkXM+8H8OOUL6Pfs137HcA+rx7c9/5Ffar6X1dXyebfjtq2FPDyfAbUagfKRd4wyrEeg6zf++e3KQnlPQEk7QccX217StLrq3JKI7NZJrPWSduPvW8Dn5C0BWV2yGEd29anGrFVozcDB9s+beSJarGn0yStQCnllwR070zqhkxEPONOSi3dYyVdREkw/8j246NfWA2I26fP8cXY+n3eg/I9b3dJl1FycRfbfqratgr1DuRs8rrlpl69sRa8AkL0i6TDKAdQ539O50hoV49nAe+zfUKNbb+XkhS+FfgZ3evenlhje8sAewHvBV5Stft14ETbw5pgAEDS/wF/T5ke8jfgL6NeYtur9T2wiKiVpKeBTWzPUypJ0suBK2xn8daFIKnbeWYxysjI9YDDbH+8v1FFRJ0k3UZZpf6M6vHNlFljB1CuBVeyvWWDIQ6NavTxx4CNKQvuHl0lhJH0I8qX5M/V2N4TlDIbF3TZti1wlu15Fi6K8UnaC9iVMnV89L+fba/V/6gi2q1aaG03Sn3f9YGHge8Dp9r+eZOxxdj6fd6r3nc74MfMWeB+u5F1VySdBjzb9s51ttlvkr4EzLb9oZ68fxLQg0fSasDqlCTzdOB9wO9GvewJ4PdVTcw6257fIl3uVSJF0qspiei3UPr+I8qo6Bm9aK/XJH2L+ZRwsJ27qBFDrvrc3HiMBPSmwAzbi837mzEWSTMZ+67/GcDJC7GGQEQMIEmPAa+xfamktSlrL7zM9nWSXgOcbnuFZqOMbiT9L3Bety+okj4HvNb2i/sf2fCSdAil3OAN1Z95Rjfne0NEb0l6MWU2+G6UEa23Z8BYdJK0BuVGxW86RyFL2he41vavGgtugiRt1fFwKeDzlBHYP6X7gNTpE20rJTgGULWy9Mjq0ltSpnY/3KfmJzO9cbJ+CTwHWBvYCNgReKukq4C9bN/YYGwLzfbeTcfQJpLWBHZh7FEh7+p/VPVpe//apuFSSa1ne/WmY+iVHOsxyPq8fz5EWbgOYAvgPtvXVY+f7tL+pOTYq9XXgM9U573TKNPYV6LUgH43ZYGkWDjvAr5g+8NNBxIxVdm+UdKRlFILxwD/2HBIMWBs30qZtT/6+a/V3VYfr1suZE6VhZG/1wD27myvY/uEB6QmAT3gRob097G92/rZHoCkVYD3UBI1KwEXAG8EzgG2Bj5Lqce0Yb9ji8EgaSfgu8A0Sm2l0aNChnokZNv711J7MadUkoEvMU6ppL5HFwMpx3oMsgb2z8uAj0maBexPGWkzYm3g9roaavuxJ2kx4EDmlG9YfNRLbLu27322PyfpOZRE894jYQBPAsfY/kJdbU0hywNnNR1ExFRVjQLdA3gTpYTmFcAnGw0qxtTv815Hu9MoealuSWFsn1JTOzvRv+uWvpU7SwmOASTpFmBn29eOsfplp0nXA5P0z5RyHvMU2x/1umWBLW3/YDLtdbzfjsC+wHbAg8BJwFds3zLqddsC5wzbFHZJe87vNXV9QLWdpOspo2veMey1wbtpe//aqMlSSW1VLea4wIZxYccc6zHI+r1/SnoBJem8FnALsI3tmdW26cBtdZUcaPuxJ+kLlPPQz4Dr6V6+4YgetLsspf7mcpRpur+yPXrNk1gA1YLsF9VdszQixiZpXUrt590oo51nAv9Nqf/ci0XsoiZNnPckvYRSJnYt5h541NFkPeVq23rdkgT0AJJ0EnCk7Vv7UUd49AJa1V2dvwKvtn1tx+s2Ai6r8aCaTSkYfzxwhu2uKzlXUw8OGba6Z+PU037m/zMLky0YSY9Sbsqc33QsvdD2/rWdpM2Bq2w/sgCvFXAI8HXbd/U8uCFSfWZ2O991G1nes/UIeinHegyypvZPScvbvn/Uc+sBd9X1pavtx56kPwPH2z666VhGq75X/BHY0fZvm45nkFT/NiPWBH4AfJqx627Ob62eiFgI1bXng8D3gFNs/6LhkGIBNXHekzSDMvL5Pxk76V1LRYG2XrekBMcA6ky09qmO8Oi7N6JMO+n1l/tX2L56fi+qRkQPVfK50q2e9vLADsxZaTcWzP8yp05kG7W9f622kKWSplFKd5wNJAE9t75N/2pQjvUYZI3sn6OTz9Vz19fcTNuPvaWBy5sOYgyizBgaPT06SpmuzhuvoswI7cbku3tE3XYBzhprIFwMtCbOe+sDe9dVEWA+GrluqWagjWXkhs1VwDdt372w75+T2ICTdCjwDdt3dNn2POA9to/sf2STtyDJ52E2xt2v24Crq1GQ/05JRMf8fQT4vKRfjy7R0hJt71/MrduUrSmvWyJf0t8D6wIrA38Gru/jory9kGM9Blmb98829w1K7eDNKCWhYngcyZDXH48YZrbPbDqGmLAmznv3UdY66IemrlsEvBB4HmWxxbuB51IGV95ZPd4e+LCkzW2PLkE5/punBMdgG10eY9S2lwNXTHYacjX1ZOOOEhyLAE8xaoRy3SU4qvdckVI4fh2m0Irk1SIHP7S9TNOxDANJl1JqLS0P/IF5pyXa9uZ9D6wmbe9fzDHW52vMq7oBewBlhMPIqsuPAMfZ/niTsU1UjvUYZG3eP9vYt6pE3YjnAKcApzF2+YZGEu8570VERB2aPu9J+gAl+bqD7afrfO8ubTVy3VKt0/Z54K2jcoEvpyyK+O+UEdDnAzfZ3nlh3j8joAffeCPllqVL3ZlhIWkdyrSJRYGlKHeUlqOU/vgLZXh/W21MSaTEgnkauKnpIHqo7f2LWCiSjqDUyv4GcAZz7r7vChwhaVHbhzcX4YTlWI9B1ub9s419+yPzlm84nFLmqZuhq5sfERHRoe/nPUmjqw28CPidpAvonhQeK5aF1dR1y8eBw0ffMLZ9VfX97OO215N0HGXNgoWSBPQAkrQFsFXHU/tK2mHUy5YEXg/UtZjHjtUqsFBqlBp4g6SXdbxmzXl+a3KOoyxCuBPwKPA64DpgT+AIYKHupgyaavTeaItRppO/HvhyfyMaXra3aDqGXmp7/yIm4D3AZ2z/Z8dzvwWmS3oQeC/lgnOo5FiPQdbm/bOlfRvG9VEiIiImqonz3sFjPP+CLs+ZsZPhC6XB65YXAmMtAH0vsHb1882UQaQLJQnowbQ5c3Z00/1AexL4HfDBmto8qMtz3RKoddZs2QDYjzmjuKfZngWcKOk5lKH/w7wo1eFdnnuCUgf6aOCTfY1mimj7autt719EZRngvDG2nQv8ax9jaUSO9Rhkbd4/h6Vvtk+e6O9K2gy4yvajNYYUERHRM02c92xPm2ib/VLzdctMykCgc7tse2+1HWAFYJ5FpOcnCegBZPsIygjgeeoz98gaPXzv8SwNPGB7djWibYWObVdSpl8PrWH4sGqptq+23vb+RQD8mnKT8sIu2zaotrddjvUYZG3eP9vct5GazD+nfJamJnNERLRaE+c9SQK+SSln8adeN0d91y1HAv8t6Trg+8A9wIrAmykz+XerXrcNE/g+lgT0gOtHEtP2bb1uYwwzgZWqn28C3sqcOy07AH/tf0gRET1lyiyIoa3f3yvV3fsRHwR+KGkW8D3m1IDeBXgn8Mb+RxgR0RrjrTEz/1+W5AVfyX42ZWDNHZNpMyIiYhImdd6bgGnAXpSyq71OQNfG9rcl3Uc5b/8/4FmUhYT/B3iN7ZHBQf9OqVO9UJKAHhKSVgJWBZYYvc32JT1obwXKQnnLA2fZfkDSEsCTtmfX1MwFwLaU5MJngTMkvQqYRSnufnRN7TRG0rMpyZLNKQssPkC5+3aS7ceajC0i6iHpFmBn29d22bYu8BPbawJUn59NzToZdLOYd2GRY6o/jHr+OnINExHRlNsknQB80/a4ieUqUX1Ef8KKiIgYGP1OetfC9gXABdXgoBWA+0bnAG0/PpH3zpe3ASdpZeBUSgJzns2UL+u1rWpdTRU4FvgAZcE8U6YqPAD8GPgFcFRNzR1INU3A9nclPQa8nbLA4heAE2pqpxHVTYMZlELutwF3URZyfDPwAUlb2L67uQgjoiarM/aUpyWA1foXylA7knrXGYiIiN6YDnwMOETS2cBXbZ/fcEwRERFRkyrpfE+d75kE9OD7CrAe8BHgeno/bftA4P2URMAFzF3X5SxgD2pKQNt+go7+2D6raqMtjgWWBV5t+5cjT0ralFJP51PA3s2EFhE1Gytx+gpSTmiB2D686RgiImL+bO8t6UOU6cXvBc6VdCvwdeBE2/c2GmBEREQsEEmHAt+wfUf183hse8L5wCSgB9+rgQ/aPrVP7b0bONL2J6ti7Z3+CKw1mTeXNH0hXm7bW0+mvYa9DvhoZ/IZwPZlkg5m3mnlETEkJH0Y+HD10MBZkp4c9bIlKaV3zuhnbBEREb1m+0Hgi8AXJb2akog+HDhC0o8oo6JnNBZgRERELIjDKWux3VH9PB4ziQGpSUAPvseoedj7fKwM/GqMbU8CS03y/acx90jBdSgLEc5kziJTqwN3UhYmHGZLM/aCK7dX2yNiON0CXFT9vBdlYYbRI76eAH4HfKOPcUVERPTbL4HnAGsDGwE7Am+VdBWwl+0bmwwuIiIiurM9rdvPvZAE9OA7gVL24rw+tfdnYF3KQnmjvRS4dTJvbnuLkZ8l7USp9byJ7V93PL8R8J1q2zC7ifJ/d26XbbsD/9vfcKaMtq+23vb+DQXbP6bUxaeUzudI25P6fIwYJcd6DLI2759t7lutJK0CvIey4PZKlPJ9bwTOAbamLDJ+MrBhUzFGRES03NBct6gsTByDStJ7KYt83Ar8jLIY4Fxsn1hje5+iXETuRBkJ/RTwcuBRyoIjX7d9ZE1tXQ8cZ/uULtv2Bg6wvV4dbTVB0u7AKZR/t9Mpo7pXoiy0uA2wh+3Tm4twsEladWFeb/tPvYqlF9rev4gocqzHIGvz/tnmvk2WpNWAO2w/NcHf3xHYF9gOeBA4CfiK7VtGvW5b4Bzbi00y5IiIiK4kLQ0szzjntcme9yYQ0zTKbNn32v7DAv5OI9ctkmaz4AvB2/aEBzInAT3gqp1hPLY9ulbzZNpbEjgf2BS4jVIO4xZgFeAyYDvbo+ucTrStx4Gdbf+sy7btge/bXrKOtppS3UA4Elix4+m7gUNtn9BMVMNhIT8IqfM46Ie292+qkbQmsAuwKrDEqM22/a7+RxWDIMd6DLI2759t7ls3/TwPVf+2VwLHA2dUC4uPFdMhtvepq+2IiAgASTtQci0vpZzvN7R9taRvANN7NdhP0j8Dm1GS3l+zfZektYG7bT88ifdt5LpF0uEL2e4RE20rJTgG3xr9bMz2Y5K2AHajjGr4I3A/pdD4abZn1djcrZTRE/MkoKvnZ9bYViNsf736AFyHshjZA8BNtud3YyHKSPyRD8LFgYOBh4DvUpL4K1G+aP0dkyiE36C292/KqMoJfZdS4/4eSu3nTrnTO7XlWI9B1ub9s819m0sD56FX2L56fi+qRkQn+RwREbWqznvfp4wy/ihwbMfmWylr9NSagJa0OPDfwJsAUS1ED9xVtf97SvWCiWrkusX24XW91/xkBHQ0RtLbgdOAG4EzmbMI4VuAFwHvsP2d5iKMQSHp85TR+Du740NLpfjuj4BbbH+4keBq0Pb+tV1VTuhOymfW6IUII56RYz0GWZv3zzb3DXIeioiIqUXSNcBVtt8taVHgSaqbo5LeCBxve+Wa2/w08C7gfZQ1D+7uaPM9wL/Z/pea2vo8LbxuSQJ6AFVD+n9v+/H5vG5ZYEvbP+hPZPWTtA2lYPorgGdRak5fCRxm+6ImY5ssSZ8DVrC9R5dtpwJ32f7P/kc2fCTdDew9RrmW1wHfsv3c/kdWj7b3r+0kPUq5ODi/6VhisOVYj0HW5v2zzX2DZs5DklYEdqXM8kvpqYiI6JuqnOuOti+QtAgljzSSDN4MON/26HPTZNv8M/AJ2//Vpc1tgO/ZXramtlp53ZISHIPpGmAT4Ap4poD5X4FX276243UvBL4H1FkD+lbGnqY3m7LQyFXAF23fMNn2bF8IXFj1cQXgvhaVp3gDcPgY284DDgOSgF4wSwPPGWPbisBSfYylF9rev7b7X0oNsIj5ybEeg6zN+2eb+wZ9Pg9JWge4nPJdcingPkqpuUWAv1C+L0RERPTKQ5T8UTerA72YDbQ8ZfZ+N9MoZTPq0srrlmlNBxBdqcvjpakx0TyOi6t2nkepnfOr6u/nUy4ybwN2BK6UtGldjdqebfueFiWfAVYGxlqZ9PZqeyyYGcAnJG3Q+aSkDYGjq+3DbAbt7l/bfQT4f9ViSxHjmUGO9RhcM2jv/jmD9vYN+n8eOo4yY/G5lO8prwOWBN4N/A3YuU9xRETE1HQBcKCkf+h4zlWd5vfTfZ2xybqVMlC0mw2Bm2psawYtvG7JCOgY7VJgfWAj23eNPCnpeZRRuz8D9qAUez8C2LaJIIfEX4C1KUn90dYGHulvOEPt/cCFwK8k/R9z6oWvQjkRvL/B2OrQ9v61jqRLRj21PHCjpD9QFhvtZNub9yeyGHA51mOQtXn/bHPfoMy46+d5aANgP+YsdjitWqj8REnPAT4PbFljexEREZ0OolQMuAn4KWUW/8eAfwaWAXbqQZunUG72zqQsgAgl6b0l8GHGnv0+Ea28bkkN6AEkaTawse2REhxz1ZfpeN1GwGW26yzB8Xvg/9k+s8u2XSg1b9aWtCvwVdvL1NV221R1nl9F+b+8u+P551KmLV5u+x1NxTdsJD0L2BvYmDJC/07Kv+PJtp9qMLRatL1/bSNpBmOXK5qH7XwRDyDHegy2Nu+fLe/bDOZzTqrzPCTpYWB725dK+guwq+1zq21bAT+xvXRd7UVERIwm6R8pgyK3o5SluB84FzjU9v/1oL1FgNOAXSg3YBcHHqOsg3BG3bmdNl63JAE9gBpOQD8G7GL7rC7b3gB8x/aSVWH382wvWVfbbSNpdcr0xMWBs5lTdmMH4HHK//GtjQU4JCQtBnwKON32lU3HU7e29y8iihzrMcjavH+2uW9NkXQ9cKTt70n6FfDbkUUHJX2W8l3iHxsNMiIiogckvZpRSW/b3Wa9T/T9W3vdkgT0AKoS0EdThtZDqdX9NeAo5q4pvCZwYM0J6KspBd23s/1Ex/NLAOcDS9teX9LbgWNsr15X221UJaGPpJQqWZ6ySMv5wGG2b2swtKEi6W/Aa22PLnvQCm3vX0QUOdZjkLV5/2xz35pQJZmXtv3eaobkGcAfgFnAi4CjbR/aZIwRERHDqq3XLakBPbgO6vJctwu5uu8gfIQyWvdPkn4K3EO5s7M98A/V3wCbUhKpMQ7bM4E9F+S11ajyq2w/2tOghtM1wHpAqz6AO7S9f61WHbtjmQ08CPzvsE6VilrlWI9B1ub9s819A55Zr+UAYHNgOUod6J8Dn+1c16UmB1Jm+GH7u9UMyrdTFiL8AnBCze1FREQ8Q9KJ83mJR2bmDKlWXrdkBPQAkrTawry+7pG0kl4CHAxsxJxaM78CPm77xjrbiqIqs/IksEFnmZUoJG0MfBv4AHCOW/bB1fb+tV01a2V+/2d/A75ou9vNxZgicqzHIGvz/tnmvgFIeiFlIfFlgV8CdwErUQaM/AV4te0/NBdhREREfaqFAEefy5cD/g74K/BX22vW3OZ8v/PVVZ2grdctSUBHDICx6nxHUa38ugywFOXf6V7m/vC37YW6cTNI2t6/tpO0I/Al4FrgTOasUrwLZSXmQ4ANgX0pZZM+3VCo0bAc6zHI2rx/trlvAJJ+CKwLbFvNvht5fjXKjMXf2n7TJNuYvhAvt+2tJ9NeRETEwqpmpn4VeIfta2p+78OZNwG9PPAayqygb9k+oqa2WnndkhIcQ0LSCpTVL5cHzrL9QFWX+Unbs5uNLqLnLqL+cjODpO39a7udKItP7Dfq+VMlfQ3Y0vY+1V3zdwFJQE9dOdZjkLV5/2xz3wC2BPbrTD5DmSVZfWE+voY2pjH3v+E6lFHWM5lz43V1yszJm2poLyIiYqHYvkTS5yiDg15V83sf3u35ajDhWZSyi3Vp5XVLRkAPOEkCjqUMvV+MshNuYPtqSecBv7B9VM1trgjsSrmwXGLU5mGvpTOQMgI6YnhJegB4m+0LumzbFviO7eUkbQ/8wPboz9WIiIgJqxYreqvtc7ps24FyHlqqxvZ2otR63sX2rzue3wj4DvAh2z+uq72IiIgFJWlr4Cd1nvcWoM0dgC/bXr1fbQ6jjIAefAcC7weOBC4Aft2x7SxgD6C2BLSkdYDLKfvGUsB9lFo6i1BqyNV5Vyciog0WAdaifEaPtna1HeCJ6k9ERESdfgN8QNLPOmdGVgNZ/q3aXqejgEM6k88Atn9djbj+OJAEdERE9JWkRYG9gdv73PTilLxZjGNa0wHEfL0bONL2J4DRI2P/SEl61Ok44ErKNDoBr6OsaP1uyiJaO9fcXsQCkbSepDMl3StpVvX3dyWt13RsdWh7/1rup8AnJL25ms2ApEUkvQU4GhgZkfZPwM0NxRgDIsd6DLI2759t7htloMo2wI2SjpT0r5KOAH4LbAvUUpOywwso9Si7uYdy8zUiIqInJE3v8ucXwB3AbvSg5KGkVbv8WbuaFXQM8D81t9e665aU4Bhwkp4AXmv756PLNEjairIi5pI1tncnsB9ldPUsYEPb/1Nt+2gVy5Z1tRdFSnCMT9IGwMXAY8BPmLO6+46UGySb2b6quQgnp+39a7uqRv8PgVdSPjf/AixLmUnyS2An2/dL2gt41PaZjQUbjcqxHoOszftnm/s2QtJrKSOP/4UyiMTAVZSRyufV3NaNwE22d+qy7cfAC22/uM42IyIiRkiawbw1kh8HbgPOsD2jB23O7tImlHPuzcAbbN9YU1utvG5JAnrASboF+JztL3VJQH8YeI/tl9TY3sPA9rYvlfQXYFfb51bbtqLU0lm6rvbaRtIbgIttL1SpkiSgxyfpQuDvga1tP9zx/N8BFwIP2n5NU/FNVtv7N1VIeg2wEfA8yiJMv+pWFzqmrhzrMcjavH+2uW+jSXo25SboX2z/rUdtvB04DbgROJM5ixC+BXgR8A7b3+lF2xEREU2QtDdjJ72vtP10jW218rolNaAH3/eAQyVdDfyqes6SXggcAHy95vZmUu6sQFnB+q3AudXjHYC/1txe2/wQ2AS4QtLTwCa2r5jfL9l+WtIalCkjMa+NgT06P3wBbD8s6VPAyc2EVZu2929KsH0+cH7TccRAy7Eeg6zN+2eb+zaXKunck8RzRxtnSLqPUtrjQOBZlIEUVwLb2b6ol+1HRET0m+1v9bG5Vl63JAE9+A4HNgUuodxZgZKUXgW4jFJrpk4XUGrFfQ/4LHCGpFdRppW/iFLPNMb2CLBM9bMW5hdt3zb/V01Z85uqMexTOdrev4gocqzHIGvz/tm6vkk6FPiG7Tuqn8dj27UtWl694YXAhZKmASsA93UugBgREVEnSXsuzOttn9KDGPYCdgVWBZaYt0nXtUZb665bICU4hkJVnmE3YDtgReB+yqjk02zPqrmtxYHFbT9UPd4ReBvw7KrNE5ydZkySpgOrU24Y7ElZfGysRVps+119Cm2oVVNQlgG2GjUFZSlgOkM6BWVE2/vXRp0zHMapBzbCtnPDN3Ksx0Br8/7Zxr5V556NO85D47HtRfoRV0RERC8swLmuU+3nPUmHUGb+3FD9eaJLo/vU1FbrrlsgCeiIWklaB/gcZbT4asB9wJNjvNy2V+1XbMNM0obADEqNpbMp9XVXAran3BzZwvaVjQU4SW3vXxtJOoxyQ+4OSYczn7vQto/oS2Ax0HKsxyBr8/7Z5r5FRERMBZJWW5jX1z3DXNJM4Ie2P1zn+47RViuvW5KAjrlU0+imdY6slrQdsC5wke3fNBXbsOkcmdJ0LG0g6Z+BQ4FXA8sBD1BWhj3K9vVNxlaHtvcvIooc6zHI2rx/trxvqwJ32n6qy7ZFgefb/lP/I4uIiGgHSQ8Db7Q9vU/tte66JQnoASfpVsYeWTcbeBC4Cvii7RtqaO87wBO296we7wccX21+Cnh9VfMt5kPS5sBVth9pOpZhJ+l1wCW2H206ll5oe/+mEklLA8sDd3RLBMTUlmM9Blmb98829w3mLgvVZdvLgStSgiMiImLiJJ1NGZT5uT601crrliSgB5ykbwFbUmo/XwbcDTwXeCVwF3A1sAnwD8DWti+bZHu3AR+1fUb1+GbgIuAA4OvASra3nEwbU42kdYHNmXPXaobt3zYb1XCpRpM/RbnZMr36c5ntxxsNrCZt799UIGkH4EjgpdVTG9i+WtI3gOm2T28uuhgUOdZjkLV5/2xz32D8WXeSNgYutf2s/kcWERHRG5JeA/wrsA7zLgiI7TVraGNax8M1gR8AnwZ+SsntjG6zlsV423rdkgT0gJP0LuBDwGts39Xx/POA84AvAadTksQP2952ku09VrV1qaS1gd8DL7N9XXWAn257hcm0MVVUUx6/RVklVR2bTPk/29v20w2ENnSqfXFrYAvm3JB5AriC8mH8c9uXNBbgJLW9f20naSfg+5TP4fOBY4FXVAnog4DNbG/XYIgxIHKsxyBr8/7Zxr5J+gfK4AaAPwJvBq4d9bIlgfcDO9hepX/RRURE9I6k7YGzgAuBbYFzKbWRXwncRrnxOukFAbssNi/GrlBQ28LzbbxugSSgB56k3wP/z/aZXbbtAnzC9tqSdgW+anuZSbZ3N7Cv7R9Jenf1/itW27YGfmx76cm0MVVIOgr4KGWl1P+mjFhfCdgdOAz4pO3DmotweEl6CbAVsDPlQ7m2D/tB0Pb+tY2kayjldt5d3Xh6kjkJ6DcCx9teudkoYxDlWI9B1ub9sw19qxbDPYz5LIJL+bJ8mO2jeh9VRERE70m6HLgS+DBlpPDId68XUgZqftT2d2to53Dmf559Rq8Wnm/DdQvA0AU8Ba1CudPRzePASFLjz8BiNbR3GfAxSbOA/SlTC0asDdxeQxtTxe7Ax20f3fHcbcDRkhYB9qF8cYgFJOnZlCL8W1LuCP4L8BClGP/Qa3v/WuzFwEeqn0dfoPyFUhM64hk51mOQtXn/bFnffgTMpCSYTwQ+Dtw86jVPAL+zfV1fI4uIiOitF1EW6BsZobwogO3fV0njQ4BJJ6BtHz7Z95iMll23JAE9BG4EDpB0vu1nEtGSlgD+o9oO8HxKfejJ+ggl6fwT4Bbg8I5tbwMur6GNqeL5lIR+N5cBB/UxlqEm6UjKHb8NKKNLf0E5oewHXFNXraWmtL1/U8BDwFiliVYH7u1fKDHIcqzHIGvz/tnGvtm+lqrkhiQDZ9u+v9moIiIi+mI2MMu2Jd0LrEopTwFwB7BWY5HVoI3XLZASHANP0jbA2cCDlMTwPZT6L9tTFh7c3vZFkr4ILGH7vTW1u/zoi1hJ6wF32U4yZQFIuhX4VrdpGJIOBfaxvUb/Ixs+Ve2lvwFfAY5t2z7Y9v61naTTgPWAzYCHKdPAXg78DrgU+E1dn80x3HKsxyBr8/7Z5r5FRERMNZIuA06wfZKksym5sbcCs4BTgVVtv6TBECelrdctSUAPgarey8HARsDzgDuBX1HKO9w43u/W1P5ywBrADZ2jsGN8kj5OGVF+FHAa5f9tJeDtlJHln7J9aGMBDhFJH6BMO9kcWIYy4mdkNdhLbT/SYHiT1vb+tZ2k1Sl33E25UbgncCbwz5T/z1fYvqOxAGNg5FiPQdbm/bPNfRsh6Z+AdwPrAEuM2mzbW/c/qoiIiPpJeh+wmu2PSHo5ZTHCv682Pw3s1m0dtWHR1uuWJKBjLpIOBpayfWD1eDPKCOylKHWmt7b9hwZDHBrVYmSnUBLOo1dO/Tawl+1ZTcQ2rCSJUvdoC8qUlFdRVru90vYrGwytFm3vX5tJWoVyY2k7yiyV+ymrMR9q+/8aDC0GUI71GGRt3j/b2jdJG1HqQc4EXgBcByxLmZJ8O/BH21s1FmBEREQPSfpH4HXAksCFtn/XcEi1aNt1SxLQMRdJ/wt8xvYJ1ePLKdMYjqUUeb/Z9tsbDHHoVCNSNgOWAx4ALrH922ajGl6SFgM2pRTh3xbYkDKyZ5FGA6tJ2/vXRpJeRzmuH206lhgeOdZjkLV5/2xj3yRdRFkLZg9KGahX2L5a0laUqch72J7eZIwRERF1kXQNcDLwbdt1rIU2sNp03ZJFCIeApBWBXRl7St27amxuZeAPVbvPoezcW9ueUe34X6yxrSmhSjaPm3CWNI0ybWTfjDCfl6RNKXf8tgQ2ARanjDCdQTnx/Lyx4GrQ9v5NAecAT0m6ijlToy6z/XizYcWgybEeg6zN+2eb+1b5Z2Av5sy4WwTA9vSqJNwnKaX8IiIi2uBO4Djg2Oom7MnAj9ry/aut1y0ZAT3gJK0DXE65WbAUcB9lJO0iwF+AB22vWWN7fwV2sX2+pDdTSkj8g+2nqnIc59lesq72opC0CB0jVpqOZ9BURfj/ClxCSe793Pb1jQZVo7b3r+0krU25I70F5SJhReAJSl3okf/PSxoLMAZGjvUYZG3eP9vcNwBJDwJvsH2xpPuAd9r+SbVtK+As20s1GmRERESNqoGauwG7A+tTFoP/AXCK7aFM0I5o63VLEtADTtJPKHc7dgIeBV5Bqeu2J3AEsIPta2ts75fAzcC/Ad+h7CPbV9veAXzC9mp1tRdFEtDjk7Q+cI1b+oHV9v5NNdXCsVsBO1OS0radGUeRYz0GWpv3zzb3DaCagfMZ26dLmg48BLyp2nwysKnttRoLMCIioockvZhShmo3YBXg9mHOW7X1uiUJ6AEn6U5gP+AsSi3mDW3/T7Xto8BrbW9ZY3vbAT8GnkVJiG5n++Jq22nAs23vXFd7USQBHTH8JD0beDVlFPTWlAUjHgYutr1Tg6FFRESLSToCeJ7t90rahqo0FPA0sDTwQdv/1WSMERERvSRpCeDNwDHA84exRnLbZUTW4FsaeMD27Gp63Qod264EDqmzMdvnVXeP1gd+Y/vmjs2XALWNto6IaANJR1JGPG8APAn8Avgu5ebhNbZnNxheRES0nO3DOn6+UNLGlC/hzwbOtX1+Y8FFRET0UFVqag/KzJ+lKWUQP9loUNFVEtCDbyawUvXzTcBbgXOrxztQ6sLUyvatwK1dnv9a3W1FRLTAwcDfKIu0Hmv73objiYiIKULSs4Dtgeuqa3hsXwNc02hgERERPSJpXUrt592Af6Tkzb4AnGr7Dw2GFuOY1nQAMV8XANtWP38W2EfSTZJ+C3wIOLHuBiWtLOmzkv5H0i3VwY2k/SVlBe2IiLl9CDgfeCdwp6SrJB0n6XWSlm44toiIaDHbT1Fm3azecCgRERH9ch2wL2Vw5ma217R9aJLPgy0joAffgZRFCLH9XUmPAW+jTKn7AnBCnY1J+ifgUkrNuMspNUwXqzavBmxIucsUERGA7S8BX5IkymfmFpSSHO8Bni3pStuvbDDEiIhot1uAFZsOIiIiok92Ac6y/UTTgcSCSwJ6wFUH1BMdj8+iLEjYK58BbgS2Ax6n1DMdcRnwqR623SqSVgXurEamjN62KKUw/p+qp2ZTVim/r48hRkSNbFvSDcDfA8tSavZvCGzcaGAREdF2xwIHSZqeMlAREdF2ts9sOoZYeElADzhJ04Bptmd1PLcdsC5wke3f1Nzkq4BdbT8iafSqoXczpx51zN+twCaUIvijvbR6fhEoiStgn/6FFhF1kbQpZcTzlpRjfnHgfmAG5cbSzxsLLiIipoKtgOWAWyX9CrgTcMd2296rkcgiIiIiSAJ6GHybMgJ6TwBJ+wHHV9uekvR62xfW2N7scbatADxWY1ttp3G2PYvx/60jYnj8grIg7CXAx4Cf276+0YgiImIqeRXwFHAvsFb1p5Pn+Y2IiIiIPkoCevBtDHy04/F/At8ADgC+DhwE1JmAvoIyErdbmY9dgF/W2FbrSPoHygiUEStLWnPUy5YE9gLu6ldcEdFTrwCuqWYyRERE9JXtNZqOISIiImI8SUAPvhWBPwNIWhtYA/iy7YclnQScXnN7RwEXSjq/em8D20j6ELAzsFnN7bXNh4DDKP9uBsaqTaTqdREx5Gxf3XQMEREREREREYMqCejB9xCwfPXzFsB9tq+rHj8NLFFnY7YvlrQT8AXgxOrpY4CZwE62f11ney30I8q/lSj/fh8Hbh71mieA33X8P0ZERERETEi18PW4Oha+joiIiOi7JKAH32XAxyTNAvYHftqxbW3g9robtH0OcE414npF4H7bN9XdThvZvha4FkCSgXNs39dsVBERERHRYjOZf53n0YuLR0RERPSNUrJysEl6ASXpvBZwC7CN7ZnVtunAbbb3mWQbWy3M621Pn0x7U4WkacA027M6ntsOWBeYbvuaxoKLiIiIiFaQtDfzJqCXB3aglO87yvaJo38vIiIiol+SgB4Skpa3ff+o59YD7rJ97yTfezZzLlo1arOr557523ZGUCwASd8BnrC9Z/V4P+D4avNTwOtt17mAZERERETEMySdShmwcnDTsURERMTUlQT0EJK0HGU0ww22n6jh/WZTak1/v/rz6Hivt33xZNucCiTdBnzU9hnV45uBi4ADgK8DK9nessEQIyIiIqLFqtl3J9l+ftOxRERExNSVGtADTtLBwFK2D6webwacDSwF/FnS1rb/MMlmtgD2At4CvBX4IXBySm1M2orAnwGqetprAF+2/bCkk4DTmwwuIiIiIlpvRWpetDwiIiJiYU1rOoCYr90ptZ9HfIqyyN1OwN3AUZNtwPYltt8FPBfYj3Khep6kP0n6pKQXT7aNKeohSv09KEn++2xfVz1+mnwZiIiIiIhJkrRZlz/bSNof+DRwacMhRkRExBSXEdCDb2XgDwCSngNsCGxte4akxYAv1tWQ7ccpo3JPl/Q8YDdgT+Ajkr5i+/11tTVFXAZ8TNIsYH/KYpIj1gZubyKoiIiIiGiVGcy7COHIui4XA//a12giIiIiRkkCevA9DSxW/bwZ8Djwy+rxvcByPWr3fmBm9eefgGV71E6bfYSSdP4JZRT74R3b3gZc3kBMEREREdEuWzFvAvpxyuKDdzUQT0RERMRckoAefL8Fdpd0GfBO4GLbT1XbVgHuqbMxSa8E9qDUgl4c+DHweuCCOtuZCqra3C+QtLzt+0dt/hCQLwQRERERMSm2ZzQdQ0RERMR4ZI++WR6DpFq5+sfAs4CngO1sX1xtOw14tu2dJ9nG2pSk8+7A6sAlwCnA92w/Mpn3joiIiIiI3pH0NLCJ7Su6bHs5cIXtRfofWURERESREdADzvZ51SKA6wO/sX1zx+ZLKAsSTtbvKQvm/QB4N3Bb9fyKklbsEtMto5+LQtKhwDds31H9PB7bnvQikhERERExpWmcbYswb3mOiIiIiL7KCOhA0uyOh/PdITKCYmzVv+XGtq8Y9e/ajfNvGRERERETIWkaJfn8FLApMHoE9JLAfwD/anulPocXERER8YyMgB4CklYGDqAsQrgc8AbbN0jaH7jc9q8n2cQ+k/z9qNie1u3niIiIiIi6SDoMGJltZ+YsUt7N8b2PKCIiImJsSUAPOEn/BFwKPA1cDvwLsFi1eTVgQ2C3ybRh++TJ/H5ERERERPTVjOpvURLR3wRuH/WaJ4DfAWf3L6yIiIiIeSUBPfg+A9wIbAc8DjzZse0y4FNNBBXdVWU3FrSujW3nGIyIiIiIhVItSj6yMLmBE2zf0WxUEREREd0l+TX4XgXsavsRSaPrBd8NpJ7bYDmSLPQSEREREX1i+4imY4iIiIgYTxLQg2+8hexWAB7rVyAxf7YPbzqGiIiIiJhaJK0I7AqsAywxarNtv6v/UUVEREQUSUAPvisoiwSe1WXbLoy/4EhERERERLSYpHUoa8UsCiwF3EdZuHwR4C/Ag81FFxEREQHTmg4g5usoYEdJ5wN7UMo7bCPpZGBn4Ogmg4uIiIiIiEYdB1wJPJeyKOHrgCWBdwN/o3xniIiIiGiM7JSrHXSSXg98AViz4+mZwPts/6yRoCIiIiIionGS7gT2o8yYnAVsaPt/qm0fBV5re8sGQ4yIiIgpLiU4hoDtc4BzJK0NrAjcb/umhsOKiIiIiIjmLQ08YHu2pAcp68SMuBI4pJmwIiIiIookoAeQpK3m85KVJa088sD29B6HFBERERERg2kmsFL1803AW4Fzq8c7AH/tf0gRERERcyQBPZgupNR6hlLHrZOr5zr/XqR/oUVERERExAC5ANgW+B7wWeAMSa+ilON4EVkzJiIiIhqWGtADSNJs4CHg+9WfR8d7ve2L+xFXREREREQMFkmLA4vbfqh6vCPwNuDZlJHQJzhf+iIiIqJBSUAPIEmbAXsBb6GMcv4hcHJKbURERERERCdJ04Bptmd1PPda4J+A6bavaSy4iIiICJKAHmiSlgDeBOwBbAPcCZwGnGL7xiZji4iIiIiI5kn6DvCE7T2rx/sB/0UZyPIU8HrbFzYYYkRERExx05oOIMZm+3Hbp9t+HbAq8AVge+AGSV9uNrqIiIiIiBgAGwM/7Xj8n8A3gWWAHwAHNRFURERExIgkoIfH/ZQVrmdSFh5ctslgIiIiIiJiIKwI/BlA0trAGsCXbT8MnASs12BsEREREUlADzpJr5T0VUr5jZOBR4DXU8pyRERERETE1PYQsHz18xbAfbavqx4/DSzRRFARERERIxZtOoCYVzVyYQ9gd2B14BLgP4Dv2X6kwdAiIiIiImKwXAZ8TNIsYH/mLsexNnB7E0FFREREjMgihANI0mzKSIYfAKcCt433etu39COuiIiIiIgYLJJeQEk6rwXcAmxje2a1bTpwm+19moswIiIiprokoAdQlYAeMd//INuL9DCciIiIiIgYcJKWt33/qOfWA+6yfW9DYUVERESkBMeAygiFiIiIiIhYYKOTz9Vz1zcRS0RERESnjICOiIiIiIiIiIiIiJ6Y1nQAEREREREREREREdFOSUBHRERERERERERERE8kAR0RERERMR+SPijpRkmnLeTvrS5pt17FFREREREx6JKAjoiIiIiYv38DtrX9joX8vdWBhU5AS1pkYX8nIiIiImIQJQEdERERETEOSV8F1gR+JukgSSdKukLSNZLeWL1mdUmXSrq6+rNp9evHAK+W9BtJH5a0t6Qvd7z32ZK2qH5+RNJnJF0LbCJp96qd30j6mqRFqj/fknSDpOslfbiv/xgREREREQspCeiIiIiIiHHY3g+4A9gSWAqYbnvD6vFxkpYC7qGMkF4feBvwxerXPwZcavtltj83n6aWAn5t+6XA/dX7vNL2y4CngXcALwNWtr2u7fWAk+rraURERERE/RZtOoCIiIiIiCHyGuANkv6jerwEsColQf1lSS+jJItfOIH3fhr4fvXz1sDLgSslASxJSXKfBawp6UvAOcD5E+tGRERERER/JAEdEREREbHgBLzZ9k1zPSkdDtwNvJQyy/DxMX5/FnPPQlyi4+fHbT/d0c7Jtg+cJwDppcB2wH7ALsA7F74bERERERH9kRIcEREREREL7jzgA6qGJUv6l+r5ZYA7bc8G9gBGFhF8GPi7jt+fCbxM0jRJqwAbjtHORcBbJK1YtbOcpNUkrQBMs/194GBg/fq6FhERERFRv4yAjoiIiIhYcEcBnweukzQNuBXYATge+L6kPYFzgUer118HPF0tLPit6ndvBX4H3Ahc3a0R27+TdDBwftXOU8D7gMeAk6rnAOYZIR0RERERMUhku+kYIiIiIiIiIiIiIqKFUoIjIiIiIiIiIiIiInoiCeiIiIiIiIiIiIiI6IkkoCMiIiIiIiIiIiKiJ5KAjoiIiIiIiIiIiIieSAI6IiIiIiIiIiIiInoiCeiIiIiIiIiIiIiI6IkkoCMiIiIiIiIiIiKiJ/4/7eihUxfGVwcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1800x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,8))\n",
    "\n",
    "sns.barplot(data=importance[:50], x='features', y='importance')\n",
    "\n",
    "plt.xticks(rotation=90, size=16)\n",
    "\n",
    "plt.yticks(size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_csv('importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (353815310.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [140]\u001b[1;36m\u001b[0m\n\u001b[1;33m    -----------\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'features': list(grand_df.drop([target], axis=1).columns), 'importance': regr1.feature_importances_}).sort_values(by='importance', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h</td>\n",
       "      <td>0.304991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>dtdays</td>\n",
       "      <td>0.165129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>second</td>\n",
       "      <td>0.079806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>🌍in_msg</td>\n",
       "      <td>0.059537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight_to_height</td>\n",
       "      <td>0.039626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>MessageEntityBold</td>\n",
       "      <td>0.033722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>list_of_count_colors</td>\n",
       "      <td>0.025665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_of_year</td>\n",
       "      <td>0.024766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>🐻in_msg</td>\n",
       "      <td>0.020455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>👉in_msg</td>\n",
       "      <td>0.012806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>speech</td>\n",
       "      <td>0.012598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.012435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>word_number_1</td>\n",
       "      <td>0.011787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.011762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>word_number_4</td>\n",
       "      <td>0.011577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>minute</td>\n",
       "      <td>0.011363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>pink_3</td>\n",
       "      <td>0.011118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>0.010984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>MessageEntityTextUrl</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>purple</td>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>r_mean</td>\n",
       "      <td>0.009769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>white</td>\n",
       "      <td>0.009123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>re_lemmas_count</td>\n",
       "      <td>0.008497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>s_median</td>\n",
       "      <td>0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>word_number_3</td>\n",
       "      <td>0.008177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  importance\n",
       "2                        h    0.304991\n",
       "1316                dtdays    0.165129\n",
       "4                   second    0.079806\n",
       "903                🌍in_msg    0.059537\n",
       "3         weight_to_height    0.039626\n",
       "1229     MessageEntityBold    0.033722\n",
       "998   list_of_count_colors    0.025665\n",
       "8              day_of_year    0.024766\n",
       "832                🐻in_msg    0.020455\n",
       "35                 👉in_msg    0.012806\n",
       "14                  speech    0.012598\n",
       "10                positive    0.012435\n",
       "1003         word_number_1    0.011787\n",
       "11                negative    0.011762\n",
       "1006         word_number_4    0.011577\n",
       "5                   minute    0.011363\n",
       "992                 pink_3    0.011118\n",
       "1                        w    0.010984\n",
       "1235  MessageEntityTextUrl    0.010100\n",
       "986                 purple    0.010066\n",
       "1338                r_mean    0.009769\n",
       "996                  white    0.009123\n",
       "999        re_lemmas_count    0.008497\n",
       "1322              s_median    0.008203\n",
       "1005         word_number_3    0.008177"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance.head(25\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 16:38:04,796]\u001b[0m A new study created in memory with name: DecisionTreeRegressor\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 100, 1)\n",
    "  \n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 1000, 1)\n",
    "  \n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 100, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = DecisionTreeRegressor(\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                random_state=42\n",
    "                                )\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = metrics.mean_absolute_percentage_error(base ** y_test, base ** model.predict(X_test)) * 100\n",
    "\n",
    "  return score\n",
    "%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "\n",
    "study = optuna.create_study(study_name=\"DecisionTreeRegressor\", direction=\"minimize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "\n",
    "study.optimize(optuna_rf, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.171\n",
      "Train MAE: 0.002\n",
      "Train MAPE: 37.514\n",
      "\n",
      "\n",
      "Test R^2: 0.108\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 39.089\n"
     ]
    }
   ],
   "source": [
    "regr1 = DecisionTreeRegressor(max_depth=study.best_params['max_depth'], min_samples_leaf = study.best_params['min_samples_leaf'],  min_samples_split = study.best_params['min_samples_split'], random_state=42)\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr1.predict(X_train))\n",
    "\n",
    "y_test_pred = (regr1.predict(X_test))\n",
    "\n",
    "# print_metrics(1 * (y_train), (1 * y_train_pred), 1 * (y_test), 1 * y_test_pred)\n",
    "\n",
    "print_metrics(base ** y_train, base ** y_train_pred, base ** y_test, base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3311633845.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [54]\u001b[1;36m\u001b[0m\n\u001b[1;33m    -----\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# ищем лучшую комбинацию гиперпараметров n_trials раз\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mFATAL)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(optuna_rf, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\Arwielao\\Python 3.10\\IDE\\skillfactory\\WB analisys\\TG\\TG addon\\tg_an_410-10-ml_addon.ipynb Cell 33\u001b[0m in \u001b[0;36moptuna_rf\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m DecisionTreeRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                               max_depth\u001b[39m=\u001b[39mmax_depth,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                               min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                               min_samples_split\u001b[39m=\u001b[39mmin_samples_split,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                               random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                               )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# обучаем модель\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_absolute_percentage_error(base \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m y_test, base \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Arwielao/Python%203.10/IDE/skillfactory/WB%20analisys/TG/TG%20addon/tg_an_410-10-ml_addon.ipynb#Y212sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 200, 1)\n",
    "  \n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 1000, 1)\n",
    "  \n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 100, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = DecisionTreeRegressor(\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                random_state=42\n",
    "                                )\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = metrics.mean_absolute_percentage_error(base ** y_test, base ** model.predict(X_test)) * 100\n",
    "\n",
    "  return score\n",
    "%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "\n",
    "study = optuna.create_study(study_name=\"DecisionTreeRegressor\", direction=\"minimize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.178\n",
      "Train MAE: 0.003\n",
      "Train MAPE: 39.748\n",
      "\n",
      "\n",
      "Test R^2: 0.136\n",
      "Test MAE: 0.003\n",
      "Test MAPE: 40.550\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = DecisionTreeRegressor(max_depth=study.best_params['max_depth'], min_samples_leaf = study.best_params['min_samples_leaf'],  min_samples_split = study.best_params['min_samples_split'], random_state=42)\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr1.predict(X_train))\n",
    "\n",
    "y_test_pred = (regr1.predict(X_test))\n",
    "\n",
    "# print_metrics(1 * (y_train), (1 * y_train_pred), 1 * (y_test), 1 * y_test_pred)\n",
    "\n",
    "print_metrics(base ** y_train, base ** y_train_pred, base ** y_test, base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'features': list(grand_df.drop([target], axis=1).columns), 'importance': regr1.feature_importances_}).sort_values(by='importance', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h</td>\n",
       "      <td>0.295512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtdays</td>\n",
       "      <td>0.131048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second</td>\n",
       "      <td>0.097981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>🌍in_msg</td>\n",
       "      <td>0.063950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🐻in_msg</td>\n",
       "      <td>0.052044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weight_to_height</td>\n",
       "      <td>0.044131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>day_of_year</td>\n",
       "      <td>0.027622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MessageEntityBold</td>\n",
       "      <td>0.023908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>speech</td>\n",
       "      <td>0.023477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>list_of_count_colors</td>\n",
       "      <td>0.021487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.018539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>skip</td>\n",
       "      <td>0.017973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>morinig</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.015645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minute</td>\n",
       "      <td>0.014439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MessageEntityTextUrl</td>\n",
       "      <td>0.013756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>📚in_msg</td>\n",
       "      <td>0.010284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>re_lemmas_count</td>\n",
       "      <td>0.009661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_number_5</td>\n",
       "      <td>0.009587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>grey</td>\n",
       "      <td>0.008083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>v_median</td>\n",
       "      <td>0.006310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features  importance\n",
       "0                      h    0.295512\n",
       "1                 dtdays    0.131048\n",
       "2                 second    0.097981\n",
       "3                🌍in_msg    0.063950\n",
       "4                🐻in_msg    0.052044\n",
       "5       weight_to_height    0.044131\n",
       "6            day_of_year    0.027622\n",
       "7      MessageEntityBold    0.023908\n",
       "8                 speech    0.023477\n",
       "9   list_of_count_colors    0.021487\n",
       "10              positive    0.018539\n",
       "11                  skip    0.017973\n",
       "12               morinig    0.017195\n",
       "13               neutral    0.015645\n",
       "14                minute    0.014439\n",
       "15  MessageEntityTextUrl    0.013756\n",
       "16               📚in_msg    0.010284\n",
       "17       re_lemmas_count    0.009661\n",
       "18         word_number_5    0.009587\n",
       "19                  grey    0.008083\n",
       "20              v_median    0.006310"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(importance.loc[0:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'dtdays', 'second', '🌍in_msg', '🐻in_msg', 'weight_to_height', 'day_of_year', 'MessageEntityBold', 'speech', 'list_of_count_colors', 'positive', 'skip', 'morinig', 'neutral', 'minute', 'MessageEntityTextUrl', '📚in_msg', 're_lemmas_count', 'word_number_5', 'grey', 'v_median']\n"
     ]
    }
   ],
   "source": [
    "fchrs = list(importance.loc[0:20,'features'])\n",
    "\n",
    "print(fchrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2133496677.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [149]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ----\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "joblib.dump(regr1, \"model.pkl\") \n",
    "\n",
    "# load\n",
    "regr1_ld = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = (regr1_ld.predict(X_train))\n",
    "y_test_pred = (regr1_ld.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), (base ** y_train_pred), np.round(base ** (y_test) * 50000), np.round(base ** y_test_pred * 50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "print(\"Версия Optuna: {}\".format(optuna.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  max_depth = trial.suggest_int('max_depth', 2, 100, 1)\n",
    "  \n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 10, 1000, 1)\n",
    "  \n",
    "  min_samples_split = trial.suggest_int('min_samples_split', 2, 100, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = DecisionTreeRegressor(\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                random_state=42\n",
    "                                )\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  score = metrics.mean_absolute_percentage_error(base ** y_test * 500, base ** model.predict(X_test) * 500) * 100\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"DecisionTreeRegressor\", direction=\"minimize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'max_depth': 23, 'min_samples_leaf': 140, 'min_samples_split': 23}\n",
      "mape на обучающем наборе: 37.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"mape на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zero = pd.read_csv('pread.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = data_zero[cols_test].drop(['forwards_to_views'], axis=1).loc[0,:].values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y = np.array(data_zero.loc[0,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y = ds_y.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ds_pred = regr1.predict(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(base ** y_ds_pred * 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics.mean_absolute_percentage_error(np.round(ds_y * 500), np.round(base ** y_ds_pred * 500)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(ds_y * 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(metrics.mean_absolute_error(np.round(ds_y * 500), np.round(base ** y_ds_pred * 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base ** y_ds_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'np.exp(y_test)': np.array([i[0] for i in np.exp(y_test)]), 'y_test_pred':y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff'] = abs(df['np.exp(y_test)'] - df['y_test_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('diff.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([i[0] for i in np.exp(y_test)]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(grand_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=list(range(np.exp(y_test).shape[0])), y=np.array([i[0] for i in np.exp(y_test)]), color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.exp(y_test), y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "scores = cross_val_score(regr1, X_train, y_train,\n",
    "                         scoring='neg_mean_absolute_percentage_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "scores * - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "scores = cross_val_score(regr1, X_test, y_test,\n",
    "                         scoring='neg_mean_absolute_percentage_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "scores * - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'features': list(grand_df.drop([target], axis=1).columns), 'importance': regr1.feature_importances_}).sort_values(by='importance', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.to_excel('importance1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(importance['features'][1:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_in = pd.DataFrame({'y_train':list(np.exp(y_test)), 'y_train_pred':list(y_train_pred.reshape(-1, 1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_in['y_train'] = plot_in['y_train'].apply(lambda x: x[0])\n",
    "plot_in['y_train_pred'] = plot_in['y_train_pred'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_in['y_diff'] = abs(plot_in['y_train_pred'] - plot_in['y_train'])\n",
    "index_to_del = list(plot_in[plot_in['y_diff'] > 0.04].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_del.remove(760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[index_to_del,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(index_to_del, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = plot_in['y_train'].drop(index_to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr1 = DecisionTreeRegressor(max_depth=12, min_samples_leaf = 4, random_state=42)\n",
    "regr1.fit(X_train, y_train)\n",
    "y_train_pred = regr1.predict(X_train)\n",
    "y_test_pred = regr1.predict(X_test)\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=list(range(plot_in['y_train'].shape[0])), y=plot_in['y_train_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2 = RandomForestRegressor(max_depth=12, n_estimators=300, random_state=42)\n",
    "regr2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = (regr2.predict(X_train))\n",
    "y_test_pred = (regr2.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test),base ** y_test_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import StackingRegressor\n",
    "# from sklearn.linear_model import RidgeCV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from statistics import linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(\n",
    "    max_depth = 3,\n",
    "    min_samples_leaf = 10,\n",
    "    n_estimators = 200,\n",
    "    random_state = 42 \n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# gb_pred  = gb.predict(X_test)\n",
    "\n",
    "y_train_pred = (gb.predict(X_train))\n",
    "y_test_pred = (gb.predict(X_test))\n",
    "\n",
    "print_metrics(base ** (y_train), base ** y_train_pred, base ** (y_test), base ** y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = np.exp(y_train_pred)\n",
    "y_test_pred = np.exp(y_test_pred)\n",
    "y_train = np.exp(y_train)\n",
    "y_test = np.exp(y_test)\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'features': list(grand_df.drop([target], axis=1).columns), 'importance': gb.feature_importances_}).sort_values(by='importance', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batching_nonlinear_test_different_sizes_another(data, target, batch_left, batch_right):\n",
    "    \n",
    "    if batch_right > data.shape[0]:\n",
    "        return 'incorrect batch_size_right value'\n",
    "    \n",
    "    data = data.loc[batch_left:batch_right,:]\n",
    "    \n",
    "    y = np.array(data[target])\n",
    "    \n",
    "    X = data.drop([target], axis = 1)\n",
    "    \n",
    "    \n",
    "    metrics_value = []\n",
    "    batch_value = []\n",
    "    \n",
    "    #\n",
    "    # dataset = data.loc[batch_left:batch_right,:]\n",
    "    \n",
    "    # target_y = y[batch_left:batch_right,]\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "    \n",
    "    # model =  linear_model.Ridge(max_iter = 2000)\n",
    "    \n",
    "    model =  DecisionTreeRegressor(max_depth=12, min_samples_leaf = 4, random_state=42)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "    \n",
    "    metrics_value = (metrics.mean_absolute_percentage_error(y_test, y_test_pred)*100)\n",
    "    \n",
    "    batch_value = (batch_right - batch_left)# dataset.shape[0]) batch_size\n",
    "    \n",
    "    return metrics_value,batch_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batching_nonlinear_test_different_sizes_another(grand_df, target, 8500, grand_df.shape[0])# grand_df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
